# ğŸ“˜ COMPLETE_SYLLABUS_v12_FINAL_Updated.md
**Version:** 12.1  
**Status:** âœ… OFFICIAL FINAL SYLLABUS (Narrative-First, MIT 6.006/6.046 Aligned)  
**Philosophy:**  
- Mental-model-first  
- Systems & production grounded  
- Pattern-centric  
- Understanding before code  
- Explicit MIT 6.006 + 6.046 topic coverage via core + optional days  

Each week includes:  
- **Primary Goal** â€“ what you should internalize.  
- **Why This Week Comes Here** â€“ role in the global learning arc.  
- **Day-by-Day Topics** â€“ with core and optional days.  
- **MIT Alignment Notes** â€“ where applicable.

Conventions:  
- â€œCoreâ€ = must-do days for interview & systems readiness.  
- â€œOptional Advancedâ€ = 6.046-style or research-flavored depth, not required for basic interview prep but highly recommended for mastery.

---

## ğŸ”· Phase A â€“ Foundations (Weeks 1â€“3)

---

### ğŸ§± Week 1 â€“ Foundations I: Computational Fundamentals, Peak Finding & Asymptotics

**Primary Goal:**  
Build a rock-solid mental model of how programs execute on a machine: memory layout, pointers, the RAM model, the cost model (Big-O), and recursion mechanics. Learn your first â€œdesign a better algorithmâ€ story via peak finding (MIT 6.006 style).

**Why This Week Comes Here:**  
Everything elseâ€”arrays, trees, graphs, DPâ€”sits on top of these models. If memory and cost are fuzzy, optimization feels like magic. Peak finding sets the tone for algorithmic thinking.

**MIT Alignment:**  
- RAM model and cost model from 6.006.  
- 1D/2D peak finding design story from 6.006.

#### ğŸ“… Day 1 (Core) â€“ RAM Model, Virtual Memory & Pointers

**Conceptual Goals:** Understand how memory is organized and addressed, what a pointer really is, and why locality matters.

**Topics & Subtopics:**
- ğŸ§  RAM Model
  - Memory as an array of cells (abstract).  
  - Constant-time random access assumption and where it breaks in reality.  
- ğŸ—‚ï¸ Process Address Space
  - Code/text segment, global/static segment, heap, stack.  
  - What typically lives where (functions, static variables, dynamic objects, call frames).  
- ğŸ·ï¸ Variables vs Pointers
  - Scalar variables as named cells holding values.  
  - Pointers/references as â€œaddresses in variablesâ€.  
  - Dereferencing: â€œfollow this arrowâ€ mentally.  
  - Null pointers and invalid addresses (conceptual only).  
- ğŸ’¾ Virtual Memory & TLB (Conceptual)
  - Virtual vs physical address space.  
  - Pages and page tables: mapping virtual â†’ physical frames.  
  - TLB (Translation Lookaside Buffer) as cache for translations.  
  - Page faults: what they are and why theyâ€™re expensive.  
  - Why contiguous access is faster (fewer TLB misses, better locality).  
- ğŸ›ï¸ Memory Hierarchy & Caches
  - Registers, L1/L2/L3 caches, DRAM, disk.  
  - Cache lines (~64 bytes) and spatial locality.  
  - Temporal locality and why repeated access to same data is fast.  
- âš ï¸ Common Pointer Pitfalls (Conceptual)
  - Uninitialized pointers.  
  - Dangling pointers (free then use).  
  - Double free.  
- ğŸ› ï¸ Systems Angle
  - Alignment & padding: why compilers align data.  
  - False sharing preview: two threads bumping same cache line.  

#### ğŸ“… Day 2 (Core) â€“ Asymptotic Analysis: Big-O, Big-Î©, Big-Î˜

**Conceptual Goals:** Learn to talk about performance in terms of input size, and classify algorithms by growth rate.

**Topics & Subtopics:**
- ğŸ¯ Motivation for Asymptotics
  - Why constant factors and micro-optimizations are not enough.  
  - â€œWhat happens as n â†’ large?â€  
- ğŸ“ˆ Basic Complexity Notions
  - Big-O (upper bound).  
  - Big-Î© (lower bound).  
  - Big-Î˜ (tight bound).  
  - Intuitive meaning with graphs.  
- ğŸ§® Common Complexity Classes
  - O(1), O(log n), O(n), O(n log n), O(nÂ²), O(2â¿), O(n!).  
  - Real-world interpretation (e.g., when n=10â¶).  
- ğŸŒ³ Simple Recurrence Examples
  - Binary search: T(n) = T(n/2) + O(1).  
  - Merge sort (high-level): T(n) = 2T(n/2) + O(n).  
  - Recurrence trees intuition (no formal Master theorem yet).  
- ğŸ§ª Comparing Functions
  - When O(n log n) beats O(nÂ²) concretely.  
  - Break-even points and constant factors.  
- ğŸ§µ Systems View
  - For small n, constants & cache may dominate.  
  - Why algorithmic complexity still matters as n grows.  

#### ğŸ“… Day 3 (Core) â€“ Space Complexity & Memory Usage

**Conceptual Goals:** Understand how much memory an algorithm uses and where it lives.

**Topics & Subtopics:**
- ğŸ§® Types of Space
  - Total vs auxiliary space.  
  - Input vs output vs scratch.  
- ğŸ§Š Stack vs Heap
  - Stack frames: parameters, locals, return addresses.  
  - Heap: dynamic allocation, fragmentation, overhead.  
- ğŸ¯ Lifetime & Scope
  - Block scope, function scope, global scope.  
  - When memory is automatically reclaimed vs manually managed (conceptual).  
- ğŸ“¦ Space Overheads
  - Pointer size, object headers, allocator metadata.  
  - Why a vector<int> uses more than NÃ—sizeof(int).  
- âš–ï¸ Timeâ€“Space Trade-offs
  - Caching results vs memory footprint.  
  - Precomputation tables & lookup.  
  - Using more memory to reduce time (memoization, hash maps).  
- ğŸ’¾ Memory Hierarchy Revisited
  - Cache vs RAM vs disk implications.  
  - Working set and â€œfitting in memory.â€  

#### ğŸ“… Day 4 (Core) â€“ Recursion I: Call Stack & Basic Patterns

**Conceptual Goals:** See recursion as a consequence of how function calls work, not magic.

**Topics & Subtopics:**
- ğŸ§± Call Stack Mechanics
  - Activation records: parameters, locals, return address.  
  - Pushing/popping frames as functions call/return.  
- ğŸ” Basic Recursive Structure
  - Base case: when to stop recursing.  
  - Recursive case: reduce problem size.  
  - Progress toward base case.  
- ğŸŒ² Simple Recursive Examples
  - Factorial, sum over array.  
  - Naive Fibonacci and its recursion tree.  
- ğŸŒ³ Recursion Trees
  - Visualizing branching and depth.  
  - Identifying exponential blowup.  
- âš ï¸ Failure Modes
  - Missing base case â†’ infinite recursion.  
  - Recursion that doesnâ€™t make progress.  
  - Stack overflow from deep recursion.  

#### ğŸ“… Day 5 (Core) â€“ Recursion II: Patterns & Memoization Intro

**Conceptual Goals:** Recognize recurring recursion patterns and understand memoization as caching for recursion.

**Topics & Subtopics:**
- ğŸ” Recursion Patterns (Structural)
  - Linear recursion (single chain).  
  - Tree recursion (multiple branches).  
  - Divide-and-conquer recursion.  
- ğŸ¯ Tail Recursion vs General Recursion (Conceptual)
  - Tail call: last operation.  
  - When tail recursion resembles a loop.  
- ğŸ”„ Mutual & Indirect Recursion
  - A calls B calls A.  
  - Even/odd recursive definitions.  
- ğŸ“¦ Memoization
  - Overlapping subproblems: recognizing repeated work.  
  - Cache design: key, value, lookup.  
  - Turning exponential recursion into polynomial time.  
- ğŸ’£ Stack Depth & Limits
  - Practical recursion depth limits.  
  - When to convert to iteration/explicit stack.  

#### ğŸ“… Day 6 (Optional Advanced) â€“ Peak Finding & Algorithmic Thinking (MIT 6.006)

**Conceptual Goals:** Experience your first full algorithm design story end-to-end.

**Topics & Subtopics:**
- ğŸ§© 1D Peak Finding
  - Definition of a peak.  
  - Simple O(n) scan solution.  
  - Why we can do better.  
- âœ‚ï¸ 1D Divide & Conquer Solution
  - Examine mid element and neighbor.  
  - Recurse on â€œpromisingâ€ side.  
  - Complexity intuition: O(log n) or O(n) depending on variant.  
- ğŸ§± Extending to 2D Peaks
  - Matrix as 2D grid.  
  - Mid-column selection and column-local maximum.  
  - Move to adjacent column if neighbor is larger.  
  - Recurrence intuition and complexity.  
- ğŸ§­ Meta-Lessons
  - Exploiting structure and monotonicity.  
  - â€œBetter-than-brute-forceâ€ mindset.  

**MIT Alignment:** Directly mirrors 6.006 peak-finding lecture.

---

### ğŸ§± Week 2 â€“ Foundations II: Linear Data Structures & Binary Search

**Primary Goal:**  
Internalize arrays, dynamic arrays, linked lists, stacks, and queues, both conceptually and in memory. Understand binary search as a robust invariant-based pattern.

**Why This Week Comes Here:**  
Arrays and lists are the substrate for most patterns and DS; binary search will recur across many later weeks.

**MIT Alignment:**  
- Arrays, dynamic arrays, linked structures, and binary search from 6.006.

#### ğŸ“… Day 1 (Core) â€“ Arrays & Memory Layout

**Topics & Subtopics:**
- ğŸ“Š Static Arrays
  - Contiguous memory representation.  
  - Indexâ†’address mapping formula (base + iÃ—stride).  
- ğŸŒ Layouts
  - Row-major vs column-major (conceptual).  
  - Impact on matrix traversals later.  
- âœ… Pros
  - Great locality, prefetching, vectorization.  
  - O(1) random access under RAM model.  
- âŒ Cons
  - Fixed size, difficult resizing.  
  - Expensive mid-insert/delete.  
- ğŸ§µ Systems Angle
  - Cache-friendly iteration vs random access.  
  - False sharing considerations when multiple threads touch arrays.

#### ğŸ“… Day 2 (Core) â€“ Dynamic Arrays & Informal Amortized Growth

**Topics & Subtopics:**
- ğŸ“¦ Dynamic Array Model
  - Logical size vs capacity.  
  - Backing store in contiguous memory.  
- â±ï¸ Growth Strategy
  - Doubling capacity when full.  
  - Amortized cost intuition: many cheap operations, few expensive ones.  
- ğŸ” Reallocation Effects
  - Copying existing elements on resize.  
  - Pointer/address invalidation.  
- ğŸ¤ Shrinking / Reserve
  - When to reserve capacity.  
  - Trade-offs of shrink-to-fit.  
- ğŸ” Systems Angle
  - Fragmentation and allocator overhead.  
  - When a vector reallocation can cause performance spikes.  

#### ğŸ“… Day 3 (Core) â€“ Linked Lists

**Topics & Subtopics:**
- ğŸ”— Singly & Doubly Linked Lists
  - Node structure (value + next [+ prev]).  
  - Visual diagrams in heap.  
- ğŸ§® Operations
  - Insert/delete at head (O(1)).  
  - Tail operations with or without tail pointer.  
  - Insert/delete at arbitrary position (need previous pointer).  
- âœ… Pros
  - O(1) insert/delete at known node.  
  - Flexible size.  
- âŒ Cons
  - No O(1) random access.  
  - Poor cache locality, pointer chasing.  
- ğŸ”¬ Systems Angle
  - Why linked lists can be slower than arrays in practice despite asymptotics.  

#### ğŸ“… Day 4 (Core) â€“ Stacks, Queues & Deques

**Topics & Subtopics:**
- ğŸ“š Stack (LIFO)
  - Push/pop semantics.  
  - Connection to call stack & recursion.  
  - Use-cases: expression evaluation, backtracking, DFS.  
- ğŸš Queue (FIFO)
  - Enqueue/dequeue semantics.  
  - Use-cases: BFS, scheduling, buffering.  
- ğŸ” Deques
  - Double-ended queues as generalization.  
  - Sliding window and monotonic queue patterns (preview).  
- ğŸ—ï¸ Implementations
  - Array-based vs list-based.  
  - Circular buffer for queues.  

#### ğŸ“… Day 5 (Core) â€“ Binary Search & Invariants

**Topics & Subtopics:**
- ğŸ” Binary Search Basics
  - Sorted arrays as precondition.  
  - low, high, mid; invariant that target lies in [low, high].  
- âš™ï¸ Implementing Safely
  - mid = low + (high - low)/2 to avoid overflow.  
  - Termination conditions & preventing infinite loops.  
- ğŸ§© Variants
  - First/last occurrence.  
  - lower_bound/upper_bound.  
- ğŸ§­ Binary Search on Answer Space
  - Monotone conditions (feasible/infeasible).  
  - Examples: capacity planning, minimize maximum load, maximize minimum distance.  
- ğŸ§µ Systems Angle
  - Binary search in standard libraries.  
  - Using BS to tune configuration parameters.  

---

### ğŸ§± Week 3 â€“ Foundations III: Sorting, Heaps & Hashing

**Primary Goal:**  
Understand internal mechanics and trade-offs of sorting algorithms, heaps, and hash tables, including string hashing.

**Why This Week Comes Here:**  
Sorting and hashing are fundamental primitives; heaps introduce tree-like structure with strong performance guarantees.

**MIT Alignment:**  
- Sorting & heaps from 6.006.  
- Hashing and string matching (Karpâ€“Rabin) from 6.006.

#### ğŸ“… Day 1 (Core) â€“ Elementary Sorts: Bubble, Selection, Insertion

**Topics & Subtopics:**
- ğŸ” Bubble Sort
  - Adjacent swaps, bubbling largest element up.  
  - Best vs worst case.  
- ğŸ¯ Selection Sort
  - Selecting min/max and placing at correct position.  
- ğŸ§© Insertion Sort
  - Grow a sorted prefix by inserting next element.  
- âš–ï¸ Trade-offs
  - O(nÂ²) but small constant factors.  
  - Use cases: small n, nearly sorted arrays, hybrid algorithms.  
- ğŸ§  Stability & In-Place
  - Definitions and why they matter.  

#### ğŸ“… Day 2 (Core) â€“ Merge Sort & Quick Sort

**Topics & Subtopics:**
- âœ‚ï¸ Merge Sort
  - Divide, recursively sort halves, merge.  
  - Recurrence and O(n log n) worst-case behavior.  
  - Extra memory cost; stable.  
- âš¡ Quick Sort
  - Partition around pivot.  
  - Expected O(n log n), worst-case O(nÂ²).  
  - Pivot strategies; randomization.  
- ğŸ§  Practical Considerations
  - Real library implementations (introsort-style hybrids).  

#### ğŸ“… Day 3 (Core) â€“ Heaps, Heapify & Heap Sort

**Topics & Subtopics:**
- ğŸ”ï¸ Binary Heap Model
  - Array representation; parent/child relationships.  
  - Min-heap vs max-heap.  
- âš™ï¸ Core Operations
  - Insert and â€œbubble upâ€.  
  - Extract-min/max and â€œheapify downâ€.  
  - Build-heap in O(n).  
- ğŸ§® Heap Sort
  - Build heap, then repeatedly extract.  
  - In-place variant vs external heap.  
- ğŸš¨ Priority Queues
  - Use-cases: Dijkstra, event simulation, task schedulers.  

#### ğŸ“… Day 4 (Core) â€“ Hash Tables I: Separate Chaining

**Topics & Subtopics:**
- ğŸ”‘ Hash Functions
  - Mapping keys to bucket indices.  
  - Desiderata: uniformity, cheap to compute.  
- ğŸª£ Separate Chaining
  - Buckets as linked lists or small vectors.  
  - Expected O(1) operations given good hash and moderate load factor.  
- ğŸ” Resizing & Load Factor
  - Resize strategies (doubling buckets).  
  - Rehashing cost & amortized analysis (intuitive).  
- âš ï¸ Worst-Case Behavior
  - Adversarial inputs and O(n) chains.  

#### ğŸ“… Day 5 (Core, Enhanced) â€“ Hash Tables II: Open Addressing & Rolling Hash (Karpâ€“Rabin)

**Topics & Subtopics:**
- ğŸšª Open Addressing Strategies
  - Linear probing; primary clustering.  
  - Quadratic probing; reducing clustering.  
  - Double hashing; independent hash functions.  
  - Load factor thresholds for performance.  
- ğŸ” Hash Security & Universal Hashing
  - Hash flooding attacks (adversarial collisions).  
  - Randomized hash seeds.  
  - Universal hashing: family of hash functions with low collision probability.  
- ğŸ§µ Rolling Hash & Karpâ€“Rabin
  - Polynomial rolling hash on strings.  
  - Sliding window updates in O(1).  
  - Collision handling & trade-offs.  
  - Applications: substring search, plagiarism detection, DNA sequences.  

**MIT Alignment:** Hashing and Karpâ€“Rabin from 6.006; universal hashing from 6.046.

---

## ğŸ”· Phase B â€“ Core Patterns & String Patterns (Weeks 4â€“6)

---

### ğŸ§© Week 4 â€“ Core Problem-Solving Patterns I: Two Pointers, Sliding Windows, Divide & Conquer, Binary Search as Pattern

**Primary Goal:**  
Acquire foundational array/sequence patterns that drastically simplify many problems.

**Why This Week Comes Here:**  
Arrays are familiar now; patterns are reusable templates to solve families of problems efficiently.

**MIT Alignment:**  
- Problem-solving patterns and recursion from 6.006.

#### ğŸ“… Day 1 (Core) â€“ Two-Pointer Patterns

**Topics & Subtopics:**
- â†”ï¸ Same-Direction Pointers
  - Merging two sorted arrays/lists.  
  - Removing duplicates in-place.  
- â†”ï¸ Opposite-Direction Pointers
  - Container with most water / max area.  
  - Two-sum in sorted arrays.  
- ğŸ§  Invariants
  - Keeping track of what is guaranteed as pointers move.  

#### ğŸ“… Day 2 (Core) â€“ Sliding Window (Fixed Size)

**Topics & Subtopics:**
- ğŸªŸ Fixed-Length Windows
  - Running sum/average of k-length subarrays.  
  - Maximum/minimum in sliding window using deque (monotonic queue).  
- ğŸ§  Patterns
  - Initiate first window, then slide by one position.  

#### ğŸ“… Day 3 (Core) â€“ Sliding Window (Variable Size)

**Topics & Subtopics:**
- ğŸ“ Variable-Size Windows
  - Growing & shrinking windows to maintain constraints.  
  - â€œAt most K distinct charactersâ€ patterns.  
- ğŸ“¦ Frequency Maps
  - Hash maps for counts; when to shrink.  
- ğŸ§  Decision Logic
  - Condition-driven expand/shrink decisions.  

#### ğŸ“… Day 4 (Core) â€“ Divide & Conquer Pattern

**Topics & Subtopics:**
- âœ‚ï¸ General Template
  - Split â†’ solve subproblems â†’ combine.  
- ğŸ§® Recurrence View
  - Recurrence trees (visual).  
- ğŸ” Classic Examples
  - Merge sort; counting inversions; majority element.  

#### ğŸ“… Day 5 (Core) â€“ Binary Search as a Pattern

**Topics & Subtopics:**
- ğŸ§­ Binary Search Beyond Sorted Arrays
  - Search on â€œanswer space.â€  
- âœ… Feasibility Checks
  - â€œCan we schedule jobs with capacity X?â€  
  - â€œCan we place routers with minimum distance D?â€  
- ğŸ” Examples
  - Minimizing maximum load (machine scheduling).  
  - Maximizing minimum distance (aggressive cows style).  

---

### ğŸ§© Week 5 â€“ Tier 1 Critical Patterns: Hash, Monotonic Stack, Intervals, Partition & Kadane, Fast/Slow

**Primary Goal:**  
Master a set of high-frequency patterns (hash, monotonic stack, interval, cyclic sort, Kadane, fast/slow) that cover a large fraction of interview problem space.

**Why This Week Comes Here:**  
Builds directly on Week 4 patterns and prepares for tree/graph/DP complexity.

**MIT Alignment:**  
- Pattern-centric intermediate problem solving in 6.006.

#### ğŸ“… Day 1 (Core) â€“ Hash Map / Hash Set Patterns

**Topics & Subtopics:**
- ğŸ¯ Two-Sum & Complement Patterns
  - Complement lookup.  
- ğŸ”¤ Frequency Counting
  - Anagrams, top-k frequent, histogram problems.  
- ğŸ‘¥ Membership & Deduplication
  - Using sets/maps for quick membership tests.  

#### ğŸ“… Day 2 (Core) â€“ Monotonic Stack

**Topics & Subtopics:**
- ğŸ“ˆ Increasing/Decreasing Stacks
  - Next greater/smaller element.  
  - Stock span problems.  
- ğŸ’§ Trapping Rain Water
  - Stack-based insight.  
- ğŸ“Š Largest Rectangle in Histogram
  - Classic monotonic stack application.  

#### ğŸ“… Day 3 (Core) â€“ Merge Operations & Interval Patterns

**Topics & Subtopics:**
- ğŸ” Merge Sorted Arrays/Lists
  - Two-pointer merge O(m+n).  
- ğŸ”„ Merge K Sorted Lists
  - Naive pairwise merging vs heap-based merging (O(N log k)).  
- ğŸ“… Interval Problems
  - Merge intervals (scheduling).  
  - Insert interval with merging.  
- ğŸ§· Real Systems
  - Calendar scheduling; resource allocation.  

#### ğŸ“… Day 4 (Part A) â€“ Partition, Cyclic Sort
**Topics & Subtopics:**
- ğŸ¨ Partitioning Arrays
  - Dutch National Flag (0/1/2 sorting).  
  - Move zeroes to the end.  
- ğŸ”„ Cyclic Sort
  - Position-based rearrangement for 1..n arrays.  
  - Finding missing numbers/duplicates.  
  - In-place segregation O(1) space
- ğŸ“ˆ Kadaneâ€™s Algorithm
  - Max subarray sum.  
  - Variants (circular arrays, max product).  

#### ğŸ“… Day 4 (Part B) â€“ Kadane's Algorithm

**Topics & Subtopics:**
- ğŸ“ˆ Kadaneâ€™s Algorithm
  - Maximum subarray problem
  - Maximum product subarray
  - Max subarray sum.  
  - Variants (circular arrays, max product).  
  - DP formulation
  - Constraint variations (circular)
  - Real-world: financial analysis

#### ğŸ“… Day 5 (Core) â€“ Fast/Slow Pointers

**Topics & Subtopics:**
- ğŸ” Floydâ€™s Cycle Detection
  - Detect cycles in linked lists.  
- ğŸ¯ Finding Cycle Start
  - Pointer reset trick.  
- ğŸ“ Midpoint & List Splitting
  - Finding middle node; splitting lists.  
- ğŸ˜Š Number Problems
  - Happy number; detecting cycles in sequences.  

---

### ğŸ§© Week 6 â€“ Tier 1.5 String Manipulation Patterns

**Primary Goal:**  
Learn practical string patterns for palindromes, substrings, parentheses, and transformations.

**Why This Week Comes Here:**  
Strings are arrays of characters; this week adapts earlier patterns to text.

**MIT Alignment:**  
- String processing and basic matching from 6.006.

#### ğŸ“… Day 1 (Core) â€“ Palindrome Patterns

**Topics & Subtopics:**
- ğŸ” Simple Palindrome Checks
  - Two-pointer comparisons.  
- ğŸ¯ Longest Palindromic Substring
  - Expand-around-center pattern.  
- ğŸ§© Palindrome Partitioning (Intro)
  - Partitioning into palindromic substrings.  
  - Link to DP in later weeks.  

#### ğŸ“… Day 2 (Core) â€“ Substring & Sliding Window on Strings

**Topics & Subtopics:**
- ğŸš« Longest Substring Without Repeating Characters
  - Variable window with char index map.  
- ğŸ”¤ Character Replacement within K Changes
  - Using counts & window length.  
- ğŸ”„ Permutation-in-String / Anagram Substrings
  - Fixed-size window + frequency matching.  
- ğŸ¯ Minimum Window Substring
  - Shrink/expand logic with char counts.  

#### ğŸ“… Day 3 (Core) â€“ Parentheses & Bracket Matching

**Topics & Subtopics:**
- ğŸ§± Valid Parentheses via Stack
  - Stack of open brackets; matching logic.  
- ğŸ§¬ Generate Parentheses
  - Backtracking pattern preview.  
- ğŸ§® Longest Valid Parentheses
  - Stack-based solution.  
  - DP-based interpretation (optional).  
- ğŸ”§ Minimum Remove to Make Valid
  - Single-pass or two-pass strategies.  

#### ğŸ“… Day 4 (Core) â€“ String Transformations & Building

**Topics & Subtopics:**
- ğŸ”¢ String to Integer (atoi)
  - Trimming, sign, overflow handling.  
- ğŸ” Integer â†” Roman Numerals
  - Mapping numeric ranges to symbols.  
- ğŸ§µ Zigzag Conversion
  - Row-by-row or index formula mapping.  
- ğŸ“¦ String Compression / RLE
  - Run-length encoding patterns.  
- âš™ï¸ Performance
  - String immutability and use of builders.  

#### ğŸ“… Day 5 (Optional Advanced) â€“ String Matching & Rolling Hash in Practice

**Topics & Subtopics:**
- ğŸ§µ Revisiting Karpâ€“Rabin
  - Rolling hash details and collision management.  
- âš–ï¸ Comparisons
  - Karpâ€“Rabin vs KMP vs Boyerâ€“Moore (high-level).  
- ğŸ§ª Applications
  - Log search; searching DNA sequences; plagiarism detection.  

**MIT Alignment:** Builds directly on 6.006 string matching topics.

---

## ğŸ”· Phase C â€“ Trees, Graphs & Dynamic Programming (Weeks 7â€“11)

---

### ğŸŒ³ Week 7 â€“ Trees & Balanced Search Trees

**Primary Goal:**  
Understand tree structures, traversals, BST operations, and balanced BSTs conceptually and practically.

**Why This Week Comes Here:**  
Trees generalize linear structures into hierarchies; BSTs and balanced BSTs are central to ordered data.

**MIT Alignment:**  
- Trees & balanced BSTs are core in 6.006; augmented trees & analysis appear in 6.046.

#### ğŸ“… Day 1 (Core) â€“ Binary Trees & Traversals

**Topics & Subtopics:**
- ğŸŒ² Tree Anatomy
  - Root, parent, child, leaf, height, depth.  
  - Full, complete, balanced trees (conceptual).  
- ğŸ” Traversals
  - Preorder, inorder, postorder.  
  - Level-order (BFS) with queue.  
- ğŸ”§ Recursive vs Iterative Traversals
  - Using explicit stack to simulate recursion.  
- ğŸ§© Use-Cases
  - Expression trees; serialization.  

#### ğŸ“… Day 2 (Core) â€“ Binary Search Trees (BSTs)

**Topics & Subtopics:**
- ğŸŒ³ BST Property
  - Left < root < right invariant.  
- ğŸ” Operations
  - Search, insert, delete.  
  - Cases for deletion (leaf, one child, two children).  
- ğŸ“ˆ Inorder Traversal
  - Produces sorted sequence.  
- ğŸ§± Degenerate BSTs
  - Linked-list-like structure when input sorted.  

#### ğŸ“… Day 3 (Core) â€“ Balanced BSTs: AVL & Red-Black (Overview)

**Topics & Subtopics:**
- âš–ï¸ Why Balance?
  - Height bound and O(log n) guarantees.  
- ğŸŒ² AVL Trees
  - Balance factor, rotations (LL, RR, LR, RL).  
- ğŸ”´ Red-Black Trees
  - Coloring rules, black-height, rotations.  
- ğŸ§® Comparison
  - AVL vs red-black trade-offs.  
- ğŸ§µ Real Systems
  - TreeMap/TreeSet, language library implementations.  

#### ğŸ“… Day 4 (Core) â€“ Tree Patterns

**Topics & Subtopics:**
- ğŸ§® Path Sum Problems
  - Root-to-leaf sums, path sum with DFS.  
- ğŸ“ Tree Diameter
  - Longest path via DFS or DP.  
- ğŸ¯ Lowest Common Ancestor (LCA)
  - Binary lifting (conceptual) / parent pointers.  
- ğŸ§± Serialization/Deserialization
  - Level-order or preorder-based approaches.  

#### ğŸ“… Day 5 (Optional Advanced) â€“ Augmented BSTs & Order-Statistics Trees (6.046 Flavor)

**Topics & Subtopics:**
- â• Augmenting Trees
  - Storing subtree size or other metadata.  
- ğŸ”¢ Order-Statistics Trees
  - kth smallest element in O(log n).  
  - Rank queries (how many â‰¤ x).  
- ğŸ“Š Range Count Queries
  - Count in [L, R] using augmented BST.  
- ğŸ§µ Real Systems
  - Range indexes in databases.  

---

### ğŸŒ Week 8 â€“ Graph Fundamentals: Representations, BFS, DFS & Topological Sort

**Primary Goal:**  
Build strong intuition for graph models and basic traversals.

**Why This Week Comes Here:**  
Graphs add a powerful modeling lens; BFS/DFS are core paradigms used everywhere.

**MIT Alignment:**  
- Graph representations, BFS, DFS, and topological sorting from 6.006.

#### ğŸ“… Day 1 (Core) â€“ Graph Models & Representations

**Topics & Subtopics:**
- Adjacency matrix vs adjacency list vs edge list.  
- Memory usage and performance trade-offs.  
- Implicit graphs: grids, puzzles, state spaces.  
- Translating real problems into graphs (nodes and edges).  
- ğŸŒ Graph Types
  - Directed vs undirected.  
  - Weighted vs unweighted.  
- ğŸ“‹ Representations
  - Adjacency list vs adjacency matrix vs edge list.  
  - Memory trade-offs (sparse vs dense).  
- ğŸ§  Implicit Graphs
  - Grids, puzzles, state spaces as graphs.  

#### ğŸ“… Day 2 (Core) â€“ Breadth-First Search (BFS)

**Topics & Subtopics:**
- ğŸš BFS Mechanics
  - Queue-based frontier expansion.  
- ğŸ§­ Shortest Path (Unweighted)
  - Distance layers from source.  
- ğŸ§© Applications
  - Shortest route in unweighted networks, level order in trees.
- BFS algorithm and queue-based frontier tracking.  
- Shortest paths in unweighted graphs.  
- Connected components and bipartite checks (conceptual).  
- Applications: social networks, shortest route when edges all equal.    

#### ğŸ“… Day 3 (Core) â€“ Depth-First Search (DFS) & Topological Sort

**Topics & Subtopics:**
- ğŸ” DFS Mechanics
  - Recursive vs stack-based exploration.  
- ğŸ§± DFS Tree & Edge Types
  - Tree, back, forward, cross edges (conceptual).  
- â™»ï¸ Cycle Detection
  - Using DFS in directed graphs.  
- ğŸ§® Topological Sort
  - DFS post-order method.  
  - Kahnâ€™s algorithm (in-degree + BFS).  
- ğŸ§© Use-Cases
  - Task scheduling & dependency resolution.  
- DFS algorithm via recursion or explicit stack.  
- Use in exploring connected components, path existence, simple cycle detection.  
- Differences vs BFS in typical tasks.  
- Basis for many advanced algorithms (topo sort, SCC, etc.).  

#### ğŸ“… Day 4 (Core) â€“ Connectivity & Bipartite Graphs

**Topics & Subtopics:**
- ğŸ”— Connected Components (Undirected)
  - BFS/DFS for components.  
- âš–ï¸ Bipartite Testing
  - Two-coloring via BFS/DFS.  
- Detecting cycles in undirected vs directed graphs.  
- Connected components and articulation points (high-level).  
- Union-Find/Disjoint Set for offline connectivity queries.  
- Network connectivity examples: reliability of network, connectivity in grids. 
- ğŸ§© Applications
  - Grouping problems; simple 2-colorable constraints.  

#### ğŸ“… Day 5 (Optional Advanced) â€“ Strongly Connected Components (SCC)

**Topics & Subtopics:**
- â™»ï¸ Strongly Connected Components
  - Definition & intuition.  
- ğŸ§­ Kosaraju/Tarjan (Conceptual)
  - Two-pass algorithm idea.  
  - Low-link values and stack.  
- ğŸ§± Component DAG
  - Collapsing SCCs to DAG for further DP/analysis.  

---

### ğŸ›£ï¸ Week 9 â€“ Graph Algorithms I: Shortest Paths, MST & Unionâ€“Find

**Primary Goal:**  
Learn foundational shortest path and MST algorithms, plus disjoint set union for connectivity.

**Why This Week Comes Here:**  
These algorithms solve fundamental optimization and connectivity problems.

**MIT Alignment:**  
- Dijkstra, Bellmanâ€“Ford, Floydâ€“Warshall, MST, and DSU from 6.006/6.046.

#### ğŸ“… Day 1 (Core) â€“ Single-Source Shortest Paths: Dijkstra

**Topics & Subtopics:**
- ğŸ¯ Problem Definition
  - Non-negative edge weights.  
- ğŸš Dijkstra Algorithm
  - Priority queue frontier.  
  - Relaxation steps.  
- â±ï¸ Complexity
  - O((V+E) log V) with heap.  
- ğŸ§µ Practical Notes
  - When Dijkstra is appropriate vs BFS vs others.  

#### ğŸ“… Day 2 (Core) â€“ Bellmanâ€“Ford & Negative Weights

**Topics & Subtopics:**
- ğŸ“‰ Relaxation Over Edges
  - Dynamic programming over path lengths.  
- ğŸ” Algorithm Mechanics
  - V-1 passes over edges.  
- âš ï¸ Negative Cycle Detection
  - Extra pass to detect changes.  
- ğŸ§© Use-Cases
  - Graphs with negative weights but no negative cycles.  

#### ğŸ“… Day 3 (Core, Enhanced) â€“ All-Pairs Shortest Paths: Floydâ€“Warshall

**Topics & Subtopics:**
- ğŸŒ APSP Problem
  - Distances between all pairs of vertices.  
- ğŸ§® DP Formulation
  - Intermediate vertices up to k.  
  - Triple-nested loops and state transitions.  
- â±ï¸ Complexity
  - O(VÂ³) time, O(VÂ²) space.  
- ğŸ§© Use-Cases
  - Dense graphs; small V.  

#### ğŸ“… Day 4 (Core) â€“ Minimum Spanning Trees: Kruskal & Prim

**Topics & Subtopics:**
- ğŸŒ³ MST Definition
  - Spanning tree of minimum total weight.  
- ğŸ§® Cut Property
  - Greedy choice correctness intuition.  
- âœ‚ï¸ Kruskal Algorithm
  - Sort edges; DSU for merging components.  
- âš™ï¸ Prim Algorithm
  - Grow tree from a start node via priority queue.  
- ğŸ§µ Applications
  - Network design; base for clustering.  

#### ğŸ“… Day 5 (Optional Advanced) â€“ DSU / Unionâ€“Find in Depth

**Topics & Subtopics:**
- ğŸ”— Disjoint Set Structure
  - Parent pointers, rank/size.  
- âš™ï¸ Operations
  - find with path compression.  
  - union by rank/size.  
- â±ï¸ Complexity
  - Inverse Ackermann Î±(n) intuition.  
- ğŸ§© Use-Cases
  - Connectivity queries; Kruskal MST; offline queries.  

---

### ğŸ§® Week 10 â€“ Dynamic Programming I: Fundamentals

**Primary Goal:**  
Build DP intuition from recursion + memoization to table-based solutions.

**Why This Week Comes Here:**  
DP is fundamental to optimizing recursive solutions; this is your first deep dive.

**MIT Alignment:**  
- DP basics and examples from 6.006.

#### ğŸ“… Day 1 (Core) â€“ DP as Recursion + Memoization

**Topics & Subtopics:**
- ğŸ§  Overlapping Subproblems
  - Fibonacci, climbing stairs.  
- ğŸ” Top-Down Approach
  - Recursion + memoization.  
- â†• Bottom-Up Approach
  - Tabulation; filling tables iteratively.  

#### ğŸ“… Day 2 (Core) â€“ 1D DP & Knapsack Family

**Topics & Subtopics:**
- ğŸªœ Climbing Stairs Variants
  - Min cost, constraints.  
- ğŸ  House Robber / Non-Adjacent Sum
  - Choose non-adjacent elements for max sum.  
- ğŸ’° Coin Change
  - Min coins, number of ways.  
- ğŸ’ 0/1 Knapsack
  - Classic state (i, weight).  

#### ğŸ“… Day 3 (Core) â€“ 2D DP: Grids & Edit Distance

**Topics & Subtopics:**
- ğŸ§© Grid DP
  - Unique paths; obstacles.  
- ğŸ”¤ Edit Distance
  - Insert/delete/replace operations.  
  - Matrix interpretation.  

#### ğŸ“… Day 4 (Core) â€“ DP on Sequences

**Topics & Subtopics:**
- ğŸ”— Longest Common Subsequence (LCS)
  - DP state and transitions.  
- ğŸ“ˆ Longest Increasing Subsequence (LIS)
  - O(nÂ²) DP and O(n log n) idea (high-level).  

#### ğŸ“… Day 5 (Optional Advanced) â€“ Story-Driven DP (MIT 6.006 Style)

**Topics & Subtopics:**
- ğŸ“„ Text Justification
  - Spaces, badness function, DP on word positions.  
- â™ ï¸ Blackjack-Style DP
  - States as (hand, dealerâ€™s shown card).  
- ğŸ¤¹ Interpreting DP States
  - How to choose meaningful states.  

---

### ğŸ§  Week 11 â€“ Dynamic Programming II: Trees, DAGs & Advanced Patterns

**Primary Goal:**  
Extend DP to trees, DAGs, subsets, and more advanced patterns.

**Why This Week Comes Here:**  
By now you can handle arrays & sequences; now extend to more complex structures.

**MIT Alignment:**  
- Advanced DP topics and tree/graph DP from 6.046.

#### ğŸ“… Day 1 (Core) â€“ DP on Trees

**Topics & Subtopics:**
- ğŸŒ³ Rooted Tree DP
  - Passing information up from children.  
- ğŸ§® Examples
  - Tree diameter via DP.  
  - Maximum independent set on trees.  

#### ğŸ“… Day 2 (Core) â€“ DP on DAGs

**Topics & Subtopics:**
- ğŸ§­ Topologically Sorted DP
  - Process vertices in topo order.  
- ğŸ“ˆ Longest Path in DAG
  - Relaxation along edges.  

#### ğŸ“… Day 3 (Core) â€“ Bitmask & Subset DP

**Topics & Subtopics:**
- ğŸ’ TSP-Style DP
  - State as (mask, last).  
- ğŸ§© Subset Selection DP
  - Counting/choosing subsets with constraints.  

#### ğŸ“… Day 4 (Optional Advanced) â€“ State Compression & Optimizations

**Topics & Subtopics:**
- ğŸ§Š Space Optimization
  - Rolling arrays; dimensionality reductions.  
- ğŸ” State Compression
  - Encoding multiple states into bit masks.  

#### ğŸ“… Day 5 (Optional Advanced) â€“ Mixed DP Problems

**Topics & Subtopics:**
- ğŸ§ª Multi-Concept DP
  - Problems combining arrays, graphs, and DP.  

---

## ğŸ”· Phase D â€“ Algorithm Paradigms (Weeks 12â€“13)

---

### ğŸ§© Week 12 â€“ Greedy Algorithms & Exchange Arguments

**Primary Goal:**  
Understand when greedy strategies are correct and how to justify them.

**Why This Week Comes Here:**  
By now you know DP; greedy provides contrast and alternative strategies.

**MIT Alignment:**  
- Greedy algorithms and exchange arguments from 6.006/6.046.

#### ğŸ“… Day 1 (Core) â€“ Greedy Basics

**Topics & Subtopics:**
- ğŸ¯ Greedy Choice Property
  - Locally optimal â†’ globally optimal conditions.  
- ğŸ§® Optimal Substructure
  - Comparison with DP.  

#### ğŸ“… Day 2 (Core) â€“ Interval Scheduling & Activity Selection

**Topics & Subtopics:**
- ğŸ“… Interval Scheduling
  - Sort by finish times; pick non-overlapping intervals.  
- ğŸ§ª Activity Selection
  - Equivalent formulations & proofs.  

#### ğŸ“… Day 3 (Core) â€“ MST as Greedy

**Topics & Subtopics:**
- ğŸŒ³ MST Revisited
  - Kruskal & Prim as greedy algorithms.  
- ğŸ§® Cut Property & Exchange Arguments
  - Why local choices give global optimum.  

#### ğŸ“… Day 4 (Optional Advanced) â€“ Huffman Coding & Other Greedy Constructions

**Topics & Subtopics:**
- ğŸ“¦ Huffman Coding
  - Building optimal prefix codes.  
  - Greedy tree construction using priority queue.  
- ğŸ§  Correctness Intuition
  - Exchange arguments for Huffman.  

#### ğŸ“… Day 5 (Optional Advanced) â€“ When Greedy Fails

**Topics & Subtopics:**
- ğŸš« Counterexamples
  - Problems where greedy is tempting but wrong.  
- ğŸ”„ Comparing DP vs Greedy
  - Choosing the right paradigm.  

---

### ğŸ§© Week 13 â€“ Advanced Graphs & Formal Amortized Analysis (6.046 Flavor)

**Primary Goal:**  
Introduce advanced graph techniques and formal amortized analysis methods.

**Why This Week Comes Here:**  
Youâ€™ve seen dynamic arrays, hash tables, and DSU; now formalize the â€œaverage costâ€ story.

**MIT Alignment:**  
- Amortized analysis methods from 6.046.

#### ğŸ“… Day 1 (Core) â€“ Advanced Graph Patterns

**Topics & Subtopics:**
- ğŸ”— Articulation Points & Bridges (Conceptual)
  - Definitions and use-cases.  
- ğŸ§­ 2-SAT via Graph Transformation (High-Level)
  - Clause implications and SCC-based approach (overview).  

#### ğŸ“… Day 2 (Core) â€“ Aggregate Method

**Topics & Subtopics:**
- ğŸ“Š Aggregate Method
  - Total cost of sequence / #operations.  
- ğŸª£ Dynamic Array Push
  - Sum-over-resizes argument.  
- ğŸ§± Stack with MultiPop
  - Show amortized O(1) per operation.  

#### ğŸ“… Day 3 (Core) â€“ Accounting Method

**Topics & Subtopics:**
- ğŸ’³ Amortized â€œCreditsâ€
  - Assigning abstract cost to operations.  
- ğŸ§® Examples
  - Dynamic array; stack with multi-pop.  

#### ğŸ“… Day 4 (Core) â€“ Potential Method

**Topics & Subtopics:**
- ğŸ”‹ Potential Function
  - Amortized cost = actual + Î”potential.  
- ğŸ§  Example
  - Dynamic array potential; high-level splay tree potential (conceptual).  

#### ğŸ“… Day 5 (Optional Advanced) â€“ Amortized Analysis in Advanced Structures

**Topics & Subtopics:**
- ğŸ§® DSU with Path Compression
  - Intuition behind inverse Ackermann bound.  
- ğŸŒ² Fibonacci Heaps (Concept-Level)
  - Why amortized analysis is crucial.  

---

## ğŸ”· Phase E â€“ Integration & Extensions (Weeks 14â€“15)

---

### ğŸ§± Week 14 â€“ Matrix Problems, Backtracking & Bit Tricks

**Primary Goal:**  
Integrate matrix patterns, backtracking, and bit manipulations.

**Why This Week Comes Here:**  
You now have enough DS and paradigms; time to mix them on matrices and combinatorial problems.

**MIT Alignment:**  
- Backtracking & search, bit tricks appear in advanced problem sets.

#### ğŸ“… Day 1 (Core) â€“ Matrix Traversal & Search

**Topics & Subtopics:**
- ğŸš¶ Standard Traversals
  - Row-wise, column-wise, diagonal.  
- ğŸ” Matrix Search Patterns
  - Searching sorted matrices (staircase search).  

#### ğŸ“… Day 2 (Core) â€“ Backtracking on Grids

**Topics & Subtopics:**
- ğŸ”¡ Word Search / Boggle
  - DFS + backtracking.  
- ğŸ”¢ Sudoku Solver (Conceptual)
  - Constraint checking & pruning.  

#### ğŸ“… Day 3 (Core) â€“ Bitmask Tricks

**Topics & Subtopics:**
- ğŸ”§ Basic Bit Ops
  - AND, OR, XOR, NOT, shifts.  
- ğŸ­ Masks
  - Representing subsets as bits.  
  - Iterating over submasks.  

#### ğŸ“… Day 4 (Optional Advanced) â€“ Number Theory & Modular Arithmetic

**Topics & Subtopics:**
- ğŸ”¢ Euclidâ€™s Algorithm
  - GCD & LCM.  
- ğŸ§® Modular Arithmetic
  - Modular addition/multiplication.  
  - Fast exponentiation (binary exponentiation).  

#### ğŸ“… Day 5 (Optional Advanced) â€“ Probability & Sampling

**Topics & Subtopics:**
- ğŸ² Expected Value & Linearity
  - Simple algorithmic examples.  
- ğŸ’§ Reservoir Sampling
  - Uniform sampling from streams.  

---

### ğŸ§µ Week 15 â€“ Advanced Strings & Network Flow

**Primary Goal:**  
Master advanced string algorithms and introduce max-flow/min-cut.

**Why This Week Comes Here:**  
Provides deeper tools for pattern matching and optimization problems.

**MIT Alignment:**  
- KMP, advanced string algorithms, and flow from 6.006/6.046.

#### ğŸ“… Day 1 (Core) â€“ KMP String Matching

**Topics & Subtopics:**
- ğŸ” Naive vs KMP
  - Why naive is O(nm).  
- ğŸ§µ Prefix / LPS Array
  - Longest proper prefix that is suffix.  
- ğŸ” KMP Matching Process
  - Avoiding re-checking characters.  

#### ğŸ“… Day 2 (Core) â€“ Z-Algorithm & Applications

**Topics & Subtopics:**
- ğŸ§µ Z-Function
  - Z[i] as length of prefix starting at i.  
- ğŸ§ª Applications
  - Pattern matching; string properties.  

#### ğŸ“… Day 3 (Core) â€“ Manacher & Palindromes (Optional / Core Depending on Track)

**Topics & Subtopics:**
- ğŸ” Manacherâ€™s Algorithm
  - O(n) longest palindromic substring.  

#### ğŸ“… Day 4 (Core) â€“ Suffix Arrays & Trees (Conceptual)

**Topics & Subtopics:**
- ğŸ“š Suffix Array
  - Sorted suffix indices.  
- ğŸŒ² Suffix Tree (High-Level)
  - Compressed trie of suffixes.  

#### ğŸ“… Day 5 (Optional Advanced) â€“ Max-Flow & Min-Cut

**Topics & Subtopics:**
- ğŸ’§ Flow Network Model
  - Nodes, edges, capacities.  
- ğŸ” Fordâ€“Fulkerson Method
  - Augmenting paths; residual graph.  
- ğŸš Edmondsâ€“Karp
  - BFS-based augmentation and O(VEÂ²).  
- âœ‚ï¸ Max-Flow Min-Cut Theorem
  - Intuitive statement and examples.  

#### ğŸ“… Day 6 (Optional Advanced) â€“ Matching via Flow

**Topics & Subtopics:**
- ğŸ­ Bipartite Matching
  - Building flow networks from bipartite graphs.  
- ğŸ§© Assignment Problems
  - Mapping tasks to resources.  

---

## ğŸ”· Phase F â€“ Advanced Deep Dives (Weeks 16â€“18, Optional Track)

---

### ğŸ§± Week 16 â€“ Segment Trees, BIT & Computational Geometry

**Primary Goal:**  
Introduce advanced DS for range queries and first geometry algorithms.

**MIT Alignment:**  
- Segment trees/BIT in 6.006; geometry and convex hull in 6.046.

#### ğŸ“… Day 1â€“3 (Core) â€“ Segment Trees & Fenwick Tree

**Topics & Subtopics:**
- ğŸŒ² Segment Trees
  - Range sum/min/max queries, point updates.  
  - Lazy propagation (intro).  
- ğŸŒ³ Fenwick/Binary Indexed Tree (BIT)
  - Representing prefix sums via bit operations.  

#### ğŸ“… Day 4 (Core) â€“ Matrix Exponentiation & Linear Recurrences

**Topics & Subtopics:**
- ğŸ” Recurrences as Matrices
  - Fibonacci via matrix exponentiation.  
- âš¡ Fast Matrix Power
  - Binary exponentiation on matrices.  

#### ğŸ“… Day 5 (Core) â€“ Geometry Foundations

**Topics & Subtopics:**
- ğŸ“ Points & Vectors
  - Coordinate representation.  
- âœ–ï¸ Dot & Cross Products
  - Orientation tests.  

#### ğŸ“… Day 6 (Optional Advanced) â€“ Convex Hull (Computational Geometry I)

**Topics & Subtopics:**
- ğŸ—» Convex Hull Problem
  - Outer boundary of point set.  
- âœ‚ï¸ Graham Scan
  - Sort by angle, maintain hull via stack.  
- ğŸ Jarvis March (Gift Wrapping)
  - Walking around hull points.  
- ğŸŒ Applications
  - Graphics, collision detection, geography.  

#### ğŸ“… Day 7 (Optional Advanced) â€“ Closest Pair & Line Sweep (Computational Geometry II)

**Topics & Subtopics:**
- ğŸ” Closest Pair of Points
  - Divide & conquer; O(n log n).  
- ğŸ“ Line Sweep Pattern
  - Event-based processing.  
  - Applications like segment intersection (conceptual).  

---

### ğŸ§  Week 17 â€“ Advanced Graphs, HLD, FFT & Advanced Strings

**Primary Goal:**  
Explore heavy-light decomposition, advanced string algorithms, and FFT.

**MIT Alignment:**  
- HLD-like decompositions and FFT appear in 6.046.

#### ğŸ“… Day 1â€“5 (Core) â€“ HLD & Advanced Strings

**Topics & Subtopics:**
- ğŸŒ² Heavy-Light Decomposition
  - Splitting tree paths into chains.  
- ğŸ§µ Advanced Automata
  - Ahoâ€“Corasick, suffix automaton (conceptual).  

#### ğŸ“… Day 6 (Optional Advanced) â€“ Fast Fourier Transform (FFT)

**Topics & Subtopics:**
- ğŸ”¢ Polynomial Multiplication
  - Naive O(nÂ²) vs convolution.  
- âš™ï¸ DFT & Roots of Unity (Intuitive)
  - Mapping time domain to frequency domain.  
- âœ‚ï¸ Cooleyâ€“Tukey Algorithm
  - Divide & conquer DFT; O(n log n).  
- ğŸŒ Applications
  - Signal processing, large integer multiplication.  

---

### ğŸ§ª Week 18 â€“ Probabilistic DS, Min-Cost Flow & System Design

**Primary Goal:**  
Explore probabilistic data structures, min-cost flow, and algorithmic system design.

**MIT Alignment:**  
- Probabilistic DS & flows in advanced lectures of 6.046.

**Topics & Subtopics (Core Days):**
- ğŸ² Bloom Filters, Count-Min Sketch, HyperLogLog.  
- ğŸšš Min-Cost Flow & Circulation (Concept-Level).  
- ğŸ—ï¸ Algorithmic System Design
  - Caching, sharding, indexing, ranking.  

**Optional Blocks:**
- Linear programming overview.  
- Cache-oblivious algorithms.  
- Distributed algorithms concepts.  

---

## ğŸ”· Phase G â€“ Mock Interviews & Final Review (Week 19)

---

### ğŸ¯ Week 19 â€“ Mixed Mock Interviews & Final Mastery

**Primary Goal:**  
Translate the entire curriculum into interview-ready, production-aware skill.

**Why This Week Comes Here:**  
Youâ€™ve built knowledge and intuition; this week focuses on application under pressure.

**Topics & Structure:**
- ğŸ§ª Mock Interview Sessions
  - Multi-problem sessions across arrays, trees, graphs, DP, strings, flows, geometry.  
- ğŸ©» Weak-Point Diagnosis
  - Analyze performance, identify shaky patterns.  
- ğŸ§­ Personal Review Plan
  - Map gaps to weeks/topics and design targeted practice.  
- ğŸ§µ System Integration Problems
  - Problems requiring combination of DS, patterns, and paradigms.  
- ğŸ§  Meta-Skills
  - Clarifying problem statements.  
  - Communicating thought process.  
  - Handling dead ends gracefully and pivoting.  

---

### âœ… MIT Coverage Summary

- **6.006 (Introduction to Algorithms):**  
  - RAM model, cost model, sorting, heaps, hashing, basic DP, BFS/DFS, shortest paths, basic flows, peak finding â€“ covered in Weeks 1â€“3, 4â€“6, 8â€“10, 15.  
- **6.046 (Design and Analysis of Algorithms):**  
  - Amortized analysis (aggregate, accounting, potential), advanced DP, greedy proofs, augmented BSTs, advanced graph algorithms, computational geometry, FFT, probabilistic DS, network flow variants â€“ covered in optional/advanced days in Weeks 7, 9, 11, 13, 15â€“18.  

**This v12 syllabus (12.1) keeps the 19-week structure, integrates all enhancements described, and marks MIT 6.006/6.046 depth via optional advanced days and enriched subtopics for each day.**