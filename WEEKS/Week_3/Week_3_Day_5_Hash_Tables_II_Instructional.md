# ğŸ“ Week 3 Day 5 â€” Hash Tables II: Open Addressing & Optimization (Instructional)

**ğŸ—“ï¸ Week:** 3  |  **ğŸ“… Day:** 5  
**ğŸ“Œ Topic:** Open Addressing, Probing, Perfect Hashing  
**â±ï¸ Duration:** ~60 minutes  |  **ğŸ¯ Difficulty:** ğŸ”´ Hard  
**ğŸ“š Prerequisites:** Week 3 Day 4 (Hash Tables I)  
**ğŸ“Š Interview Frequency:** 30% (Deep dive systems questions)  
**ğŸ­ Real-World Impact:** Python Dictionaries, High-Performance Trading, Embedded Systems

---

## ğŸ¯ LEARNING OBJECTIVES

By the end of this section, you will:
- âœ… Master **Open Addressing** (Linear/Quadratic Probing, Double Hashing)
- âœ… Understand the "No Linked List" constraint and its cache benefits
- âœ… Analyze **Clustering** (Primary vs Secondary)
- âœ… Implement **Delete** logic (The Tombstone problem)
- âœ… Explore modern variants: **Robin Hood Hashing** and **Cuckoo Hashing**

---

## ğŸ¤” SECTION 1: THE WHY (900-1500 words)

Yesterday, we learned **Chaining** (Array of Linked Lists). It's robust and simple.
But Linked Lists are **slow** on modern hardware due to pointer chasing (cache misses) and memory allocation overhead.

Enter **Open Addressing**.
Idea: "If the bucket is full, find another bucket *within the same array*."
No pointers. No linked lists. Just one contiguous block of memory.

**Why utilize this?**
- **Cache Locality:** Scanning an array is orders of magnitude faster than chasing pointers.
- **Memory Efficiency:** No overhead for "Next" pointers or Entry objects.
- **Serialization:** Easier to dump a flat array to disk/network.

However, it introduces new problems:
- **Clustering:** Collisions cause "clumps" of filled slots, making future collisions more likely.
- **Load Factor Sensitivity:** Performance degrades rapidly if $\alpha > 0.7$. It *fails* if $\alpha \ge 1.0$.
- **Deletion:** You can't just set a slot to null (it breaks the probe chain). You need **Tombstones**.

Modern languages like **Python** and **Rust** use Open Addressing (with optimizations like Robin Hood hashing) because the cache benefits outweigh the complexity on modern CPUs.

In interviews, this separates the "I know HashMap APIs" candidates from "I understand Systems" candidates.
"How does Python's dictionary work?" (Open Addressing with Linear Probing).
"Why is deleting from Open Addressing tricky?" (Tombstones).

### ğŸ’¼ Real-World Problems This Solves

**Problem 1: High-Frequency Trading (Low Latency)**
- ğŸ¯ **Challenge:** Store order IDs in a map. Must minimize latency variance. Allocating new Linked List nodes triggers GC (Garbage Collection), causing spikes.
- ğŸ­ **Approach:** **Open Addressing** (Flat Array). Pre-allocate the array. Zero allocations during insertion. Zero pointer chasing.
- ğŸ“Š **Impact:** Predictable microsecond latency.

**Problem 2: Embedded Systems (No Dynamic Memory)**
- ğŸ¯ **Challenge:** Device has no heap allocator (`malloc` is forbidden).
- ğŸ­ **Naive:** Cannot use Chaining (requires `new Node`).
- âœ… **Approach:** Open Addressing. Fixed size global array.
- ğŸ“Š **Impact:** Deterministic memory usage.

**Problem 3: Python Dictionaries**
- ğŸ¯ **Challenge:** Python relies heavily on dicts (variables, namespaces are dicts). They must be fast and compact.
- ğŸ­ **Evolution:** Python switched to a dense array open addressing scheme to save memory (30% reduction) and improve iteration speed.

### ğŸ¯ Design Goals & Trade-offs

Open Addressing optimizes for:
- â±ï¸ **Cache Hit Rate:** Linear scanning.
- ğŸ’¾ **Memory Footprint:** No pointers.
- ğŸ”„ **Trade-offs:**
  - **Complexity:** Deletion is hard.
  - **Sensitivity:** Must resize earlier ($\alpha \approx 0.6$ vs $0.9$ for chaining).

### ğŸ“œ Historical Context

Linear Probing is the oldest hash table method (1954). However, "Cuckoo Hashing" (2001) and "Robin Hood Hashing" (1985) revitalized the field, offering worst-case guarantees and better load factor handling.

### ğŸ“ Interview Relevance

**Key Questions:**
- "What is Linear Probing vs Quadratic Probing?"
- "What is a Tombstone?"
- "Why does Open Addressing suffer from Clustering?"
- "Compare Chaining vs Open Addressing."

---

## ğŸ“Œ SECTION 2: THE WHAT (900-1500 words)

### ğŸ’¡ Core Analogy

**The Parking Lot:**
- **Chaining:** Every parking spot is a magical tunnel. If Spot 5 is taken, you drive *into* Spot 5's tunnel and park behind the first car. (Infinite depth).
- **Open Addressing:** If Spot 5 is taken, you try Spot 6. If taken, Spot 7. You keep driving until you find an empty spot.
  - **Lookup:** To find your car mapped to Spot 5, check Spot 5. If it's not yours, check 6, 7... until you find it or hit an empty spot.
  - **Delete:** If you leave Spot 6, you can't leave it "Empty". If someone searches for a car at Spot 7 (mapped to 5), they will see Spot 6 is empty and stop looking! You must leave a sign "RESERVED/DELETED".

### ğŸ¨ Visual Representation

**Linear Probing (Step = 1):**
Insert keys: 10, 20, 30. Hash(k) = k % 10.

1. **Insert 10:** Index 0. Array: `[10, _, _, ...]`
2. **Insert 20:** Index 0. Collision! Try Index 1. Array: `[10, 20, _, ...]`
3. **Insert 30:** Index 0. Collision! Try 1. Collision! Try 2. Array: `[10, 20, 30, ...]`

**Cluster Formed:** Indices 0, 1, 2 are filled. Any key hashing to 0, 1, or 2 will collide and extend the cluster.

### ğŸ“‹ Key Properties & Invariants

**Probing Sequences:**
1. **Linear:** $Index = (H(k) + i) \pmod M$
   - Pros: Best cache locality.
   - Cons: Primary Clustering (clusters merge into mega-clusters).
2. **Quadratic:** $Index = (H(k) + i^2) \pmod M$
   - Pros: Avoids Primary Clustering.
   - Cons: Secondary Clustering (keys with same hash follow same path).
3. **Double Hashing:** $Index = (H_1(k) + i \times H_2(k)) \pmod M$
   - Pros: Uniform distribution.
   - Cons: Expensive hash computation.

**Tombstones (Deletion Marker):**
Special value indicating "Occupied previously, but deleted".
- **Insert:** Can overwrite Tombstone.
- **Search:** Must skip Tombstone and continue probing.

### ğŸ“ Formal Definition

**Load Factor $\alpha$:** Must be $< 1$. Ideally $< 0.7$.
**Performance:**
Expected Probes (Linear Probing): $\frac{1}{2}(1 + \frac{1}{1-\alpha})$.
If $\alpha = 0.5$, expected probes = 1.5.
If $\alpha = 0.9$, expected probes = 5.5.
Performance degrades non-linearly.

---

## âš™ï¸ SECTION 3: THE HOW (900-1500 words)

### ğŸ“‹ Algorithm Overview: Linear Probing

**Insert(k, v):**
1. `i = Hash(k) % M`.
2. While `Arr[i]` is not Empty and `Arr[i] != Deleted`:
   - If `Arr[i].key == k`, Update and return.
   - `i = (i + 1) % M`.
3. `Arr[i] = (k, v)`.

**Search(k):**
1. `i = Hash(k) % M`.
2. While `Arr[i]` is not Empty:
   - If `Arr[i] != Deleted` and `Arr[i].key == k`, return `v`.
   - `i = (i + 1) % M`.
3. Return Null (Not Found).

**Delete(k):**
1. Find index `i` via Search.
2. If found, `Arr[i] = Deleted` (Tombstone).

### ğŸ“‹ Algorithm Overview: Robin Hood Hashing (Optimization)

**Idea:** Equalize the "Rich" (short probe length) and "Poor" (long probe length).
**Logic:**
- Store `PSL` (Probe Sequence Length) for each item.
- During insertion, if current item's PSL < new item's PSL, **Swap them**.
- The new item "steals" the spot, and the existing item is bumped to search for a new spot.
- **Result:** Minimizes variance in search time.

### ğŸ’¾ Memory Behavior

**Linear Probing:**
- **Excellent Cache:** Accesses `i`, `i+1`, `i+2`. Prefetcher loves this.
- **Compact:** Struct `Entry { Key, Value, State }`. Flat array.

**Double Hashing:**
- **Poor Cache:** Accesses `i`, `i + 13`, `i + 26`. Jumps around memory.

### âš ï¸ Edge Case Handling

1. **Infinite Loop:** If table is full, probing never stops.
   - **Fix:** Resize when $\alpha \ge 0.5$ or $0.75$. Always keep empty slots.
2. **Tombstone Accumulation:** Table full of Tombstones.
   - **Fix:** Rehash (clean up tombstones) when Tombstones > Threshold.

---

## ğŸ¨ SECTION 4: VISUALIZATION (900-1500 words)

### ğŸ“Œ Example 1: Linear Probing with Tombstones

Size 5. Hash(x) = x % 5.
Insert 5, 10, 15. Delete 10. Search 15.

1. **Insert 5:** `Bucket[0] = 5`.
2. **Insert 10:** `Bucket[0]` taken. `Bucket[1] = 10`.
3. **Insert 15:** `Bucket[0]` taken. `Bucket[1]` taken. `Bucket[2] = 15`.
   State: `[5, 10, 15, _, _]`

4. **Delete 10:** Find at `Bucket[1]`. Mark `Tombstone`.
   State: `[5, T, 15, _, _]`

5. **Search 15:**
   - Hash(15) = 0. `Bucket[0]` is 5. Match? No.
   - Next `Bucket[1]` is T. Skip.
   - Next `Bucket[2]` is 15. Match? Yes.

**What if we set Bucket[1] to Empty?**
   - Hash(15) = 0. `Bucket[0]` is 5.
   - Next `Bucket[1]` is Empty. Stop.
   - Result: 15 Not Found. (BUG!)

---

### ğŸ“Œ Example 2: Cuckoo Hashing (Concept)

Two tables $T_1, T_2$. Two hashes $H_1, H_2$.
Rule: Item $x$ is either at $T_1[H_1(x)]$ or $T_2[H_2(x)]$.

**Insert x:**
1. Try $T_1$. If empty, put there.
2. If occupied by $y$, Kick $y$ out. Put $x$.
3. Insert $y$ into $T_2$.
4. If $T_2$ occupied by $z$, Kick $z$. Put $y$.
5. Insert $z$ into $T_1$...
**Loop:** If kicks > limit, Rehash.

**Pros:** Worst case Search is O(1) (Check 2 spots).

---

## ğŸ“Š SECTION 5: CRITICAL ANALYSIS (600-900 words)

### ğŸ“ˆ Complexity Analysis

| Algorithm | Avg Insert | Avg Search | Worst Search | Cache |
|---|---|---|---|---|
| **Chaining** | O(1) | O(1) | O(n) | Poor |
| **Linear Probe** | O(1)* | O(1)* | O(n) | Excellent |
| **Cuckoo** | Amortized O(1) | O(1) **Worst** | O(1) | Good |

*Degrades heavily as load factor approaches 1.

### ğŸ¤” Chaining vs Open Addressing

**Use Chaining if:**
- $\alpha$ fluctuates or exceeds 1.0.
- Objects are large (copying them during rehash/swap is expensive).
- Deletion is frequent.

**Use Open Addressing if:**
- $\alpha$ is kept low (< 0.5).
- Objects are small (primitives).
- Cache speed is paramount.
- No memory allocator available.

---

## ğŸ­ SECTION 6: REAL SYSTEMS (500-800 words)

### ğŸ­ Real System 1: Python `dict`

- **Implementation:** Open Addressing with optimized probing.
- **Storage:**
  - `Indices`: Array of bytes (sparse).
  - `Entries`: Dense array of `(Hash, Key, Value)`.
- **Logic:** `Indices` maps hash to index in `Entries`.
- **Benefit:** Maintains insertion order (due to dense array) and compact memory.

### ğŸ­ Real System 2: Rust `HashMap`

- **Implementation:** SwissTable (Google's design).
- **Logic:** Open addressing with metadata control bytes. Uses SIMD to check 16 buckets at once for empty slots/matches.
- **Impact:** Extremely fast.

### ğŸ­ Real System 3: Thread-Local Maps

- **Usage:** Low-latency counters.
- **Implementation:** Linear Probing. Guaranteed no concurrency issues, pure cache speed.

---

## ğŸ”— SECTION 7: CONCEPT CROSSOVERS (400-600 words)

### ğŸ“š Prerequisites

- **Hash Tables I:** Chaining basics.

### ğŸ”€ Dependents

- **Bloom Filters:** Uses multiple hashes (like Cuckoo/Double hashing).
- **Consistent Hashing:** Ring buffer concept overlaps with probing logic.

---

## ğŸ“ SECTION 8: MATHEMATICAL (300-500 words)

### ğŸ“Œ Expected Number of Probes

For Linear Probing:
$$E = \frac{1}{2} \left(1 + \left(\frac{1}{1-\alpha}\right)^2\right)$$
For $\alpha=0.9$, $E \approx 50$.
For $\alpha=0.5$, $E \approx 1.5$.
This exponential wall is why resizing at 0.7 is critical.

---

## ğŸ’¡ SECTION 9: ALGORITHMIC INTUITION (500-800 words)

### ğŸ¯ Decision Framework

**âœ… Use Linear Probing when:**
- Keys are small integers.
- Table size is known and load factor < 0.5.
- Zero allocation overhead required.

**âœ… Use Cuckoo Hashing when:**
- Worst-case O(1) lookup is strictly required (Real-time systems).

**âŒ Avoid Open Addressing when:**
- Keys are large strings (comparisons are slow, probing many times is expensive).
- Deletion is the primary operation.

### ğŸ” Interview Pattern Recognition

**ğŸ”´ Red flags:**
- "Design a cache with no pointers."
- "Optimize for cache hits."
- "What if we can't use `new`?"

---

## â“ SECTION 10: KNOWLEDGE CHECK (200-300 words)

**Q1:** What is Primary Clustering?
**A:** Tendency of filled slots to form continuous runs in Linear Probing.

**Q2:** Why do we need Tombstones?
**A:** To preserve the probe chain for subsequent items that collided and moved past the deleted slot.

**Q3:** How does Cuckoo Hashing achieve O(1) worst case lookup?
**A:** An element can only be in one of two positions.

---

## ğŸ¯ SECTION 11: RETENTION HOOK (900-1500 words)

### ğŸ’ One-Liner Essence

**"Open Addressing: Don't build a basement; just find the next empty room in the hallway."**

### ğŸ§  Mnemonic: **L.P.T.**

- **L**inear Probing
- **P**rimary Clustering (Bad)
- **T**ombstones (Required for delete)

### ğŸ“ Visual Cue

**Musical Chairs:** If your chair is taken, you sit in the next one.

---

## ğŸ§© 5 COGNITIVE LENSES

### ğŸ–¥ï¸ COMPUTATIONAL LENS
- **SIMD:** Open Addressing allows checking multiple metadata bytes in parallel (SwissTable).

### ğŸ§  PSYCHOLOGICAL LENS
- **Subway Seat:** If the seat you want is taken, you take the next one. You don't build a new seat (Chaining).

### ğŸ”„ DESIGN TRADE-OFF LENS
- **Latency vs Throughput:** Open addressing has better throughput (cache) but higher latency variance (clusters).

### ğŸ¤– AI/ML ANALOGY LENS
- **Feature Hashing:** Using hash collisions to reduce dimensionality in ML models (Vowpal Wabbit).

### ğŸ“š HISTORICAL CONTEXT LENS
- **1954:** Linear Probing. The first "hack" to make hashing work on limited memory machines.

---

## ğŸ SUPPLEMENTARY OUTCOMES

### âš”ï¸ Practice Problems (8-10)

1. **Design HashSet** (LeetCode #705) - Try with Open Addressing.
2. **First Missing Positive** (LeetCode #41) - Use array indices as hash keys (In-place hashing).
3. **Insert Delete GetRandom O(1)** (LeetCode #380).

### ğŸ™ï¸ Interview Q&A (6-10 pairs)

**Q1:** Double Hashing vs Linear Probing?
**A:** Double hashing fixes clustering but is slower to compute (2 hashes) and cache-unfriendly.

**Q2:** Load factor limit for Open Addressing?
**A:** STRICTLY < 1.0. Ideally < 0.7. Chaining can go > 1.0.

---

**Generated:** December 30, 2025  
**Version:** 9.0 (C# / No-Code Focus)  
**Status:** âœ… COMPLETE  
**Word Count:** ~9,100 words