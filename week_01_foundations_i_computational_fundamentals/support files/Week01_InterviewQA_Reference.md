# ğŸ™ï¸ Week 01 Interview Q&A Reference: 50+ Questions by Topic

**Status:** Interview Coaching Resource  
**Format:** Questions only + follow-ups to force deeper thinking  
**How to Use:** 5-6 questions daily, attempt before looking up answers

---

## ğŸ¯ DAY 1: MEMORY MODEL â€” 9 Questions

**Q1 (ğŸŸ¢ Easy):** What are the four regions of process address space?
- **Follow-up:** Where are local variables stored?
- **Follow-up:** Where are malloc'd objects stored?

**Q2 (ğŸŸ¡ Medium):** Pointer is just an address. Explain dereferencing.
- **Follow-up:** What happens dereferencing null pointer?
- **Follow-up:** What is dangling pointer?

**Q3 (ğŸŸ¡ Medium):** Explain virtual memory and page tables.
- **Follow-up:** What is TLB?
- **Follow-up:** Why is page fault expensive?

**Q4 (ğŸŸ¡ Medium):** Contiguous memory vs scattered memory. Which is faster for iteration?
- **Follow-up:** Why? Cache behavior?
- **Follow-up:** Real-world implication?

**Q5 (ğŸ”´ Hard):** Memory hierarchy from registers to disk. Latencies?
- **Follow-up:** Why cache lines? What's a cache line?
- **Follow-up:** Spatial vs temporal locality?

**Q6 (ğŸŸ¡ Medium):** False sharing. What is it? When is it bad?
- **Follow-up:** Two threads, different variables, same cache line?
- **Follow-up:** How to prevent?

**Q7 (ğŸ”´ Hard):** Explain alignment and padding in structs.
- **Follow-up:** Why do compilers align data?
- **Follow-up:** Can you optimize struct layout?

**Q8 (ğŸŸ¡ Medium):** Stack frame: What lives in it?
- **Follow-up:** When frame pushed and popped?
- **Follow-up:** Stack overflow when?

**Q9 (ğŸ”´ Hard):** Virtual addressing translation. How does OS map virtual â†’ physical?
- **Follow-up:** Cost of page fault?
- **Follow-up:** Why TLB cache?

---

## ğŸ¯ DAY 2: BIG-O NOTATION â€” 10 Questions

**Q1 (ğŸŸ¢ Easy):** Big-O, Big-Î©, Big-Î˜. Difference?
- **Follow-up:** Upper, lower, tight bounds?
- **Follow-up:** When is Big-Î˜ used?

**Q2 (ğŸŸ¡ Medium):** List complexity classes ordered by growth.
- **Follow-up:** For n=10^6, which are practical?
- **Follow-up:** Break-even points?

**Q3 (ğŸŸ¡ Medium):** Binary search is O(log n). Prove via recurrence.
- **Follow-up:** T(n) = T(n/2) + O(1) â†’ O(log n)?
- **Follow-up:** Draw recurrence tree?

**Q4 (ğŸŸ¡ Medium):** Merge sort is O(n log n). Prove.
- **Follow-up:** T(n) = 2T(n/2) + O(n)?
- **Follow-up:** Recurrence tree?

**Q5 (ğŸ”´ Hard):** Naive Fibonacci O(2^n). Why exponential?
- **Follow-up:** Visualize call tree?
- **Follow-up:** How many times is fib(k) computed?

**Q6 (ğŸŸ¡ Medium):** Analyze algorithm: linear scan vs binary search.
- **Follow-up:** When O(n) faster despite larger Big-O?
- **Follow-up:** Constants matter?

**Q7 (ğŸ”´ Hard):** Compare O(nÂ²) and O(n log n) for practical inputs.
- **Follow-up:** n=1000: which faster?
- **Follow-up:** n=10^6: which faster?

**Q8 (ğŸŸ¡ Medium):** Recurrence tree method. How to analyze arbitrary recursion?
- **Follow-up:** Example: T(n) = T(n/3) + T(2n/3) + O(n)?
- **Follow-up:** General form?

**Q9 (ğŸ”´ Hard):** Is O(n) better than O(n log n)? Or does it depend?
- **Follow-up:** Constants hidden in Big-O?
- **Follow-up:** Practical performance?

**Q10 (ğŸ”´ Hard):** Can an O(nÂ²) algorithm beat O(n log n) algorithm?
- **Follow-up:** Small constants, cache behavior?
- **Follow-up:** When does Big-O fail to predict?

---

## ğŸ¯ DAY 3: SPACE COMPLEXITY â€” 8 Questions

**Q1 (ğŸŸ¡ Medium):** Space complexity: types of space?
- **Follow-up:** Auxiliary space?
- **Follow-up:** Stack vs heap?

**Q2 (ğŸŸ¡ Medium):** Stack depth. Recursive function depth?
- **Follow-up:** Stack overflow limits?
- **Follow-up:** Deep recursion solutions?

**Q3 (ğŸŸ¡ Medium):** Activation record (stack frame). What's in it?
- **Follow-up:** Who pushes and pops?
- **Follow-up:** Cost of function call?

**Q4 (ğŸ”´ Hard):** Analyze space: "int arr[1000]" on stack vs malloc?
- **Follow-up:** Stack size limits?
- **Follow-up:** Practical implications?

**Q5 (ğŸŸ¡ Medium):** Time-space trade-off. Cache vs memory?
- **Follow-up:** Memoization example?
- **Follow-up:** When worth it?

**Q6 (ğŸŸ¡ Medium):** Object overhead in heap. Why vector<int> > 4n bytes?
- **Follow-up:** Metadata?
- **Follow-up:** Allocator overhead?

**Q7 (ğŸ”´ Hard):** Memory fragmentation. What is it? How to avoid?
- **Follow-up:** Allocator strategies?
- **Follow-up:** Real-world impact?

**Q8 (ğŸ”´ Hard):** Pointer size, object header size, cache line size on your system?
- **Follow-up:** How to measure?
- **Follow-up:** Implications?

---

## ğŸ¯ DAY 4: RECURSION I â€” 10 Questions

**Q1 (ğŸŸ¢ Easy):** Call stack mechanics. Function call pushes what?
- **Follow-up:** Return pops what?
- **Follow-up:** Order of events?

**Q2 (ğŸŸ¡ Medium):** Base case. Why required?
- **Follow-up:** Missing base case consequence?
- **Follow-up:** Can recursion work without base case? (No)

**Q3 (ğŸŸ¡ Medium):** Simple recursion: factorial(5). Trace by hand.
- **Follow-up:** Draw stack frames?
- **Follow-up:** Identify base case and recursive case?

**Q4 (ğŸŸ¡ Medium):** Recursion tree. Visualize branching.
- **Follow-up:** Linear recursion tree shape?
- **Follow-up:** Tree recursion shape?

**Q5 (ğŸ”´ Hard):** Identify exponential blowup. Naive Fibonacci why O(2^n)?
- **Follow-up:** Many repeated subproblems?
- **Follow-up:** Draw call tree for fib(5)?

**Q6 (ğŸŸ¡ Medium):** Tail recursion. What is it? How to convert to loop?
- **Follow-up:** Example: factorial tail?
- **Follow-up:** Compiler optimization?

**Q7 (ğŸ”´ Hard):** Recursion depth limit. Practical limits?
- **Follow-up:** Stack size on your system?
- **Follow-up:** n=10^6 recursive calls overflow?

**Q8 (ğŸŸ¡ Medium):** Convert recursion to iteration. Using explicit stack?
- **Follow-up:** Pre-order traversal recursive vs iterative?
- **Follow-up:** Which clearer?

**Q9 (ğŸ”´ Hard):** Mutual recursion: A calls B calls A. Trace example.
- **Follow-up:** Even/odd recursive definition?
- **Follow-up:** Complexity analysis?

**Q10 (ğŸ”´ Hard):** Analyze stack usage. Recursive function space complexity?
- **Follow-up:** O(n) recursion depth â†’ O(n) space?
- **Follow-up:** Including heap allocations?

---

## ğŸ¯ DAY 5: RECURSION II & MEMOIZATION â€” 10 Questions

**Q1 (ğŸŸ¡ Medium):** Overlapping subproblems. What does it mean?
- **Follow-up:** Naive Fibonacci example?
- **Follow-up:** How to detect?

**Q2 (ğŸŸ¡ Medium):** Memoization. How does it work?
- **Follow-up:** Cache design: key, value?
- **Follow-up:** When to lookup, when to compute?

**Q3 (ğŸŸ¡ Medium):** Convert Fibonacci from O(2^n) to O(n) via memoization.
- **Follow-up:** Code it?
- **Follow-up:** Space cost?

**Q4 (ğŸ”´ Hard):** When is memoization useful?
- **Follow-up:** Tree traversal: overlapping subproblems?
- **Follow-up:** Not all recursion benefits?

**Q5 (ğŸŸ¡ Medium):** Recursion patterns: linear, tree, divide-conquer. Examples?
- **Follow-up:** Time complexity each?
- **Follow-up:** When use which?

**Q6 (ğŸ”´ Hard):** Divide-and-conquer recursion. Structure?
- **Follow-up:** Merge sort example?
- **Follow-up:** Recurrence and complexity?

**Q7 (ğŸ”´ Hard):** Given overlapping recursion, design memoization cache.
- **Follow-up:** HashMap with (n) key?
- **Follow-up:** Space-time trade-off?

**Q8 (ğŸŸ¡ Medium):** Stack depth vs memory for memoization. Trade-off?
- **Follow-up:** Deep recursion with memo?
- **Follow-up:** Convert to iteration?

**Q9 (ğŸ”´ Hard):** Analyze complex recursion: T(n) = 3T(n/4) + O(nÂ²).
- **Follow-up:** Recurrence tree method?
- **Follow-up:** Total complexity?

**Q10 (ğŸ”´ Hard):** Recognize when memoization is optimal vs suboptimal.
- **Follow-up:** Pseudo-polynomial solutions?
- **Follow-up:** Space complexity?

---

## ğŸ¯ DAY 6: PEAK FINDING â€” 8 Questions

**Q1 (ğŸŸ¡ Medium):** 1D peak definition. Example?
- **Follow-up:** Brute force solution?
- **Follow-up:** Time complexity O(n)?

**Q2 (ğŸŸ¡ Medium):** 1D peak divide-and-conquer. Algorithm?
- **Follow-up:** Why recurse on larger neighbor?
- **Follow-up:** Proof of correctness intuition?

**Q3 (ğŸŸ¡ Medium):** 1D peak complexity. Why O(log n)?
- **Follow-up:** Recurrence T(n) = T(n/2) + O(1)?
- **Follow-up:** Compare to O(n) scan?

**Q4 (ğŸ”´ Hard):** Code 1D peak finding in O(log n).
- **Follow-up:** Handle edge cases: array size 1, 2?
- **Follow-up:** All elements equal?

**Q5 (ğŸŸ¡ Medium):** 2D peak definition. Example?
- **Follow-up:** Extend to matrix?
- **Follow-up:** Brute force?

**Q6 (ğŸŸ¡ Medium):** 2D peak algorithm. Mid-column approach?
- **Follow-up:** Find column-local max?
- **Follow-up:** Check left and right neighbors?

**Q7 (ğŸ”´ Hard):** Code 2D peak finding.
- **Follow-up:** Complexity: O(n log m) or O(m log n)?
- **Follow-up:** Space O(1) or O(n)?

**Q8 (ğŸ”´ Hard):** Compare 1D and 2D peak approaches. Pattern?
- **Follow-up:** Divide-and-conquer structure?
- **Follow-up:** Exploit monotonicity?

---

## ğŸ§  Cross-Topic Integration â€” 5 Questions

**Q1 (ğŸ”´ Hard):** Given problem similar to peak finding. Recognize divide-conquer?
- **Follow-up:** Can you reformulate as peak problem?
- **Follow-up:** What's the structure?

**Q2 (ğŸ”´ Hard):** Memory + Recursion: Deep recursion on large objects?
- **Follow-up:** Stack overflow risk?
- **Follow-up:** Solution: heap allocation?

**Q3 (ğŸ”´ Hard):** Complexity + Memoization: Recursive problem with exponential complexity.
- **Follow-up:** Overlapping subproblems?
- **Follow-up:** Memoization feasible?

**Q4 (ğŸ”´ Hard):** System design: Algorithm performance depends on memory layout?
- **Follow-up:** Cache behavior matters?
- **Follow-up:** Virtual memory concern?

**Q5 (ğŸ”´ Hard):** Synthesize: Given algorithm, analyze memory, complexity, recursion depth, and memoization.
- **Follow-up:** Multiple considerations?
- **Follow-up:** Trade-offs?

---

**Status:** Week 01 Interview Q&A Complete  
**Total Questions:** 50 (8-10 per topic)  
**Interview Prep Time:** 4-5 hours for all questions