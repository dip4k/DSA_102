# ğŸ“˜ WEEK 13: BACKTRACKING & BRANCH & BOUND
## Phase D: Algorithm Paradigms | 25 Hours | Search-Based Problem Solving

---

## ğŸ¯ WEEKLY GOAL

**Master backtracking for combinatorial problems and branch & bound for systematic optimization.**

By end of Week 13, you will:
- âœ… Understand backtracking concept and state space tree
- âœ… Design backtracking algorithms with pruning
- âœ… Solve N-queens, Sudoku, permutations, combinations
- âœ… Understand branch & bound optimization strategy
- âœ… Apply branch & bound to TSP and knapsack
- âœ… Master amortized analysis (all three methods)
- âœ… Know when to combine multiple paradigms

---

# ğŸ“… DAY 1: BACKTRACKING FUNDAMENTALS & STATE SPACE TREES
## 5 Hours | Topics: Concept, Template, Pruning Strategies

---

## ğŸ“ PART 1: WHAT IS BACKTRACKING? (90 minutes)

### Backtracking: The Core Idea

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            BACKTRACKING DEFINITION                   â”‚
â”‚                                                      â”‚
â”‚  Backtracking is a general problem-solving techniqueâ”‚
â”‚  that considers searching every possible combo:      â”‚
â”‚                                                      â”‚
â”‚  1. Build solution incrementally                     â”‚
â”‚  2. At each step, try all valid next choices        â”‚
â”‚  3. If choice leads nowhere (dead end):              â”‚
â”‚     BACKTRACK and try next choice                    â”‚
â”‚  4. If all choices lead nowhere: fail that branch    â”‚
â”‚  5. If reach complete solution: success!             â”‚
â”‚                                                      â”‚
â”‚  Key: Explores decision tree via DFS                â”‚
â”‚       Prunes branches that can't succeed             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Backtracking vs Brute Force

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    BACKTRACKING â‰  SIMPLE BRUTE FORCE                â”‚
â”‚                                                      â”‚
â”‚  Brute Force:                                        â”‚
â”‚  â€¢ Generate ALL possible solutions                   â”‚
â”‚  â€¢ Test each one                                     â”‚
â”‚  â€¢ Very slow: O(2â¿) or worse                         â”‚
â”‚  â€¢ No optimization                                   â”‚
â”‚  Example: Try all n! permutations                    â”‚
â”‚                                                      â”‚
â”‚  Backtracking:                                       â”‚
â”‚  â€¢ Generate solutions INTELLIGENTLY                  â”‚
â”‚  â€¢ Prune dead ends EARLY                             â”‚
â”‚  â€¢ Still exponential worst case, but MUCH faster     â”‚
â”‚  â€¢ Can solve larger problems                         â”‚
â”‚  Example: N-queens: prune based on attack positions â”‚
â”‚                                                      â”‚
â”‚  Key difference: PRUNING                             â”‚
â”‚  Backtracking asks: "Can this lead to solution?"     â”‚
â”‚  If NO â†’ stop exploring this branch                  â”‚
â”‚  If YES â†’ continue deeper                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Backtracking Template

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         UNIVERSAL BACKTRACKING TEMPLATE              â”‚
â”‚                                                      â”‚
â”‚  function backtrack(current_solution, state):        â”‚
â”‚    1. BASE CASE: Is current_solution complete?       â”‚
â”‚       If YES: record solution, return               â”‚
â”‚                                                      â”‚
â”‚    2. PRUNING: Can current_solution lead to valid?  â”‚
â”‚       If NO: prune this branch, return              â”‚
â”‚                                                      â”‚
â”‚    3. EXPLORE: For each valid next choice:          â”‚
â”‚       a. Add choice to solution                     â”‚
â”‚       b. Recursively backtrack with new state       â”‚
â”‚       c. Remove choice from solution (undo)         â”‚
â”‚                                                      â”‚
â”‚  Key aspects:                                        â”‚
â”‚  â€¢ Recursive structure (natural for exploration)     â”‚
â”‚  â€¢ Explicit backtracking (remove choice)             â”‚
â”‚  â€¢ Early pruning (avoid dead ends)                   â”‚
â”‚  â€¢ Base case (found solution or impossible)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why "Backtracking"?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       WHY THE NAME "BACKTRACKING"?                   â”‚
â”‚                                                      â”‚
â”‚  Visualization of search process:                    â”‚
â”‚                                                      â”‚
â”‚  Start at root of decision tree:
â”‚        â”Œâ”€ Root â”€â”
â”‚        â”‚ [ ]   â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚           / | \
â”‚          /  |  \
â”‚         /   |   \
â”‚      â”Œâ”€'  â”Œâ”€'  â”Œâ”€'
â”‚    Node1 Node2 Node3
â”‚      /     X    / \
â”‚     /           /   \
â”‚    [...]     Leaf   [...]
â”‚    
â”‚  Exploration process:
â”‚  1. Go deep: [ ] â†’ Node1 â†’ ...
â”‚  2. Hit dead end or find solution
â”‚  3. BACKTRACK: return to previous choice
â”‚  4. TRY NEXT: explore Node2
â”‚  5. SKIP: Node2 pruned (X)
â”‚  6. BACKTRACK again: try Node3
â”‚
â”‚  Like hiking in forest:
â”‚  â€¢ Go down trail (Node1, Node2, ...)
â”‚  â€¢ Hit dead end (cliff)
â”‚  â€¢ BACKTRACK to junction
â”‚  â€¢ Try different path
â”‚  â€¢ Mark failed paths to avoid retry
â”‚
â”‚  In code: UNDO the choice (remove from solution)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 2: STATE SPACE TREE (90 minutes)

### What is State Space Tree?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          STATE SPACE TREE CONCEPT                    â”‚
â”‚                                                      â”‚
â”‚  Definition: Tree representing all possible states   â”‚
â”‚  of solving a problem                                â”‚
â”‚                                                      â”‚
â”‚  Nodes: Partial solutions                            â”‚
â”‚  Edges: Decisions/choices                            â”‚
â”‚  Leaves: Complete solutions or dead ends             â”‚
â”‚                                                      â”‚
â”‚  Example: 3-Queens (place 3 queens on 3Ã—3 board)    â”‚
â”‚  State space tree for column-by-column placement:    â”‚
â”‚                                                      â”‚
â”‚         â”Œâ”€ Root â”€â”                                   â”‚
â”‚         â”‚ [] (no queens)                             â”‚
â”‚         â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚             |            |             |             â”‚
â”‚        â”Œâ”€â”€â”€â”€â”˜            |       â”Œâ”€â”€â”€â”€â”€â”˜             â”‚
â”‚        |                 |       |                    â”‚
â”‚    [Qâ‚ at         [Qâ‚ at     [Qâ‚ at                  â”‚
â”‚     row0]         row1]      row2]                   â”‚
â”‚       / \            |          / \                  â”‚
â”‚      /   \           |         /   \                 â”‚
â”‚  [Qâ‚,Qâ‚‚  [Qâ‚,Qâ‚‚  [Qâ‚,Qâ‚‚    [Qâ‚,Qâ‚‚ [Qâ‚,Qâ‚‚          â”‚
â”‚   rows   rows    rows       rows    rows              â”‚
â”‚   0,1]   0,2]    1,0]       1,2]    2,0]            â”‚
â”‚    X      âœ“       X         X       X (continue)     â”‚
â”‚   (Q's           (valid                              â”‚
â”‚    attack)      so far)                              â”‚
â”‚                                                      â”‚
â”‚  âœ“ = Valid partial solution (can continue)          â”‚
â”‚  X = Dead end (violates constraint)                 â”‚
â”‚  (continue) = Check next level                       â”‚
â”‚                                                      â”‚
â”‚  PRUNING: Don't explore X branches!                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual Example: Complete State Space for 3-Queens

```
If we only consider valid-so-far states:

                    â”Œâ”€ Root: [] â”€â”
                    â”‚ (0 queens)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
    [Q at 0]          [Q at 1]           [Q at 2]
        â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”              â”‚              â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚       â”‚              â”‚              â”‚       â”‚
[Q Q at  [Q Q at      [Q Q at       [Q Q at  [Q Q at
 00 12]   00 20]      01 10]       02 10]   02 20]
    â”‚       â”‚              â”‚              â”‚       â”‚
    X       âœ“              X              X       X
  (Qâ‚‚     (valid)      (Q's          (Q's     (Q's
 attacks)             attack)       attack)  attack)

Only continue from âœ“ states to depth 3:

[Q Q Q at:
 0 1 2] = three queens at rows 0,1,2 of columns 0,1,2
 
Check final state: valid or not?

Actually for 3-queens: NO valid solution exists
(too small board)

The state space tree shows this through exhaustive search!
```

### Node Classification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      STATE SPACE TREE NODE CLASSIFICATIONS          â”‚
â”‚                                                      â”‚
â”‚  Root Node:                                          â”‚
â”‚  â€¢ Empty solution [ ]                                â”‚
â”‚  â€¢ Starting point for backtracking                   â”‚
â”‚                                                      â”‚
â”‚  Internal Nodes:                                     â”‚
â”‚  â€¢ Partial solutions (some choices made)             â”‚
â”‚  â€¢ Can potentially lead to complete solution        â”‚
â”‚  â€¢ Need to explore further                           â”‚
â”‚                                                      â”‚
â”‚  Leaf Nodes:                                         â”‚
â”‚  â€¢ Option A: Complete solution (ALL choices made)   â”‚
â”‚    Example: All queens placed, valid config         â”‚
â”‚    ACCEPT: Record this solution                      â”‚
â”‚                                                      â”‚
â”‚  â€¢ Option B: Dead end (can't continue validly)      â”‚
â”‚    Example: Queen conflicts, no valid next move     â”‚
â”‚    REJECT: Prune (don't explore deeper)             â”‚
â”‚                                                      â”‚
â”‚  â€¢ Option C: Pruned node (violates early constraint)â”‚
â”‚    Example: Two queens already attacking            â”‚
â”‚    SKIP: Never add to frontier                      â”‚
â”‚                                                      â”‚
â”‚  Pruning = Avoiding exploring subtrees              â”‚
â”‚           under dead-end nodes!                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 3: PRUNING STRATEGIES (90 minutes)

### What is Pruning?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PRUNING DEFINITION                      â”‚
â”‚                                                      â”‚
â”‚  Pruning: Not exploring branches that can't         â”‚
â”‚           possibly lead to valid solutions           â”‚
â”‚                                                      â”‚
â”‚  Question: Why explore when we know it'll fail?     â”‚
â”‚  Answer: We don't always "know"... but we can GUESS â”‚
â”‚                                                      â”‚
â”‚  Pruning works if:                                   â”‚
â”‚  â€¢ Can quickly check: "Is this feasible?"            â”‚
â”‚  â€¢ If not feasible: all deeper choices also fail     â”‚
â”‚  â€¢ So we can skip entire subtree                     â”‚
â”‚                                                      â”‚
â”‚  Example: N-Queens                                   â”‚
â”‚  â€¢ If two queens attack each other NOW               â”‚
â”‚  â€¢ Then adding more queens WON'T fix it              â”‚
â”‚  â€¢ So we can prune this branch                       â”‚
â”‚                                                      â”‚
â”‚  Benefit: Exponentially fewer nodes explored!        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pruning Strategy 1: Constraint Checking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       PRUNING STRATEGY: CONSTRAINT CHECK             â”‚
â”‚                                                      â”‚
â”‚  At each step, verify constraints:                  â”‚
â”‚                                                      â”‚
â”‚  N-Queens Example:                                   â”‚
â”‚  â€¢ After placing queen i:                            â”‚
â”‚    - Check: Does it attack any previous queen?      â”‚
â”‚    - If YES: Violates constraint, PRUNE             â”‚
â”‚    - If NO: Can continue, explore deeper            â”‚
â”‚                                                      â”‚
â”‚  Sudoku Example:                                     â”‚
â”‚  â€¢ After placing digit d in cell (i,j):             â”‚
â”‚    - Check: Is d unique in row i?                    â”‚
â”‚    - Check: Is d unique in column j?                 â”‚
â”‚    - Check: Is d unique in 3Ã—3 box?                  â”‚
â”‚    - If any check fails: PRUNE                       â”‚
â”‚    - If all pass: Can continue                       â”‚
â”‚                                                      â”‚
â”‚  General pattern:                                    â”‚
â”‚                                                      â”‚
â”‚  if constraint_violated(current_state):             â”‚
â”‚      return  // Prune: don't explore subtree        â”‚
â”‚  else:                                               â”‚
â”‚      continue exploring                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pruning Strategy 2: Bound-Based Pruning

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      PRUNING STRATEGY: BOUNDING PRUNING             â”‚
â”‚                                                      â”‚
â”‚  Estimate: Can this path achieve goal?               â”‚
â”‚  How? Compute bound (upper/lower estimate)           â”‚
â”‚                                                      â”‚
â”‚  Optimization example: Maximize value               â”‚
â”‚  â€¢ Current partial solution value: 50               â”‚
â”‚  â€¢ Optimistic bound: +100 possible                  â”‚
â”‚  â€¢ Best we can get from this path: 150              â”‚
â”‚                                                      â”‚
â”‚  Compare with global best:                           â”‚
â”‚  â€¢ Global best achieved so far: 140                 â”‚
â”‚  â€¢ Our bound of 150 > 140: KEEP exploring          â”‚
â”‚                                                      â”‚
â”‚  But if:                                             â”‚
â”‚  â€¢ Global best: 200                                  â”‚
â”‚  â€¢ Our bound: 180                                    â”‚
â”‚  â€¢ Can't beat global best: PRUNE!                   â”‚
â”‚                                                      â”‚
â”‚  Key insight:                                        â”‚
â”‚  Even in best case, can't improve â†’ give up!         â”‚
â”‚                                                      â”‚
â”‚  Requires:                                           â”‚
â”‚  1. Ability to compute upper/lower bound             â”‚
â”‚  2. Track best solution found so far                â”‚
â”‚  3. Compare: if bound â‰¤ best, prune                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pruning Strategy 3: Monotonicity

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      PRUNING STRATEGY: MONOTONIC BOUNDS             â”‚
â”‚                                                      â”‚
â”‚  Observation: If property is monotonic decreasing,  â”‚
â”‚  we can prune early                                  â”‚
â”‚                                                      â”‚
â”‚  Example: Sudoku solving                             â”‚
â”‚  â€¢ Define: f(state) = number of empty cells         â”‚
â”‚  â€¢ Property: f always decreases as we fill cells    â”‚
â”‚  â€¢ If f(state) = 0: solved or invalid               â”‚
â”‚  â€¢ If f(state) = 81: completely full (check valid)  â”‚
â”‚                                                      â”‚
â”‚  Example: TSP                                        â”‚
â”‚  â€¢ Define: f(tour) = edges added so far             â”‚
â”‚  â€¢ Property: f always increases (tour grows)        â”‚
â”‚  â€¢ If f(tour) = n: complete tour (calculate cost)  â”‚
â”‚  â€¢ If f(tour) < n: partial tour                     â”‚
â”‚                                                      â”‚
â”‚  Monotonic property enables:                         â”‚
â”‚  â€¢ Predictable progress                              â”‚
â”‚  â€¢ Early termination conditions                      â”‚
â”‚  â€¢ Pruning based on state properties                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 1 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DAY 1: KEY TAKEAWAYS                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ Backtracking = incremental solution building     â”‚
â”‚  âœ“ Recurse deeply, backtrack when dead end          â”‚
â”‚  âœ“ Key: PRUNING makes it efficient                   â”‚
â”‚                                                      â”‚
â”‚  âœ“ STATE SPACE TREE represents all possibilities     â”‚
â”‚  âœ“ Nodes = partial solutions                         â”‚
â”‚  âœ“ Edges = choices/decisions                         â”‚
â”‚  âœ“ Leaves = complete solutions or dead ends          â”‚
â”‚                                                      â”‚
â”‚  âœ“ PRUNING STRATEGIES:                               â”‚
â”‚    1. Constraint checking (violates rule â†’ prune)    â”‚
â”‚    2. Bound-based (can't improve â†’ prune)            â”‚
â”‚    3. Monotonic properties (predictable progress)    â”‚
â”‚                                                      â”‚
â”‚  âœ“ Backtracking â‰  brute force (pruning is key!)      â”‚
â”‚  âœ“ Template: recurse, prune, explore, backtrack      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“… DAY 2: BACKTRACKING PROBLEMS - N-QUEENS & SUDOKU
## 5 Hours | Classic Problem Applications

---

## ğŸ“ PART 1: N-QUEENS PROBLEM (90 minutes)

### Problem Definition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            N-QUEENS PROBLEM                          â”‚
â”‚                                                      â”‚
â”‚  Given: nÃ—n chessboard                               â”‚
â”‚  Goal: Place n queens such that NO two attack each   â”‚
â”‚                                                      â”‚
â”‚  Queens attack: same row, column, or diagonal        â”‚
â”‚                                                      â”‚
â”‚  Example: 4-Queens board (one valid solution)        â”‚
â”‚                                                      â”‚
â”‚      Col: 0 1 2 3                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚  0 â”‚   Q   .   .   . â”‚                                â”‚
â”‚  1 â”‚   .   .   .   Q â”‚                                â”‚
â”‚  2 â”‚   Q   .   .   . â”‚  INVALID! Queens in            â”‚
â”‚  3 â”‚   .   .   Q   . â”‚  different columns            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     but let me try again:      â”‚
â”‚                                                      â”‚
â”‚      Col: 0 1 2 3                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚  0 â”‚   .   Q   .   . â”‚                                â”‚
â”‚  1 â”‚   .   .   .   Q â”‚                                â”‚
â”‚  2 â”‚   Q   .   .   . â”‚  VALID!                        â”‚
â”‚  3 â”‚   .   .   Q   . â”‚  No two queens                 â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   attack each other            â”‚
â”‚                                                      â”‚
â”‚  Note: Exactly one queen per row, per column         â”‚
â”‚        (by definition of placement)                  â”‚
â”‚        Only need to check DIAGONALS!                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Backtracking Solves N-Queens

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    N-QUEENS BACKTRACKING STRATEGY                    â”‚
â”‚                                                      â”‚
â”‚  Key insight: Place one queen per row                â”‚
â”‚  (automatically ensures row uniqueness)              â”‚
â”‚                                                      â”‚
â”‚  Decision point: Which COLUMN in each row?           â”‚
â”‚                                                      â”‚
â”‚  Algorithm:                                          â”‚
â”‚  1. Start at row 0                                   â”‚
â”‚  2. Try each column 0 to n-1 for queen in row 0     â”‚
â”‚  3. For each column c:                               â”‚
â”‚     a. Place queen at (row 0, column c)              â”‚
â”‚     b. Check: Is it safe? (not attacking prev)       â”‚
â”‚     c. If safe: Move to row 1 (recurse)              â”‚
â”‚     d. If unsafe: Try next column                    â”‚
â”‚  4. When reach row n: Found solution! Record it     â”‚
â”‚  5. Backtrack: try previous row's next column        â”‚
â”‚                                                      â”‚
â”‚  Pruning:                                            â”‚
â”‚  â€¢ Check diagonal conflicts with previous queens    â”‚
â”‚  â€¢ If conflict: don't even try this column          â”‚
â”‚  â€¢ Move to next column immediately                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual Example: Solving 4-Queens

```
State space exploration (showing only valid states):

                  â”Œâ”€ Row 0 â”€â”
                  â”‚ [ ]     â”‚
                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚             â”‚             â”‚
    Col 0         Col 1 âœ“       Col 2
    Queen         Queen         Invalid
   (valid)      (safe so far)   (diagonal)
         â”‚             â”‚             X
    â”Œâ”€ R1 â”€â”      â”Œâ”€ R1 â”€â”
    â”‚[Q..]â”‚      â”‚[.Q..]â”‚
    â””â”€â”€â”¬â”€â”€â”˜      â””â”€â”€â”¬â”€â”€â”˜
       â”‚             â”‚
   Col 0,1,2     Col 0,1,2,3
   (invalid)     ...
       X
   (conflict)
              â”‚
         â”Œâ”€ R2 â”€â”
         â”‚[.Q..]â”‚ at col 3 in R1
         â””â”€â”€â”¬â”€â”€â”˜
            â”‚
        Try cols...
            â”‚
        â”Œâ”€ R3 â”€â”
        â”‚[.Q.Q]â”‚ at col 3 in R1, col 0 in R3
        â””â”€â”€â”¬â”€â”€â”˜
           â”‚
       Check: Valid solution!
       Record: [.Q.Q] (actually [1,3,0,2] positions)

Continue: Backtrack from R3, try other configs...
```

### Diagonal Conflict Checking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      DIAGONAL CONFLICT IN N-QUEENS                   â”‚
â”‚                                                      â”‚
â”‚  Two queens attack diagonally if:                    â”‚
â”‚  |rowâ‚ - rowâ‚‚| = |colâ‚ - colâ‚‚|                      â”‚
â”‚  (same distance vertically and horizontally)         â”‚
â”‚                                                      â”‚
â”‚  Example:                                            â”‚
â”‚  Queen 1 at (0, 0)                                   â”‚
â”‚  Queen 2 at (2, 2)                                   â”‚
â”‚  |0-2| = 2, |0-2| = 2  â†’ Diagonal! Conflict!       â”‚
â”‚                                                      â”‚
â”‚  Queen 1 at (1, 1)                                   â”‚
â”‚  Queen 2 at (2, 2)                                   â”‚
â”‚  |1-2| = 1, |1-2| = 1  â†’ Diagonal! Conflict!       â”‚
â”‚                                                      â”‚
â”‚  But:                                                â”‚
â”‚  Queen 1 at (0, 0)                                   â”‚
â”‚  Queen 2 at (2, 1)                                   â”‚
â”‚  |0-2| = 2, |0-1| = 1  â†’ Not diagonal! Safe!       â”‚
â”‚                                                      â”‚
â”‚  Pruning condition:                                  â”‚
â”‚  For each previously placed queen at (r_prev, c_prev)â”‚
â”‚  and new queen candidate at (r_new, c_new):         â”‚
â”‚                                                      â”‚
â”‚  if |r_prev - r_new| = |c_prev - c_new|:            â”‚
â”‚      PRUNE (don't place queen here)                  â”‚
â”‚  else:                                               â”‚
â”‚      SAFE (can explore this subtree)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 2: SUDOKU SOLVER VIA BACKTRACKING (90 minutes)

### Sudoku Constraints Review

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SUDOKU CONSTRAINTS                          â”‚
â”‚                                                      â”‚
â”‚  Rules:                                              â”‚
â”‚  â€¢ 9Ã—9 grid divided into 3Ã—3 boxes                   â”‚
â”‚  â€¢ Fill with digits 1-9                              â”‚
â”‚  â€¢ Constraint 1: Each row has digits 1-9 (unique)   â”‚
â”‚  â€¢ Constraint 2: Each column has 1-9 (unique)       â”‚
â”‚  â€¢ Constraint 3: Each 3Ã—3 box has 1-9 (unique)      â”‚
â”‚                                                      â”‚
â”‚  Example cell (3, 4):                                â”‚
â”‚  â€¢ Row 3: can't repeat any digit in row 3           â”‚
â”‚  â€¢ Column 4: can't repeat any digit in column 4     â”‚
â”‚  â€¢ Box containing (3,4): 3Ã—3 box starting at...     â”‚
â”‚    Row: 3 // 3 * 3 = 3 (rows 3-5)                  â”‚
â”‚    Col: 4 // 3 * 3 = 3 (cols 3-5)                  â”‚
â”‚    So cell (3,4) in box starting at (3,3)          â”‚
â”‚                                                      â”‚
â”‚  Three constraints = high pruning potential!         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sudoku Backtracking Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    SUDOKU BACKTRACKING APPROACH                      â”‚
â”‚                                                      â”‚
â”‚  Key insight: Find empty cell, try digits 1-9       â”‚
â”‚                                                      â”‚
â”‚  Algorithm:                                          â”‚
â”‚  1. Find first empty cell (value = 0)                â”‚
â”‚  2. If no empty cell: Found solution! Return         â”‚
â”‚  3. For each digit d = 1 to 9:                       â”‚
â”‚     a. Check: Is d valid in this cell?              â”‚
â”‚        (not in row, column, or 3Ã—3 box)             â”‚
â”‚     b. If valid: Place d in cell (tentatively)       â”‚
â”‚     c. Recursively solve rest (backtrack call)       â”‚
â”‚     d. If recursive call succeeds: Return TRUE       â”‚
â”‚     e. If fails: Remove d (undo), try next digit    â”‚
â”‚  4. If no digit works: Return FALSE (dead end)       â”‚
â”‚                                                      â”‚
â”‚  Pruning:                                            â”‚
â”‚  â€¢ Before placing digit: check 3 constraints        â”‚
â”‚  â€¢ If ANY constraint violated: skip this digit      â”‚
â”‚  â€¢ Only place if ALL constraints satisfied          â”‚
â”‚                                                      â”‚
â”‚  Optimization opportunities:                        â”‚
â”‚  â€¢ Choose cell with minimum candidates first        â”‚
â”‚  â€¢ (most constrained variable heuristic)            â”‚
â”‚  â€¢ Prunes more aggressively                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sudoku Example: Partial Solution

```
Starting Sudoku (partially filled):

  5 3 _ | _ 7 _ | _ _ _
  6 _ _ | 1 9 5 | _ _ _
  _ 9 8 | _ _ _ | _ 6 _
  ------+-------+------
  8 _ _ | _ 6 _ | _ _ 3
  4 _ _ | 8 _ 3 | _ _ 1
  7 _ _ | _ 2 _ | _ _ 6
  ------+-------+------
  _ 6 _ | _ _ _ | 2 8 _
  _ _ _ | 4 1 9 | _ _ 5
  _ _ _ | _ 8 _ | _ 7 9

Backtracking process:

1. Find first empty cell: (0, 2) - can be 1,2,3,4,...
2. Check constraints for position (0,2):
   - Row 0: has 5,3,7 â†’ can't use these
   - Col 2: has 8 â†’ can't use this
   - Box (0,0): has 5,3,6,9,8 â†’ can't use these
   - Candidates: {1,2,4}
3. Try 1: place at (0,2), recurse â†’ fails (eventually)
4. Backtrack: remove 1, try 2 â†’ fails
5. Backtrack: remove 2, try 4 â†’ succeeds! Continue...

This exploration continues recursively until entire grid filled.
```

---

## ğŸ“ PART 3: OTHER BACKTRACKING PROBLEMS (90 minutes)

### Permutations and Combinations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    GENERATING PERMUTATIONS VIA BACKTRACKING          â”‚
â”‚                                                      â”‚
â”‚  Problem: Generate all permutations of {1,2,3}       â”‚
â”‚                                                      â”‚
â”‚  State space tree:                                   â”‚
â”‚         [Empty]                                      â”‚
â”‚         /  |  \                                      â”‚
â”‚        1   2   3                                     â”‚
â”‚       / \ / \ / \                                    â”‚
â”‚      2 3 1 3 1 2                                     â”‚
â”‚      |   |   |                                       â”‚
â”‚      3   3   2                                       â”‚
â”‚    [1,2,3] [2,1,3] [3,2,1] etc.                     â”‚
â”‚                                                      â”‚
â”‚  Backtracking approach:                              â”‚
â”‚  1. Start with empty sequence                        â”‚
â”‚  2. Track "used" set (which elements already picked) â”‚
â”‚  3. At each step: try each unused element           â”‚
â”‚  4. Add to sequence, mark as used                    â”‚
â”‚  5. Recurse (build longer permutation)               â”‚
â”‚  6. When sequence length = n: record solution       â”‚
â”‚  7. Backtrack: remove element, mark as unused       â”‚
â”‚                                                      â”‚
â”‚  Pruning: Natural (can't use same element twice)     â”‚
â”‚  No constraint checking needed!                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Combinations Generation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    GENERATING COMBINATIONS VIA BACKTRACKING          â”‚
â”‚                                                      â”‚
â”‚  Problem: Generate all 2-combinations of {1,2,3,4}   â”‚
â”‚  Result: {1,2}, {1,3}, {1,4}, {2,3}, {2,4}, {3,4}   â”‚
â”‚                                                      â”‚
â”‚  Difference from permutations:                       â”‚
â”‚  â€¢ Don't track "used" globally                       â”‚
â”‚  â€¢ Instead: only consider elements â‰¥ last picked    â”‚
â”‚  â€¢ Prevents duplicates (e.g., {1,2} vs {2,1})       â”‚
â”‚                                                      â”‚
â”‚  Backtracking approach:                              â”‚
â”‚  1. Start with empty sequence                        â”‚
â”‚  2. Track minimum element to consider (start = 1)    â”‚
â”‚  3. At each step: try each element â‰¥ minimum        â”‚
â”‚  4. Add to sequence                                  â”‚
â”‚  5. Recurse: with minimum = current element + 1     â”‚
â”‚  6. When sequence length = k: record solution       â”‚
â”‚  7. Backtrack: remove element                        â”‚
â”‚                                                      â”‚
â”‚  Example process:                                    â”‚
â”‚  Pick 1: min becomes 2                               â”‚
â”‚    Pick 2: sequence [1,2], record, backtrack        â”‚
â”‚    Pick 3: sequence [1,3], record, backtrack        â”‚
â”‚    Pick 4: sequence [1,4], record, backtrack        â”‚
â”‚  Backtrack from 1, pick 2: min becomes 3            â”‚
â”‚    Pick 3: sequence [2,3], record, backtrack        â”‚
â”‚    Pick 4: sequence [2,4], record, backtrack        â”‚
â”‚  Backtrack from 2, pick 3: min becomes 4            â”‚
â”‚    Pick 4: sequence [3,4], record, backtrack        â”‚
â”‚                                                      â”‚
â”‚  Result: {1,2}, {1,3}, {1,4}, {2,3}, {2,4}, {3,4}  â”‚
â”‚  No duplicates!                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Word Search in Grid

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      WORD SEARCH: BACKTRACKING APPROACH              â”‚
â”‚                                                      â”‚
â”‚  Problem: Find word "BACKTRACK" in 2D grid           â”‚
â”‚                                                      â”‚
â”‚  Grid:                                               â”‚
â”‚    B A X C D                                         â”‚
â”‚    K C K T O                                         â”‚
â”‚    A R O P A                                         â”‚
â”‚    C T E E R                                         â”‚
â”‚    T A K K C                                         â”‚
â”‚                                                      â”‚
â”‚  Goal: Find path spelling "BACKTRACK"                â”‚
â”‚  Path must be adjacent cells (not diagonal)          â”‚
â”‚                                                      â”‚
â”‚  Backtracking:                                       â”‚
â”‚  1. Start at any cell matching first letter (B)     â”‚
â”‚  2. For each neighbor: does it match next letter?   â”‚
â”‚  3. If yes: add to path, mark visited, recurse      â”‚
â”‚  4. If reach end of word: SUCCESS!                   â”‚
â”‚  5. Backtrack: unmark visited, try other neighbor   â”‚
â”‚  6. If no neighbors match: dead end, backtrack      â”‚
â”‚                                                      â”‚
â”‚  Path found:                                         â”‚
â”‚  B(0,0) â†’ A(0,1) â†’ C(1,1) â†’ K(1,0) â†’ T(4,0)        â”‚
â”‚  â†’ R(3,1) â†’ A(2,0) â†’ C(3,0) â†’ K(4,2)                â”‚
â”‚  = "BACKTRACK" âœ“                                     â”‚
â”‚                                                      â”‚
â”‚  Pruning: Track visited cells to avoid cycles       â”‚
â”‚           If next letter not available adjacent: skipâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 2 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DAY 2: KEY TAKEAWAYS                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ N-Queens: place one queen per row, check diagonalsâ”‚
â”‚  âœ“ Sudoku: find empty cell, try digits with constraintsâ”‚
â”‚  âœ“ Permutations: track used elements                 â”‚
â”‚  âœ“ Combinations: only consider elements â‰¥ last      â”‚
â”‚  âœ“ Word Search: find path in graph with DFS         â”‚
â”‚                                                      â”‚
â”‚  âœ“ All use same backtracking template:               â”‚
â”‚    1. Find choice point                              â”‚
â”‚    2. Try each option                                â”‚
â”‚    3. Recursively solve subproblem                   â”‚
â”‚    4. Backtrack if fails                             â”‚
â”‚    5. Try next option                                â”‚
â”‚                                                      â”‚
â”‚  âœ“ Key: Effective pruning makes it fast              â”‚
â”‚  âœ“ Pruning depends on problem constraints            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“… DAY 3: BRANCH & BOUND OPTIMIZATION
## 5 Hours | Systematic Optimization Strategy

---

## ğŸ“ PART 1: BRANCH & BOUND CONCEPT (90 minutes)

### What is Branch & Bound?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BRANCH & BOUND DEFINITION                    â”‚
â”‚                                                      â”‚
â”‚  Algorithm design technique for optimization        â”‚
â”‚  problems (maximization or minimization)             â”‚
â”‚                                                      â”‚
â”‚  Components:                                         â”‚
â”‚  â€¢ BRANCHING: Divide problem into subproblems       â”‚
â”‚  â€¢ BOUNDING: Compute upper/lower bounds on solutionsâ”‚
â”‚  â€¢ PRUNING: Eliminate branches that can't improve   â”‚
â”‚                                                      â”‚
â”‚  Process:                                            â”‚
â”‚  1. Branch: Systematically explore solution space   â”‚
â”‚     (similar to backtracking)                        â”‚
â”‚  2. Bound: Calculate best/worst case for each node  â”‚
â”‚  3. Prune: If bound can't beat current best,        â”‚
â”‚     don't explore subtree                            â”‚
â”‚                                                      â”‚
â”‚  Result: Optimal solution found FAST                 â”‚
â”‚          (prunes massive portions of search space)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Branch & Bound vs Backtracking

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BRANCH & BOUND vs BACKTRACKING                    â”‚
â”‚                                                      â”‚
â”‚  BACKTRACKING:                                       â”‚
â”‚  â€¢ Test FEASIBILITY: Is solution valid?              â”‚
â”‚  â€¢ Prune infeasible branches                         â”‚
â”‚  â€¢ Find ANY valid solution (or all solutions)        â”‚
â”‚  â€¢ Example: N-Queens (feasible = no attacks)         â”‚
â”‚                                                      â”‚
â”‚  BRANCH & BOUND:                                     â”‚
â”‚  â€¢ Test OPTIMALITY: Is solution better than best?    â”‚
â”‚  â€¢ Prune sub-optimal branches                        â”‚
â”‚  â€¢ Find OPTIMAL solution                             â”‚
â”‚  â€¢ Track best solution found so far                  â”‚
â”‚  â€¢ Example: TSP (optimal = shortest tour)            â”‚
â”‚                                                      â”‚
â”‚  Key difference:                                      â”‚
â”‚  Backtracking: "Is this valid?" â†’ feasibility       â”‚
â”‚  B&B: "Can this beat current best?" â†’ optimality    â”‚
â”‚                                                      â”‚
â”‚  Overlap: B&B can use feasibility pruning too!       â”‚
â”‚           But primary purpose is optimality          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The B&B Template

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    BRANCH & BOUND ALGORITHM TEMPLATE                 â”‚
â”‚                                                      â”‚
â”‚  function branchAndBound():                          â”‚
â”‚    best_solution = null                              â”‚
â”‚    best_value = -âˆ (for maximization)                â”‚
â”‚    frontier = [root_node]                            â”‚
â”‚                                                      â”‚
â”‚    while frontier not empty:                         â”‚
â”‚      node = frontier.pop()                           â”‚
â”‚                                                      â”‚
â”‚      # Bounding                                       â”‚
â”‚      upper_bound = compute_upper_bound(node)         â”‚
â”‚      if upper_bound â‰¤ best_value:                    â”‚
â”‚        continue  # Prune: can't improve              â”‚
â”‚                                                      â”‚
â”‚      # Check if complete solution                     â”‚
â”‚      if node is complete_solution:                   â”‚
â”‚        if value(node) > best_value:                  â”‚
â”‚          best_value = value(node)                    â”‚
â”‚          best_solution = node                        â”‚
â”‚      else:                                            â”‚
â”‚        # Branching: generate children                 â”‚
â”‚        for each child in expand(node):               â”‚
â”‚          frontier.add(child)                         â”‚
â”‚                                                      â”‚
â”‚    return best_solution                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 2: BOUNDING TECHNIQUES (90 minutes)

### Upper Bounds for Maximization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     UPPER BOUND: MAXIMIZATION PROBLEMS               â”‚
â”‚                                                      â”‚
â”‚  Goal: Find maximum value we could POSSIBLY achieve  â”‚
â”‚                                                      â”‚
â”‚  Strategy: Relax problem to something easier         â”‚
â”‚           Solve relaxed version (gives upper bound)  â”‚
â”‚                                                      â”‚
â”‚  Property: Relaxed value â‰¥ actual optimal value     â”‚
â”‚           (because we relaxed constraints)          â”‚
â”‚                                                      â”‚
â”‚  Knapsack Example:                                   â”‚
â”‚  â€¢ 0/1 Knapsack: must take whole item or nothing     â”‚
â”‚  â€¢ Fractional knapsack: can take fractions (relax)   â”‚
â”‚  â€¢ Fractional knapsack value â‰¥ 0/1 value            â”‚
â”‚  â€¢ So: fractional solution = upper bound for 0/1    â”‚
â”‚                                                      â”‚
â”‚  Usage in B&B:                                       â”‚
â”‚  if upper_bound(partial) â‰¤ current_best:             â”‚
â”‚      prune (can't find better even in best case)     â”‚
â”‚                                                      â”‚
â”‚  Example:                                            â”‚
â”‚  Current best: value 100                             â”‚
â”‚  Node's upper bound: 95                              â”‚
â”‚  Even if perfect luck, can only get 95 < 100        â”‚
â”‚  â†’ Prune this node                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Lower Bounds for Maximization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     LOWER BOUND: MAXIMIZATION PROBLEMS               â”‚
â”‚                                                      â”‚
â”‚  Goal: Find minimum value we know we can achieve     â”‚
â”‚                                                      â”‚
â”‚  Strategy: ANY feasible solution gives lower bound   â”‚
â”‚                                                      â”‚
â”‚  Property: Actual optimal â‰¥ lower bound              â”‚
â”‚           (because lower bound is feasible)         â”‚
â”‚                                                      â”‚
â”‚  Usage in B&B:                                       â”‚
â”‚  1. Initially: lower_bound = 0 (or first solution)   â”‚
â”‚  2. When find complete solution: might update lower  â”‚
â”‚     if value better than current best                â”‚
â”‚  3. Use lower bound to prune: discard nodes with     â”‚
â”‚     upper_bound < lower_bound                        â”‚
â”‚                                                      â”‚
â”‚  Example:                                            â”‚
â”‚  Lower bound (best found so far): 80                 â”‚
â”‚  Node's upper bound: 75                              â”‚
â”‚  Even in best case, can't beat lower â†’ Prune        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Computing Bounds: TSP Example

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       TSP BOUNDING: LOWER BOUND EXAMPLE              â”‚
â”‚                                                      â”‚
â”‚  Traveling Salesman Problem:                         â”‚
â”‚  â€¢ Visit all n cities exactly once                   â”‚
â”‚  â€¢ Return to start                                   â”‚
â”‚  â€¢ Minimize total distance                           â”‚
â”‚                                                      â”‚
â”‚  Lower bound technique: Minimum spanning tree        â”‚
â”‚                                                      â”‚
â”‚  Reasoning:                                          â”‚
â”‚  â€¢ Any tour connects all cities                      â”‚
â”‚  â€¢ Tour â‰¥ MST (MST is minimum to connect all)       â”‚
â”‚  â€¢ So: MST_cost â‰¤ optimal_tour_cost                  â”‚
â”‚  â€¢ Therefore: MST_cost is lower bound                â”‚
â”‚                                                      â”‚
â”‚  Better lower bound:                                 â”‚
â”‚  â€¢ MST has n-1 edges                                 â”‚
â”‚  â€¢ Tour has n edges                                  â”‚
â”‚  â€¢ MST_cost + min_edge_cost â‰¥ tour cost             â”‚
â”‚  â€¢ So: (MST_cost + min_edge_to_close) is tighter     â”‚
â”‚                                                      â”‚
â”‚  Upper bound: Any complete tour                      â”‚
â”‚  â€¢ Use greedy heuristic: nearest neighbor           â”‚
â”‚  â€¢ Find valid tour quickly                           â”‚
â”‚  â€¢ Greedy_tour â‰¥ optimal_tour (worst case)          â”‚
â”‚  â€¢ Use as upper bound for pruning                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 3: BEST-FIRST SEARCH & OPTIMIZATION (90 minutes)

### Best-First Search Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       BEST-FIRST SEARCH FOR B&B                      â”‚
â”‚                                                      â”‚
â”‚  Strategy: Explore most promising nodes first        â”‚
â”‚                                                      â”‚
â”‚  Queue: Priority queue (ordered by bounds)           â”‚
â”‚                                                      â”‚
â”‚  For maximization:                                   â”‚
â”‚  â€¢ Sort by upper_bound (descending)                  â”‚
â”‚  â€¢ Process highest upper_bound first                 â”‚
â”‚  â€¢ Rationale: most likely to find improvements       â”‚
â”‚                                                      â”‚
â”‚  Algorithm:                                          â”‚
â”‚  1. Initialize: frontier = [root]                    â”‚
â”‚  2. best_value = -âˆ                                  â”‚
â”‚  3. While frontier not empty:                        â”‚
â”‚     a. Pop node with highest bound                   â”‚
â”‚     b. If bound â‰¤ best_value: skip (prune)          â”‚
â”‚     c. If complete: update best_value                â”‚
â”‚     d. Else: add children with bounds to frontier    â”‚
â”‚  4. Return best solution found                       â”‚
â”‚                                                      â”‚
â”‚  Benefit: Often finds good solution early            â”‚
â”‚          Allows aggressive pruning later             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: 0/1 Knapsack with B&B

```
Knapsack capacity: 10 kg
Items:
  A: weight 5, value $50 (ratio 10)
  B: weight 6, value $60 (ratio 10)
  C: weight 2, value $15 (ratio 7.5)

Branch & Bound tree (simplified):

                [Root: no items]
                upper_bound = 100 (fractional)
                /            \
        Include A        Exclude A
        [A]:5kg,$50      []:0kg,$0
        bound:80          bound:75
         /        \       /      \
      Include B  Exclude B  Include B  Exclude B
      [A,B]:11   [A]:5,$50  [B]:6,$60   []:0
      INFEASIBLE  bound:60   bound:73
                  prune(60<80)  /    \
              Include C  Exclude C
              [B,C]:8    [B]:6,$60
              complete    bound:75
              $75 âœ“       (leaf)

Best found: [B,C] with value $75

Pruning saves exploring many nodes!
```

---

## ğŸ“‹ DAY 3 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DAY 3: KEY TAKEAWAYS                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ Branch & Bound = optimization via search + bounds â”‚
â”‚  âœ“ Branch: explore subproblems systematically        â”‚
â”‚  âœ“ Bound: compute upper/lower bound for each node   â”‚
â”‚  âœ“ Prune: if bound can't beat best, skip subtree     â”‚
â”‚                                                      â”‚
â”‚  âœ“ Upper bound (maximization):                       â”‚
â”‚    Relaxed problem, can't be beaten                  â”‚
â”‚  âœ“ Lower bound (maximization):                       â”‚
â”‚    Feasible solution, known to be achievable         â”‚
â”‚                                                      â”‚
â”‚  âœ“ Best-first search: explore promising nodes first  â”‚
â”‚  âœ“ Often finds good solution early                   â”‚
â”‚  âœ“ Enables aggressive pruning                        â”‚
â”‚                                                      â”‚
â”‚  âœ“ Key applications: TSP, 0/1 knapsack, assignment  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“… DAY 4: AMORTIZED ANALYSIS
## 5 Hours | Analyzing Cost Over Operations

---

## ğŸ“ PART 1: AMORTIZED COMPLEXITY CONCEPT (90 minutes)

### What is Amortized Analysis?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AMORTIZED ANALYSIS CONCEPT                   â”‚
â”‚                                                      â”‚
â”‚  Question: What's the typical cost of an operation? â”‚
â”‚           Not worst case for single operation        â”‚
â”‚           But average over sequence of operations    â”‚
â”‚                                                      â”‚
â”‚  Definition: Amortized cost = total cost / # ops    â”‚
â”‚                                                      â”‚
â”‚  Use case: Some ops expensive, many ops cheap      â”‚
â”‚           Single op might cost O(n)                  â”‚
â”‚           But over k ops, amortized might be O(1)   â”‚
â”‚                                                      â”‚
â”‚  Example: Dynamic array append                       â”‚
â”‚  â€¢ Array size: 1                                     â”‚
â”‚  â€¢ Append (size fits): O(1) â€“ 100 appends           â”‚
â”‚  â€¢ Append (array full): O(n) â€“ must resize          â”‚
â”‚                                                      â”‚
â”‚  Question: Average cost per append?                  â”‚
â”‚  Answer: Via amortized analysis!                     â”‚
â”‚                                                      â”‚
â”‚  Key insight:                                        â”‚
â”‚  Expensive operations (resize) happen rarely         â”‚
â”‚  Cheap operations (normal append) happen frequently  â”‚
â”‚  So average is heavily weighted toward cheap!        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Amortized Analysis Matters

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    WHY NOT JUST WORST-CASE ANALYSIS?                â”‚
â”‚                                                      â”‚
â”‚  Worst-case per operation:                           â”‚
â”‚  â€¢ Dynamic array append: O(n)                        â”‚
â”‚  â€¢ Binary search tree insert: O(n)                   â”‚
â”‚  â€¢ Splay tree operation: O(n)                        â”‚
â”‚  â€¢ Sounds terrible!                                  â”‚
â”‚                                                      â”‚
â”‚  But in practice:                                    â”‚
â”‚  â€¢ Most operations are fast!                         â”‚
â”‚  â€¢ Slow operations are rare                          â”‚
â”‚  â€¢ Amortized cost is much better                     â”‚
â”‚                                                      â”‚
â”‚  Example: Dynamic array                              â”‚
â”‚  â€¢ 1000 appends total                                â”‚
â”‚  â€¢ 999 at O(1)                                       â”‚
â”‚  â€¢ 1 resize at O(1000)                               â”‚
â”‚  â€¢ Total: 999 + 1000 = 1999 â‰ˆ O(1000)               â”‚
â”‚  â€¢ Average: 1999/1000 â‰ˆ O(2) â‰ˆ O(1) âœ“               â”‚
â”‚                                                      â”‚
â”‚  Conclusion: Worst-case misleads!                    â”‚
â”‚             Amortized gives realistic picture        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 2: AGGREGATE ANALYSIS METHOD (60 minutes)

### Aggregate Analysis Approach

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        AGGREGATE ANALYSIS METHOD                     â”‚
â”‚                                                      â”‚
â”‚  Technique: Calculate TOTAL cost for n operations    â”‚
â”‚            Divide by n for amortized cost            â”‚
â”‚                                                      â”‚
â”‚  Steps:                                              â”‚
â”‚  1. Analyze worst-case sequence of n operations      â”‚
â”‚  2. Compute total cost: T(n)                         â”‚
â”‚  3. Amortized cost = T(n) / n                        â”‚
â”‚                                                      â”‚
â”‚  Formula:                                            â”‚
â”‚  amortized_cost = total_cost_for_n_ops / n           â”‚
â”‚                                                      â”‚
â”‚  Example: Dynamic Array Doubling                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚                                                      â”‚
â”‚  Size progression: 1 â†’ 2 â†’ 4 â†’ 8 â†’ 16 â†’ ...         â”‚
â”‚                                                      â”‚
â”‚  Append operations:                                  â”‚
â”‚  â€¢ Elements 1-1: no resize (1 cheap op)              â”‚
â”‚  â€¢ Element 2: resize (2â†’4, costs 2)                  â”‚
â”‚  â€¢ Elements 3-4: no resize (2 cheap)                 â”‚
â”‚  â€¢ Element 5: resize (4â†’8, costs 4)                  â”‚
â”‚  â€¢ Elements 6-8: no resize (3 cheap)                 â”‚
â”‚  â€¢ Element 9: resize (8â†’16, costs 8)                 â”‚
â”‚                                                      â”‚
â”‚  Total cost for n appends:                           â”‚
â”‚  â€¢ Resizes happen at: 1, 2, 4, 8, ...                â”‚
â”‚  â€¢ Total resize cost: 1+2+4+...+2^k â‰ˆ 2*n           â”‚
â”‚  â€¢ Total append ops: n                               â”‚
â”‚  â€¢ Total cost: n (appends) + 2n (resizes) = 3n       â”‚
â”‚                                                      â”‚
â”‚  Amortized: 3n/n = O(3) = O(1) per operation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Aggregate Analysis Visualization

```
Operation costs over time:

Cost
  |
  |                    â”Œâ”€â”€â”€â”€â”€â”
  |                    â”‚ 8   â”‚
  |        â”Œâ”€â”€â”€â”       â”‚     â”‚
  |        â”‚ 4 â”‚       â”‚     â”‚
  |    â”Œâ”€â” â”‚   â”‚   â”Œâ”€â” â”‚     â”‚
  |    â”‚2â”‚ â”‚   â”‚   â”‚2â”‚ â”‚     â”‚
  |  1 â”‚ â”‚ â”‚   â”‚ 1 â”‚ â”‚ â”‚     â”‚ (resizes)
  | â”Œâ”€â”€â”´â”€â”´â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”´â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€ (cheap appends)
  |
Total cost: 1 + (2+2+2+2) + (4+4+4+4) + (8+8+...+8) + cheap_ops
         = sum of resizes + sum of cheap ops
         â‰ˆ 2n for total

So: amortized = 2n/n = O(1) per append
```

---

## ğŸ“ PART 3: ACCOUNTING AND POTENTIAL METHODS (90 minutes)

### Accounting Method

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ACCOUNTING METHOD                           â”‚
â”‚                                                      â”‚
â”‚  Idea: "Bank account" for future costs               â”‚
â”‚                                                      â”‚
â”‚  Setup:                                              â”‚
â”‚  â€¢ Assign amortized cost to each operation           â”‚
â”‚  â€¢ Some ops are "cheap" (use amortized cost)         â”‚
â”‚  â€¢ Some ops are "expensive" (also use amortized)     â”‚
â”‚  â€¢ When expensive op occurs:                         â”‚
â”‚    pay actual cost from account                      â”‚
â”‚  â€¢ If account never negative: amortized cost valid! â”‚
â”‚                                                      â”‚
â”‚  Dynamic Array Example:                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  Amortized cost per append: 3 units                  â”‚
â”‚                                                      â”‚
â”‚  â€¢ Cheap append: costs 1 unit actual                 â”‚
â”‚    Pay 3: contribute 2 to account                    â”‚
â”‚  â€¢ Resize: costs i units actual (i = old size)      â”‚
â”‚    Pay 3: need 3 â‰¥ i? No! But account has balance   â”‚
â”‚    Accumulated balance from previous appends         â”‚
â”‚    Pay from balance                                  â”‚
â”‚                                                      â”‚
â”‚  Detailed trace (capacity starts at 1):              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚                                                      â”‚
â”‚  Op 1 (append, sizeâ†’2): actual=2, pay=3, balance=1 â”‚
â”‚  Op 2 (append): actual=1, pay=3, balance=1+3-1=3   â”‚
â”‚  Op 3 (resize, 2â†’4): actual=2, pay=3, balance=3+3-2â”‚
â”‚  Op 4 (append): actual=1, pay=3, balance=3+3-1=5   â”‚
â”‚  Op 5 (append): actual=1, pay=3, balance=5+3-1=7   â”‚
â”‚  ...                                                 â”‚
â”‚                                                      â”‚
â”‚  Balance never goes negative! âœ“                      â”‚
â”‚  So amortized cost of 3 per operation is valid!     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Potential Method

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          POTENTIAL METHOD                            â”‚
â”‚                                                      â”‚
â”‚  Idea: Define "potential" function on data structure â”‚
â”‚        Measure "disorder" or "unfinished work"        â”‚
â”‚                                                      â”‚
â”‚  Formula:                                            â”‚
â”‚  amortized_cost_i = actual_cost_i +                 â”‚
â”‚                     Î”_potential                       â”‚
â”‚                                                      â”‚
â”‚  Where Î”_potential = potential_after - potential_beforeâ”‚
â”‚                                                      â”‚
â”‚  Proof technique:                                    â”‚
â”‚  1. Define potential function Î¦                      â”‚
â”‚  2. Show Î¦(initial) = 0                              â”‚
â”‚  3. Show Î¦(final) â‰¥ 0                                â”‚
â”‚  4. Sum amortized costs:                             â”‚
â”‚     Î£ amortized = Î£ actual + Î£ Î”_potential          â”‚
â”‚                 = Î£ actual + (Î¦_final - Î¦_initial)  â”‚
â”‚                 = Î£ actual + (Î¦_final - 0)          â”‚
â”‚                 â‰¥ Î£ actual                           â”‚
â”‚  5. So amortized upper bounds actual                 â”‚
â”‚                                                      â”‚
â”‚  Example: Dynamic Array                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  Potential = number_of_filled_spaces                 â”‚
â”‚  (excess capacity relative to "ideal")               â”‚
â”‚                                                      â”‚
â”‚  Ï† = num_elements - (current_capacity/2)             â”‚
â”‚                                                      â”‚
â”‚  Normal append (no resize):                          â”‚
â”‚  â€¢ actual_cost = 1 (copy element)                    â”‚
â”‚  â€¢ Ï†_before = n - (2n/2) = 0                         â”‚
â”‚  â€¢ Ï†_after = (n+1) - (2n/2) = 1                      â”‚
â”‚  â€¢ Î”Ï† = 1                                             â”‚
â”‚  â€¢ amortized = 1 + 1 = 2                             â”‚
â”‚                                                      â”‚
â”‚  Resize (when full):                                 â”‚
â”‚  â€¢ actual_cost = n (copy all elements)               â”‚
â”‚  â€¢ Ï†_before = n - (n/2) = n/2                        â”‚
â”‚  â€¢ Ï†_after = n - (2n/2) = 0 (capacity doubles!)     â”‚
â”‚  â€¢ Î”Ï† = 0 - n/2 = -n/2                               â”‚
â”‚  â€¢ amortized = n - n/2 = n/2                         â”‚
â”‚                                                      â”‚
â”‚  For n+1 operations: total â‰ˆ 2n, amortized = 2      â”‚
â”‚  (similar to aggregate analysis)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 4: ADVANCED AMORTIZED ANALYSIS (60 minutes)

### Splay Trees: Complex Amortized Analysis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SPLAY TREES: O(log n) AMORTIZED OPERATIONS        â”‚
â”‚                                                      â”‚
â”‚  What are splay trees?                               â”‚
â”‚  â€¢ Binary search trees that reorganize on access    â”‚
â”‚  â€¢ Move accessed element to root (splay)             â”‚
â”‚  â€¢ Single operation: O(n) worst case                 â”‚
â”‚  â€¢ But: O(log n) amortized per operation!            â”‚
â”‚                                                      â”‚
â”‚  Why amortized O(log n)?                             â”‚
â”‚  â€¢ Potential function: Î£ log(subtree_size)           â”‚
â”‚  â€¢ When splay: reorganize tree structure             â”‚
â”‚  â€¢ Zigzag rotations decrease potential               â”‚
â”‚  â€¢ Amortized cost bounded despite expensive rotationsâ”‚
â”‚                                                      â”‚
â”‚  Key insight:                                        â”‚
â”‚  â€¢ Expensive operations improve tree balance        â”‚
â”‚  â€¢ Future operations benefit from improved balance  â”‚
â”‚  â€¢ Cost spread across sequence of operations        â”‚
â”‚  â€¢ Amortized analysis captures this!                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fibonacci Heaps: Amortized Operations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FIBONACCI HEAPS: AMORTIZED OPERATIONS              â”‚
â”‚                                                      â”‚
â”‚  Fibonacci heaps achieve:                            â”‚
â”‚  â€¢ Extract-min: O(log n) amortized                   â”‚
â”‚  â€¢ Insert: O(1) amortized                            â”‚
â”‚  â€¢ Decrease-key: O(1) amortized                      â”‚
â”‚  â€¢ Delete: O(log n) amortized                        â”‚
â”‚                                                      â”‚
â”‚  How?                                                â”‚
â”‚  â€¢ Lazy merging: delay consolidation                 â”‚
â”‚  â€¢ Cascading cuts: mark nodes, cut when needed       â”‚
â”‚  â€¢ Potential function captures "work owed"           â”‚
â”‚  â€¢ Amortized analysis proves efficiency              â”‚
â”‚                                                      â”‚
â”‚  Without amortized analysis:                         â”‚
â”‚  â€¢ Worst-case operations look terrible!              â”‚
â”‚  â€¢ Insert seems cheap but cascading cuts cost O(n)  â”‚
â”‚  â€¢ Delete seems expensive                            â”‚
â”‚                                                      â”‚
â”‚  With amortized analysis:                            â”‚
â”‚  â€¢ Operations are O(1) or O(log n)                   â”‚
â”‚  â€¢ Used in Dijkstra's, Prim's for MST               â”‚
â”‚  â€¢ Among the most efficient heaps                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 4 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DAY 4: KEY TAKEAWAYS                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ Amortized analysis = average cost per operation   â”‚
â”‚  âœ“ Over sequence of operations (not single op)       â”‚
â”‚  âœ“ Some ops expensive, many cheap                    â”‚
â”‚                                                      â”‚
â”‚  âœ“ THREE METHODS:                                    â”‚
â”‚    1. Aggregate: T(n)/n = amortized cost             â”‚
â”‚    2. Accounting: bank account model                 â”‚
â”‚    3. Potential: define Î¦, track changes             â”‚
â”‚                                                      â”‚
â”‚  âœ“ Dynamic array: O(1) amortized per append          â”‚
â”‚  âœ“ Splay trees: O(log n) amortized                   â”‚
â”‚  âœ“ Fibonacci heaps: O(1) insert, O(log n) delete     â”‚
â”‚                                                      â”‚
â”‚  âœ“ Key insight: Expensive ops improve future ops    â”‚
â”‚  âœ“ Cost naturally spreads across sequence            â”‚
â”‚  âœ“ Amortized analysis captures this reality!         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“… DAY 5: INTEGRATION & MIXED PARADIGMS
## 5 Hours | Combining Techniques and Synthesis

---

## ğŸ“ PART 1: PARADIGM SELECTION GUIDE (90 minutes)

### Decision Tree: Which Paradigm?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       ALGORITHM PARADIGM SELECTION GUIDE               â”‚
â”‚                                                        â”‚
â”‚  Question 1: Can we make greedy choice?                â”‚
â”‚  â””â”€â†’ YES: Try greedy                                   â”‚
â”‚      â””â”€ Provable choice property? â†’ GREEDY WORKS      â”‚
â”‚      â””â”€ No proof? â†’ Try DP or backtracking             â”‚
â”‚  â””â”€â†’ NO: Continue to Q2                                â”‚
â”‚                                                        â”‚
â”‚  Question 2: Does problem have optimal substructure?   â”‚
â”‚  â””â”€â†’ YES: Consider DP                                  â”‚
â”‚      â””â”€ Overlapping subproblems? â†’ DP OPTIMAL         â”‚
â”‚      â””â”€ No overlap? â†’ Maybe greedy/divide-conquer     â”‚
â”‚  â””â”€â†’ NO: Continue to Q3                                â”‚
â”‚                                                        â”‚
â”‚  Question 3: Need ALL solutions (or find ALL)?         â”‚
â”‚  â””â”€â†’ YES: Consider backtracking                        â”‚
â”‚      â””â”€ Constraints high? â†’ Backtrack (with pruning)  â”‚
â”‚      â””â”€ Constraints low? â†’ Brute force enumeration    â”‚
â”‚  â””â”€â†’ NO: Continue to Q4                                â”‚
â”‚                                                        â”‚
â”‚  Question 4: Need OPTIMAL solution (minimize/maximize)â”‚
â”‚  â””â”€â†’ YES: Consider B&B                                â”‚
â”‚      â””â”€ Can compute bounds? â†’ Branch & Bound         â”‚
â”‚      â””â”€ No bounds? â†’ Backtracking (find all, pick best)â”‚
â”‚  â””â”€â†’ NO: Continue to Q5                                â”‚
â”‚                                                        â”‚
â”‚  Question 5: Problem breaks into independent parts?    â”‚
â”‚  â””â”€â†’ YES: Consider divide-conquer                      â”‚
â”‚      â””â”€ Can solve parts independently? â†’ DC WORKS    â”‚
â”‚  â””â”€â†’ NO: Problem solved! Use heuristic/approximation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Problem Type Classification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     PROBLEM CLASSIFICATION & ALGORITHM CHOICE        â”‚
â”‚                                                      â”‚
â”‚  Search & Enumeration Problems:                      â”‚
â”‚  â€¢ All permutations/combinations                     â”‚
â”‚  â€¢ All valid configurations (N-queens)               â”‚
â”‚  â†’ Backtracking with good pruning                    â”‚
â”‚                                                      â”‚
â”‚  Optimization Problems (one solution):               â”‚
â”‚  â€¢ Shortest path                                     â”‚
â”‚  â€¢ Minimum spanning tree                             â”‚
â”‚  â€¢ Knapsack variants                                 â”‚
â”‚  â†’ Try greedy first                                  â”‚
â”‚  â†’ If fails: DP or B&B                               â”‚
â”‚                                                      â”‚
â”‚  Path-Finding Problems:                              â”‚
â”‚  â€¢ Sudoku solver                                     â”‚
â”‚  â€¢ Maze solving                                      â”‚
â”‚  â€¢ Constraint satisfaction                          â”‚
â”‚  â†’ Backtracking with constraint pruning              â”‚
â”‚                                                      â”‚
â”‚  Combinatorial Optimization:                         â”‚
â”‚  â€¢ TSP (find best tour)                              â”‚
â”‚  â€¢ Weighted knapsack                                 â”‚
â”‚  â€¢ Job scheduling with weights                       â”‚
â”‚  â†’ Dynamic programming or B&B                        â”‚
â”‚                                                      â”‚
â”‚  Interval/Sequence Problems:                         â”‚
â”‚  â€¢ Activity selection                                â”‚
â”‚  â€¢ LCS, LIS                                          â”‚
â”‚  â€¢ Huffman coding                                    â”‚
â”‚  â†’ Greedy (if structure permits) or DP              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 2: COMBINING PARADIGMS (90 minutes)

### Greedy + Backtracking: Intelligent Search

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COMBINING GREEDY + BACKTRACKING                    â”‚
â”‚                                                      â”‚
â”‚  Use case: Backtracking but want to try promising    â”‚
â”‚           branches first                             â”‚
â”‚                                                      â”‚
â”‚  Strategy:                                           â”‚
â”‚  1. At each choice point: order options by greedy    â”‚
â”‚     heuristic (most promising first)                 â”‚
â”‚  2. Try options in that order (backtrack if needed)  â”‚
â”‚  3. Often finds solution much faster                 â”‚
â”‚                                                      â”‚
â”‚  Example: Sudoku solving                             â”‚
â”‚  â€¢ Backtracking: try each digit 1-9 randomly        â”‚
â”‚  â€¢ Smart: try digits that appear least in row/col   â”‚
â”‚  â€¢ Greedy heuristic + backtrack = faster             â”‚
â”‚                                                      â”‚
â”‚  Example: N-Queens                                   â”‚
â”‚  â€¢ Backtracking: try each column 0-n                â”‚
â”‚  â€¢ Smart: prioritize columns with fewer conflicts   â”‚
â”‚  â€¢ Result: find solution faster                      â”‚
â”‚                                                      â”‚
â”‚  Key insight:                                        â”‚
â”‚  â€¢ Greedy chooses order of exploration               â”‚
â”‚  â€¢ Backtracking ensures correctness (can retry)      â”‚
â”‚  â€¢ Together: fast AND complete                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dynamic Programming + Greedy: Hybrid Optimization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COMBINING DP + GREEDY                              â”‚
â”‚                                                      â”‚
â”‚  Use case: Top-level greedy, subproblems DP          â”‚
â”‚                                                      â”‚
â”‚  Strategy:                                           â”‚
â”‚  1. Make greedy choice at highest level              â”‚
â”‚  2. Subproblem might not have greedy structure       â”‚
â”‚  3. Solve subproblem via DP                          â”‚
â”‚  4. Combine: greedy_choice + DP_solution             â”‚
â”‚                                                      â”‚
â”‚  Example: Weighted activity selection                â”‚
â”‚  â€¢ Greedy by finish time: doesn't work (weighted)    â”‚
â”‚  â€¢ Top-level greedy: decide to include activity i    â”‚
â”‚  â€¢ Subproblem DP: max value in activities before i   â”‚
â”‚  â€¢ Result: optimal weighted solution                 â”‚
â”‚                                                      â”‚
â”‚  Example: Interval scheduling with costs            â”‚
â”‚  â€¢ Greedy: select maximum profit non-overlapping     â”‚
â”‚  â€¢ For each selection: DP on remaining intervals     â”‚
â”‚  â€¢ Together: optimal sequence with profit            â”‚
â”‚                                                      â”‚
â”‚  Key insight:                                        â”‚
â”‚  â€¢ Greedy at top level for efficiency                â”‚
â”‚  â€¢ DP for subproblem complexity                      â”‚
â”‚  â€¢ Often beats pure DP (faster)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Branch & Bound + Greedy Heuristics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COMBINING B&B + GREEDY HEURISTICS                  â”‚
â”‚                                                      â”‚
â”‚  Use case: B&B needs upper/lower bounds              â”‚
â”‚           Greedy provides quick heuristic bounds     â”‚
â”‚                                                      â”‚
â”‚  Strategy:                                           â”‚
â”‚  1. Use greedy to find quick initial solution        â”‚
â”‚  2. Use greedy value as lower/upper bound            â”‚
â”‚  3. B&B prunes more aggressively with tighter bounds â”‚
â”‚  4. B&B finds optimal (by exploring remaining)       â”‚
â”‚                                                      â”‚
â”‚  Example: TSP with B&B                               â”‚
â”‚  â€¢ Greedy nearest-neighbor: finds decent tour       â”‚
â”‚  â€¢ Use greedy_cost as upper bound                    â”‚
â”‚  â€¢ B&B: only explore if bound > greedy_cost         â”‚
â”‚  â€¢ Result: optimal TSP tour found faster             â”‚
â”‚                                                      â”‚
â”‚  Example: 0/1 Knapsack                               â”‚
â”‚  â€¢ Greedy fractional solution: upper bound           â”‚
â”‚  â€¢ Start B&B: initial lower bound = 0                â”‚
â”‚  â€¢ As B&B progresses, tighten both bounds            â”‚
â”‚  â€¢ Converges to optimal                              â”‚
â”‚                                                      â”‚
â”‚  Key insight:                                        â”‚
â”‚  â€¢ Greedy provides quick initial bounds              â”‚
â”‚  â€¢ B&B refines to optimality                         â”‚
â”‚  â€¢ Hybrid: fast + guaranteed optimal                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Divide & Conquer + Dynamic Programming

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COMBINING DIVIDE-CONQUER + DP                      â”‚
â”‚                                                      â”‚
â”‚  Use case: D&C structure exists but subproblems      â”‚
â”‚           overlap (classic DP indicator)             â”‚
â”‚                                                      â”‚
â”‚  Strategy:                                           â”‚
â”‚  1. Recognize D&C structure                          â”‚
â”‚  2. But subproblems computed multiple times          â”‚
â”‚  3. Memoize subproblem solutions                     â”‚
â”‚  4. Use DP (or memoization) with D&C structure       â”‚
â”‚                                                      â”‚
â”‚  Example: Fibonacci                                  â”‚
â”‚  â€¢ D&C: F(n) = F(n-1) + F(n-2)                      â”‚
â”‚  â€¢ Subproblems overlap (F(n-2) computed many times)  â”‚
â”‚  â€¢ DP/Memoization: store computed values             â”‚
â”‚  â€¢ Result: O(n) instead of O(2^n)                    â”‚
â”‚                                                      â”‚
â”‚  Example: Quicksort + DP for selection               â”‚
â”‚  â€¢ D&C: partition + recurse on parts                 â”‚
â”‚  â€¢ DP: remember partition info for future queries    â”‚
â”‚  â€¢ Result: faster repeated queries                   â”‚
â”‚                                                      â”‚
â”‚  Key insight:                                        â”‚
â”‚  â€¢ D&C structure = independent subproblems           â”‚
â”‚  â€¢ But if overlap: add DP on top                     â”‚
â”‚  â€¢ Hybrid: clean structure + efficiency              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 3: PROBLEM-SOLVING METHODOLOGY (90 minutes)

### Approaching an Unknown Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PROBLEM-SOLVING METHODOLOGY: STEPS                 â”‚
â”‚                                                      â”‚
â”‚  Step 1: UNDERSTAND THE PROBLEM                      â”‚
â”‚  â”œâ”€ Read carefully                                   â”‚
â”‚  â”œâ”€ Identify: input, output, constraints             â”‚
â”‚  â”œâ”€ Do you want: one solution, all solutions,        â”‚
â”‚  â”‚  best solution?                                   â”‚
â”‚  â””â”€ Examples: work through by hand                   â”‚
â”‚                                                      â”‚
â”‚  Step 2: IDENTIFY PROBLEM STRUCTURE                  â”‚
â”‚  â”œâ”€ Is there a greedy choice?                        â”‚
â”‚  â”œâ”€ Are there optimal substructure indicators?       â”‚
â”‚  â”œâ”€ Do subproblems overlap?                          â”‚
â”‚  â”œâ”€ Is it a search problem (permutations, configs)?  â”‚
â”‚  â””â”€ Is it an optimization (min/max)?                 â”‚
â”‚                                                      â”‚
â”‚  Step 3: TRY GREEDY FIRST                            â”‚
â”‚  â”œâ”€ Identify natural greedy choice                   â”‚
â”‚  â”œâ”€ Try it on examples                               â”‚
â”‚  â”œâ”€ Does it work?                                    â”‚
â”‚  â”œâ”€ If YES: Try to prove (exchange arg, etc)        â”‚
â”‚  â””â”€ If NO: Next approach                             â”‚
â”‚                                                      â”‚
â”‚  Step 4: IF GREEDY FAILS, TRY DP                     â”‚
â”‚  â”œâ”€ Define optimal substructure                      â”‚
â”‚  â”œâ”€ Write recurrence relation                        â”‚
â”‚  â”œâ”€ Identify overlapping subproblems                 â”‚
â”‚  â”œâ”€ Implement (top-down memoization or bottom-up)   â”‚
â”‚  â””â”€ Check complexity and space                       â”‚
â”‚                                                      â”‚
â”‚  Step 5: IF DP OVERKILL, TRY BACKTRACKING            â”‚
â”‚  â”œâ”€ Do you need to explore many possibilities?       â”‚
â”‚  â”œâ”€ Can you prune effectively?                       â”‚
â”‚  â”œâ”€ Design pruning strategy                          â”‚
â”‚  â””â”€ Implement with recursion                         â”‚
â”‚                                                      â”‚
â”‚  Step 6: IF OPTIMIZATION CRITICAL, TRY B&B           â”‚
â”‚  â”œâ”€ Can you compute bounds?                          â”‚
â”‚  â”œâ”€ Do bounds improve as you search?                 â”‚
â”‚  â”œâ”€ Implement best-first search                      â”‚
â”‚  â””â”€ Use greedy for initial bounds if needed          â”‚
â”‚                                                      â”‚
â”‚  Step 7: REVIEW & OPTIMIZE                           â”‚
â”‚  â”œâ”€ Check time complexity: acceptable?               â”‚
â”‚  â”œâ”€ Check space: acceptable?                         â”‚
â”‚  â”œâ”€ Consider hybrid approaches                       â”‚
â”‚  â””â”€ Test edge cases                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Examples of Paradigm Choices

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EXAMPLES: WHICH PARADIGM FOR CLASSIC PROBLEMS?     â”‚
â”‚                                                      â”‚
â”‚  Activity Selection (unweighted):                    â”‚
â”‚  â””â”€ Greedy (sort finish time) âœ“                      â”‚
â”‚                                                      â”‚
â”‚  Activity Selection (weighted):                      â”‚
â”‚  â””â”€ DP (optimal substructure) âœ“                      â”‚
â”‚                                                      â”‚
â”‚  N-Queens:                                           â”‚
â”‚  â””â”€ Backtracking (place one/row, check diagonals) âœ“  â”‚
â”‚                                                      â”‚
â”‚  Sudoku:                                             â”‚
â”‚  â””â”€ Backtracking + constraint checking âœ“             â”‚
â”‚                                                      â”‚
â”‚  TSP:                                                â”‚
â”‚  â””â”€ B&B (if small), DP (if medium), heuristic (large)â”‚
â”‚                                                      â”‚
â”‚  0/1 Knapsack:                                       â”‚
â”‚  â””â”€ DP (no greedy choice property) âœ“                 â”‚
â”‚                                                      â”‚
â”‚  Fractional Knapsack:                                â”‚
â”‚  â””â”€ Greedy (by value/weight ratio) âœ“                 â”‚
â”‚                                                      â”‚
â”‚  Huffman Coding:                                     â”‚
â”‚  â””â”€ Greedy (combine smallest frequencies) âœ“          â”‚
â”‚                                                      â”‚
â”‚  LCS (Longest Common Subsequence):                   â”‚
â”‚  â””â”€ DP (optimal substructure, overlaps) âœ“            â”‚
â”‚                                                      â”‚
â”‚  Graph Coloring:                                     â”‚
â”‚  â””â”€ Backtracking (try colors, backtrack) âœ“           â”‚
â”‚                                                      â”‚
â”‚  MST:                                                â”‚
â”‚  â””â”€ Greedy (Kruskal, Prim) âœ“                         â”‚
â”‚                                                      â”‚
â”‚  Shortest Path:                                      â”‚
â”‚  â””â”€ Greedy (Dijkstra) or DP (Bellman-Ford) âœ“         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 5 & WEEK 13 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     WEEK 13: COMPLETE SUMMARY                        â”‚
â”‚     BACKTRACKING & BRANCH & BOUND MASTERY            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DAY 1: BACKTRACKING FUNDAMENTALS
âœ“ Backtracking = incremental solution building
âœ“ State space tree represents all possibilities
âœ“ Pruning avoids exploring dead-end branches
âœ“ Three pruning strategies: constraint, bound, monotonic
âœ“ Key: Backtrack and UNDO choices

DAY 2: BACKTRACKING APPLICATIONS
âœ“ N-Queens: place queen per row, check diagonals
âœ“ Sudoku: find empty cell, try digits with constraints
âœ“ Permutations: track used elements
âœ“ Combinations: only consider elements â‰¥ last picked
âœ“ Word Search: DFS path finding in grid

DAY 3: BRANCH & BOUND
âœ“ B&B = optimization via search + bounds
âœ“ Branch: explore subproblems systematically
âœ“ Bound: compute upper/lower bound per node
âœ“ Prune: if bound can't beat best, skip subtree
âœ“ Best-first search: explore promising nodes first

DAY 4: AMORTIZED ANALYSIS
âœ“ Amortized = average cost over sequence of operations
âœ“ Some ops expensive, many cheap
âœ“ Three methods: aggregate, accounting, potential
âœ“ Dynamic arrays: O(1) amortized append
âœ“ Splay trees: O(log n) amortized per operation

DAY 5: PARADIGM INTEGRATION
âœ“ Decision tree: greedy â†’ DP â†’ backtrack â†’ B&B
âœ“ Hybrid approaches: greedy + backtrack, DP + greedy, B&B + greedy
âœ“ Problem-solving methodology: understand â†’ structure â†’ try approaches
âœ“ Examples: know classic problems and best paradigms
âœ“ Choose based on problem properties

KEY INSIGHTS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. BACKTRACKING IS SYSTEMATIC SEARCH
   â€¢ Explores all possibilities intelligently
   â€¢ Prunes dead ends early
   â€¢ Guarantees finding all solutions
   â€¢ BUT: exponential worst case without good pruning

2. BRANCH & BOUND IS OPTIMIZATION SEARCH
   â€¢ Like backtracking but for optimization
   â€¢ Uses bounds to prune sub-optimal branches
   â€¢ Finds optimal solution faster than brute force
   â€¢ Critical for TSP, knapsack, assignment problems

3. AMORTIZED ANALYSIS EXPLAINS PERFORMANCE
   â€¢ Single expensive operation is misleading
   â€¢ Sequence of operations often cheap on average
   â€¢ Dynamic arrays, splay trees, Fibonacci heaps
   â€¢ Essential for modern data structures

4. PARADIGMS ARE TOOLS, NOT ALGORITHMS
   â€¢ Greedy: fast, requires proof of correctness
   â€¢ DP: powerful, requires optimal substructure
   â€¢ Backtrack: complete, explores all options
   â€¢ B&B: optimized backtrack, needs bounds
   â€¢ Choose based on problem structure!

5. HYBRIDS ARE OFTEN BEST
   â€¢ Greedy ordering for backtracking
   â€¢ DP for subproblems in B&B
   â€¢ Greedy heuristics for B&B bounds
   â€¢ Combine tools wisely!

MASTERY CHECKLIST:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â–¡ Understand backtracking completely
â–¡ Can solve N-Queens and variants
â–¡ Can solve Sudoku systematically
â–¡ Understand pruning strategies
â–¡ Know state space tree concept
â–¡ Understand branch & bound completely
â–¡ Can compute bounds (upper/lower)
â–¡ Know best-first search strategy
â–¡ Master amortized analysis (all 3 methods)
â–¡ Can choose right paradigm for problem
â–¡ Can combine paradigms effectively
â–¡ Know classic problems and best algorithms

PROGRESSION OUTCOME:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ Phase D (Weeks 12-13): Algorithm Paradigms Complete
âœ“ Mastered 4 major design approaches:
  â€¢ Greedy (fast, requires proof)
  â€¢ Dynamic Programming (powerful, overlaps)
  â€¢ Backtracking (complete search, pruned)
  â€¢ Branch & Bound (optimized search, bounds)
âœ“ Can recognize problem structure
âœ“ Can select appropriate algorithm
âœ“ Can combine approaches effectively
âœ“ Ready for advanced topics or real-world problems!

NEXT PATHS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â†’ Graph Algorithms: DFS, BFS, topological sort
â†’ Shortest Path: Dijkstra, Bellman-Ford, Floyd-Warshall
â†’ NP-Completeness: understanding limits
â†’ Approximation Algorithms: dealing with hard problems
â†’ Interview Preparation: applying paradigms to coding problems
```

---

# ğŸ“Š WEEK 13 LEARNING PROGRESSION

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DIFFICULTY PROGRESSION BY DAY                â”‚
â”‚                                                      â”‚
â”‚ Day 1: ğŸŸ¢ GREEN (Fundamentals)                       â”‚
â”‚ â”œâ”€ Backtracking concept: intuitive vs brute force   â”‚
â”‚ â”œâ”€ State space trees: visual, concrete              â”‚
â”‚ â””â”€ Pruning strategies: pattern recognition          â”‚
â”‚                                                      â”‚
â”‚ Day 2: ğŸŸ¡ YELLOW (Application)                       â”‚
â”‚ â”œâ”€ N-Queens: diagonal conflict checking             â”‚
â”‚ â”œâ”€ Sudoku: constraint satisfaction                  â”‚
â”‚ â””â”€ Permutations/Combinations: algorithmic variationsâ”‚
â”‚                                                      â”‚
â”‚ Day 3: ğŸŸ  ORANGE (Optimization)                      â”‚
â”‚ â”œâ”€ Branch & Bound: systematic optimization          â”‚
â”‚ â”œâ”€ Bounds: upper/lower computation                  â”‚
â”‚ â””â”€ Best-first search: priority-based exploration    â”‚
â”‚                                                      â”‚
â”‚ Day 4: ğŸŸ  ORANGE (Analysis)                          â”‚
â”‚ â”œâ”€ Amortized analysis: sequence perspective         â”‚
â”‚ â”œâ”€ Three methods: aggregate, accounting, potential  â”‚
â”‚ â””â”€ Complex examples: splay trees, Fibonacci heaps   â”‚
â”‚                                                      â”‚
â”‚ Day 5: ğŸ”´ RED (Integration & Meta-Learning)          â”‚
â”‚ â”œâ”€ Paradigm selection: decision tree                â”‚
â”‚ â”œâ”€ Hybrid approaches: combining techniques          â”‚
â”‚ â”œâ”€ Problem-solving methodology: systematic approach â”‚
â”‚ â””â”€ Synthesis: knowing when/where to apply each tool â”‚
â”‚                                                      â”‚
â”‚ MASTERY OUTCOME:                                     â”‚
â”‚ âœ“ Complete mastery of search & optimization         â”‚
â”‚ âœ“ Can solve hard combinatorial problems             â”‚
â”‚ âœ“ Understand performance analysis deeply            â”‚
â”‚ âœ“ Know algorithmic paradigms completely             â”‚
â”‚ âœ“ Ready for advanced algorithms or interviews!      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š RECOMMENDED STUDY MATERIALS

### Concept Mastery
- Trace through backtracking examples on paper
- Draw state space trees completely
- Implement N-Queens and Sudoku solver
- Understand pruning at visceral level

### B&B Deep Dive
- Compute bounds by hand for small examples
- Visualize search tree with best-first ordering
- See how bounds prune aggressively
- Practice on 0/1 knapsack by hand

### Amortized Analysis
- Work through accounting method step-by-step
- Define potential functions and verify
- Trace dynamic array operations with potential
- Practice aggregation calculations

### Integration Practice
- Solve mix of problems using different paradigms
- Classify unknown problems correctly
- Design hybrid approaches
- Reason about which paradigm is best

### Common Pitfalls to Avoid
- âŒ Don't assume backtracking is slow (with pruning, it's fast!)
- âŒ Don't forget to undo choices (critical for correctness!)
- âŒ Don't compute wrong bounds (bounds must be valid!)
- âŒ Don't confuse worst-case with amortized (very different!)
- âŒ Don't use wrong paradigm (know the structure first!)

---

**Week 13 Complete! Weeks 12-13: Algorithm Paradigms Complete!**

**You now have complete mastery of:**
- âœ“ Greedy algorithms & proofs
- âœ“ Backtracking & search
- âœ“ Branch & bound optimization
- âœ“ Amortized analysis
- âœ“ Paradigm selection & combination

**Ready for interview prep, real-world problems, or advanced algorithms!**
