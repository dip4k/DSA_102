# ğŸ“˜ WEEK 12: GREEDY ALGORITHMS & PROOFS
## Phase D: Algorithm Paradigms | 25 Hours | Mastery-Focused

---

## ğŸ¯ WEEKLY GOAL

**Master greedy algorithm design paradigm and learn rigorous correctness proofs.**

By end of Week 12, you will:
- âœ… Understand greedy algorithm concept and template
- âœ… Write exchange argument proofs rigorously
- âœ… Identify greedy choice property and optimal substructure
- âœ… Solve activity selection and interval problems
- âœ… Understand Huffman coding optimality
- âœ… Apply greedy to knapsack and scheduling
- âœ… Recognize when greedy fails and why

---

# ğŸ“… DAY 1: GREEDY FUNDAMENTALS & PROOFS
## 5 Hours | Topics: Concept, Template, Correctness Proofs

---

## ğŸ“ PART 1: GREEDY ALGORITHM CONCEPT (90 minutes)

### What is a Greedy Algorithm?

A **greedy algorithm** is an algorithmic paradigm that makes **locally optimal choices at each step** with the hope that this sequence of local choices will lead to a **globally optimal solution**.

### Why "Greedy"?

The term reflects the strategy: at each decision point, the algorithm greedily picks what seems best **right now**, without reconsidering previous choices.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        GREEDY ALGORITHM MENTAL MODEL            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problem State: [Options to choose from]
                        â†“
            Pick "best-looking" option NOW
                        â†“
            Move to new state
                        â†“
            Repeat until solution found
                        â†“
        Hope: Local optimality â†’ Global optimality
```

### The Key Insight and Risk

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Why Greedy is DANGEROUS (and Powerful):            â”‚
â”‚                                                      â”‚
â”‚  âœ“ NO backtracking - once choice made, move on      â”‚
â”‚  âœ“ Very fast - often O(n log n) or better           â”‚
â”‚  âœ— NOT always optimal - greedy can fail!            â”‚
â”‚  âœ— MUST prove correctness per problem               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Critical Understanding:**
- âŒ Greedy is NOT a magical solution
- âŒ Greedy does NOT always work
- âœ… Greedy ONLY works if problem has special structure
- âœ… MUST rigorously prove greedy is correct

### Simple Example: Coin Change (Change-making Problem)

**Problem:** Give change for amount X using minimum number of coins (denominations: 1, 5, 10, 25)

**Greedy Approach:** Always pick largest denomination that fits

```
Amount = 30 cents
â”œâ”€ Pick 25Â¢ (largest â‰¤ 30)  â†’ Remaining: 5Â¢
â”œâ”€ Pick 5Â¢ (largest â‰¤ 5)    â†’ Remaining: 0Â¢
â””â”€ Total: 2 coins âœ“ OPTIMAL
```

**Why greedy works here:**
- Coin system is "canonical" (greedy property holds)
- Larger coins never worse than smaller ones

**But with non-standard denominations (1, 3, 4):**

```
Amount = 6 cents
â”Œâ”€ Greedy:        Pick 4 â†’ Pick 1 â†’ Pick 1 = 3 coins
â””â”€ Optimal:       Pick 3 â†’ Pick 3 = 2 coins âœ— GREEDY FAILS
```

---

## ğŸ“ PART 2: WHEN GREEDY WORKS - THE TWO PROPERTIES (90 minutes)

### Property 1: Optimal Substructure

**Definition:** An optimal solution to a problem contains optimal solutions to subproblems.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OPTIMAL SUBSTRUCTURE                    â”‚
â”‚                                                      â”‚
â”‚  Original Problem â†’ [Greedy Choice] + Subproblem    â”‚
â”‚                                                      â”‚
â”‚  If Opt(Original) = [Greedy Choice] + Opt(Sub)      â”‚
â”‚  Then we can build optimal from greedy choice       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Visual Example: Activity Selection**

```
Activities: A B C D E (sorted by finish time)
â”Œâ”€â”€â”€â”€â”
â”‚ A  â”‚
â””â”€â”€â”€â”€â”˜
      â”Œâ”€â”€â”€â”€â”
      â”‚ B  â”‚
      â””â”€â”€â”€â”€â”˜
              â”Œâ”€â”€â”€â”€â”
              â”‚ C  â”‚
              â””â”€â”€â”€â”€â”˜
                     â”Œâ”€â”€â”€â”€â”
                     â”‚ D  â”‚
                     â””â”€â”€â”€â”€â”˜
                          â”Œâ”€â”€â”€â”€â”
                          â”‚ E  â”‚
                          â””â”€â”€â”€â”€â”˜

Optimal solution: [A selected] + Optimal of remaining non-overlapping

The key: picking A doesn't prevent optimal solution to rest!
```

### Property 2: Greedy Choice Property

**Definition:** A globally optimal solution can be reached by making a greedy choice at each step.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           GREEDY CHOICE PROPERTY                     â”‚
â”‚                                                      â”‚
â”‚  There exists an optimal solution where:            â”‚
â”‚  â€¢ First choice IS the greedy choice                â”‚
â”‚  â€¢ No other choice could be first in ANY optimal    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Visual: Why Greedy Choice Matters**

```
Activity Selection Problem:

ALL possible orderings to consider:
  Option 1: Start with A
  Option 2: Start with B
  Option 3: Start with C
  ... millions of possibilities

Greedy Choice Property says:
  "Starting with earliest-finishing activity (A)
   is GUARANTEED to be optimal - don't even
   consider other starting points!"

This reduces search space exponentially.
```

### The Two Properties Together

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      WHEN GREEDY WORKS: BOTH PROPERTIES NEEDED        â”‚
â”‚                                                        â”‚
â”‚  1ï¸âƒ£ Optimal Substructure:                             â”‚
â”‚     Remaining problem after greedy choice             â”‚
â”‚     is same type of problem                           â”‚
â”‚                                                        â”‚
â”‚  2ï¸âƒ£ Greedy Choice Property:                           â”‚
â”‚     Greedy choice MUST be part of                     â”‚
â”‚     SOME optimal solution                            â”‚
â”‚                                                        â”‚
â”‚  âœ“ Both properties present â†’ Greedy works!           â”‚
â”‚  âœ— Missing either property â†’ Greedy may fail!        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 3: GREEDY ALGORITHM TEMPLATE (60 minutes)

### Universal Greedy Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         GREEDY ALGORITHM TEMPLATE                    â”‚
â”‚                                                      â”‚
â”‚  Input: Problem instance P                           â”‚
â”‚  Output: Solution S                                  â”‚
â”‚                                                      â”‚
â”‚  1. Sort input by selection criterion                â”‚
â”‚  2. Initialize S = empty                             â”‚
â”‚  3. FOR each element in sorted order:                â”‚
â”‚       IF element feasible to add:                    â”‚
â”‚          Add to S                                    â”‚
â”‚  4. Return S                                         â”‚
â”‚                                                      â”‚
â”‚  KEY: "Feasible" means respects constraints          â”‚
â”‚       "Selection criterion" is problem-specific      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Template Application: Activity Selection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ACTIVITY SELECTION INSTANTIATION          â”‚
â”‚                                                     â”‚
â”‚  Input: Activities with (start, finish) times      â”‚
â”‚  Output: Maximum set of non-overlapping activities  â”‚
â”‚                                                     â”‚
â”‚  1. Sort by FINISH TIME (earliest first)           â”‚
â”‚  2. S = empty                                        â”‚
â”‚  3. FOR each activity in finish-time order:        â”‚
â”‚       IF activity doesn't overlap with S:          â”‚
â”‚          Add to S                                   â”‚
â”‚  4. Return S                                        â”‚
â”‚                                                     â”‚
â”‚  Selection criterion: Earliest finish time         â”‚
â”‚  Feasibility: Non-overlapping constraint           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 4: EXCHANGE ARGUMENT - PROOF TECHNIQUE (90 minutes)

### What is an Exchange Argument?

The exchange argument is the **primary technique for proving greedy correctness**. The idea:

```
Start with ANY optimal solution
        â†“
Find a difference from greedy
        â†“
Swap one element with greedy choice
        â†“
Show solution is still optimal (or better)
        â†“
Repeat until solution becomes greedy solution
        â†“
Conclusion: Greedy solution is optimal
```

### Visual: Exchange Argument for Activity Selection

```
Step 1: Start with Optimal Solution O
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ O = [Aâ‚, Aâ‚‚, Aâ‚ƒ, Aâ‚„]  (activities)     â”‚
â”‚ where Aâ‚ is NOT the earliest finish     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Greedy would pick A (earliest finish)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Greedy choice: A (earliest finish time) â”‚
â”‚ O's choice: Aâ‚ (NOT earliest)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 3: Exchange Aâ‚ with A
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ O' = [A, Aâ‚‚, Aâ‚ƒ, Aâ‚„]                    â”‚
â”‚                                         â”‚
â”‚ Key observation:                        â”‚
â”‚ Since A finishes EARLIER than Aâ‚:      â”‚
â”‚ - A doesn't overlap with Aâ‚‚, Aâ‚ƒ, Aâ‚„   â”‚
â”‚ - All original constraints still met    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 4: Conclude O' is also optimal
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ O' has same size as O                   â”‚
â”‚ O' has same or fewer conflicts           â”‚
â”‚ Therefore O' is also optimal            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 5: Repeat for next element
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Continue exchanging Aâ‚‚, Aâ‚ƒ, Aâ‚„...       â”‚
â”‚ Until O' = G (greedy solution)          â”‚
â”‚ Therefore: Greedy solution is optimal   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Insight of Exchange Argument

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    WHY EXCHANGE ARGUMENT PROVES OPTIMALITY          â”‚
â”‚                                                      â”‚
â”‚  The exchange argument shows:                        â”‚
â”‚                                                      â”‚
â”‚  â€¢ For ANY optimal solution O                       â”‚
â”‚  â€¢ We can transform it into greedy G                â”‚
â”‚  â€¢ Without losing optimality                        â”‚
â”‚  â€¢ Therefore G is also optimal                      â”‚
â”‚  â€¢ But G is greedy by construction                  â”‚
â”‚  â€¢ So greedy approach IS optimal!                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Exchange Argument Structure (General)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    GENERAL EXCHANGE ARGUMENT PROOF TEMPLATE           â”‚
â”‚                                                        â”‚
â”‚  Theorem: Greedy algorithm G produces optimal sol.   â”‚
â”‚  Proof:                                               â”‚
â”‚    1. Let O be ANY optimal solution                  â”‚
â”‚    2. IF O â‰  G:                                      â”‚
â”‚       a. Find first position i where O â‰  G          â”‚
â”‚       b. G has element g_i, O has element o_i       â”‚
â”‚       c. SHOW: Swapping g_i for o_i doesn't hurt   â”‚
â”‚       d. Result O' is still optimal                 â”‚
â”‚    3. Continue until O becomes G                    â”‚
â”‚    4. Therefore G is optimal (Q.E.D.)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Proof Works

The power of the exchange argument:

```
âŒ Showing greedy is optimal directly is hard
   (need to consider all possible solutions)

âœ… Showing ANY optimal can be transformed to greedy
   (only need to show local swaps preserve optimality)

This is much more tractable!
```

---

## ğŸ“ PART 5: CORRECTNESS PROOF STRATEGY (60 minutes)

### Five-Step Strategy to Prove Greedy Correctness

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     5-STEP GREEDY CORRECTNESS PROOF STRATEGY        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1: Identify Greedy Choice
â”œâ”€ What is the local choice?
â”œâ”€ Why does it seem optimal?
â””â”€ Example: Activity Selection chooses earliest finish

Step 2: Show Optimal Substructure
â”œâ”€ Show problem can be split into:
â”‚  â””â”€ [Greedy Choice] + [Remaining subproblem]
â”œâ”€ Remaining subproblem is same type
â””â”€ Example: After choosing activity A,
            remaining activities form same problem

Step 3: Show Greedy Choice Property
â”œâ”€ Show there EXISTS an optimal solution
â”‚  with greedy choice as first element
â”œâ”€ Use exchange argument if needed
â””â”€ Example: Earliest-finish activity IS in
            some optimal solution

Step 4: Show Subproblems are Independent
â”œâ”€ Greedy choice doesn't affect
â”‚  optimality of remaining subproblems
â””â”€ Example: Picking activity A limits future
            choices but doesn't make remaining
            choices worse

Step 5: Conclude by Induction
â”œâ”€ If greedy choice is optimal for first step
â”œâ”€ And subproblems follow same pattern
â”œâ”€ Then entire greedy solution is optimal
â””â”€ By induction on problem size
```

### Proof Structure Visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GREEDY CORRECTNESS PROOF ARCHITECTURE              â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Greedy Choice Property                     â”‚    â”‚
â”‚  â”‚ (greedy choice in SOME optimal)            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                  â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Optimal Substructure                       â”‚    â”‚
â”‚  â”‚ (after greedy choice, same type problem)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                  â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Inductive Step                             â”‚    â”‚
â”‚  â”‚ (greedy optimal for rest by induction)     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                  â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Conclusion: Greedy is Optimal              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Proving Activity Selection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ACTIVITY SELECTION CORRECTNESS PROOF           â”‚
â”‚                                                      â”‚
â”‚  Problem: Select maximum non-overlapping activities â”‚
â”‚                                                      â”‚
â”‚  STEP 1: Identify Greedy Choice                    â”‚
â”‚  â”œâ”€ Greedy choice: Activity with earliest finish   â”‚
â”‚  â””â”€ Intuition: Leaves most room for future        â”‚
â”‚                                                      â”‚
â”‚  STEP 2: Show Optimal Substructure                 â”‚
â”‚  â”œâ”€ After selecting earliest-finish activity A     â”‚
â”‚  â”œâ”€ Remaining activities form same type problem    â”‚
â”‚  â”‚  (select max non-overlapping after A)           â”‚
â”‚  â””â”€ Optimal = {A} âˆª Optimal(remaining)             â”‚
â”‚                                                      â”‚
â”‚  STEP 3: Show Greedy Choice Property               â”‚
â”‚  â”œâ”€ Suppose O is an optimal solution not           â”‚
â”‚  â”‚  starting with earliest-finish activity         â”‚
â”‚  â”œâ”€ Let A_m = earliest-finish activity             â”‚
â”‚  â”œâ”€ Let O = {Oâ‚, Oâ‚‚, ...}                          â”‚
â”‚  â”œâ”€ Where Oâ‚ â‰  A_m                                 â”‚
â”‚  â”œâ”€ EXCHANGE: Replace Oâ‚ with A_m                  â”‚
â”‚  â”‚  Since A_m finishes â‰¤ Oâ‚ finish:                â”‚
â”‚  â”‚  A_m doesn't overlap with Oâ‚‚, Oâ‚ƒ, ...           â”‚
â”‚  â”‚  So O' = {A_m} âˆª {Oâ‚‚, Oâ‚ƒ, ...} is feasible     â”‚
â”‚  â”‚  And |O'| = |O|, so O' is optimal               â”‚
â”‚  â””â”€ Therefore: Greedy choice in optimal solution   â”‚
â”‚                                                      â”‚
â”‚  STEP 4: Show Independence                         â”‚
â”‚  â”œâ”€ Picking A_m (earliest finish) means:           â”‚
â”‚  â”‚  Next activity must start after A_m finish      â”‚
â”‚  â”œâ”€ No other earlier choice would start later      â”‚
â”‚  â””â”€ So A_m doesn't artificially limit future       â”‚
â”‚                                                      â”‚
â”‚  STEP 5: Inductive Conclusion                      â”‚
â”‚  â”œâ”€ Base: Single activity is optimal               â”‚
â”‚  â”œâ”€ Inductive step: If greedy optimal for         â”‚
â”‚  â”‚  remaining subproblem, and greedy choice       â”‚
â”‚  â”‚  optimal for first step...                      â”‚
â”‚  â””â”€ Then entire greedy sequence is optimal         â”‚
â”‚                                                      â”‚
â”‚  CONCLUSION: âœ“ Greedy activity selection works!    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 1 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DAY 1: KEY TAKEAWAYS                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ Greedy makes locally optimal choices             â”‚
â”‚  âœ“ NOT always globally optimal (must prove!)        â”‚
â”‚                                                      â”‚
â”‚  âœ“ TWO properties needed:                           â”‚
â”‚    1. Optimal substructure                          â”‚
â”‚    2. Greedy choice property                        â”‚
â”‚                                                      â”‚
â”‚  âœ“ EXCHANGE ARGUMENT proves greedy works            â”‚
â”‚    by showing ANY optimal can become greedy         â”‚
â”‚                                                      â”‚
â”‚  âœ“ 5-STEP proof strategy:                           â”‚
â”‚    1. Identify choice   2. Substructure             â”‚
â”‚    3. Choice property   4. Independence             â”‚
â”‚    5. Inductive conclusion                          â”‚
â”‚                                                      â”‚
â”‚  âœ“ Greedy is fast (usually O(n log n))              â”‚
â”‚  âœ“ But MUST verify with rigorous proof              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“… DAY 2: ACTIVITY SELECTION & INTERVAL PROBLEMS
## 5 Hours | Canonical Greedy Application

---

## ğŸ“ PART 1: ACTIVITY SELECTION PROBLEM (90 minutes)

### Problem Definition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ACTIVITY SELECTION PROBLEM                   â”‚
â”‚                                                      â”‚
â”‚  Input: n activities, each with:                    â”‚
â”‚         - Start time: s_i                           â”‚
â”‚         - Finish time: f_i                          â”‚
â”‚         (ordered by finish time: f_i â‰¤ f_{i+1})    â”‚
â”‚                                                      â”‚
â”‚  Goal: Select maximum-size subset of               â”‚
â”‚         non-overlapping activities                  â”‚
â”‚                                                      â”‚
â”‚  Two activities i,j compatible if:                  â”‚
â”‚  f_i â‰¤ s_j  or  f_j â‰¤ s_i                          â”‚
â”‚  (activities don't overlap)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual Example

```
Timeline Visualization:

Activities on timeline:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚  1[â”â”â”â”â”â”] 
â”‚     2[â”€â”€â”€â”€â”€â”€â”€â”€]
â”‚  3[â”â”]
â”‚       4[â”€â”€â”€â”€â”€â”€]
â”‚            5[â”€â”€]
â”‚              6[â”€â”€â”€â”€â”€â”€â”€â”€]
â”‚                     7[â”€â”€]
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problem: Pick max activities with NO overlaps
```

### Visualizing Different Choices

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       CHOOSING ACTIVITIES: THREE SCENARIOS â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Scenario 1: Pick longest duration
[Activity starts early, runs long]
Result: Can only fit 1 activity â†’ NOT OPTIMAL

Scenario 2: Pick earliest start
[Pick earliest starting]
Result: 2-3 activities â†’ NOT OPTIMAL

Scenario 3: Pick earliest FINISH âœ“
[Pick finishes earliest, frees time]
Result: 4 activities â†’ OPTIMAL!

Greedy Insight:
The earlier an activity finishes,
the more time remains for future activities!
```

---

## ğŸ“ PART 2: GREEDY SELECTION BY FINISH TIME (90 minutes)

### The Greedy Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    GREEDY ACTIVITY SELECTION ALGORITHM              â”‚
â”‚                                                      â”‚
â”‚  Input: Activities with finish times                â”‚
â”‚  Output: Maximum set S of non-overlapping activitiesâ”‚
â”‚                                                      â”‚
â”‚  GREEDY CHOICE:                                     â”‚
â”‚  Always pick activity with EARLIEST FINISH TIME     â”‚
â”‚                                                      â”‚
â”‚  WHY?                                               â”‚
â”‚  â€¢ Earliest finishing leaves most room later        â”‚
â”‚  â€¢ Minimizes "time consumed"                        â”‚
â”‚  â€¢ Maximizes "time left" for others                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step-by-Step Example

```
Given activities (already sorted by finish time):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Activity â”‚ Start â”‚ Finish â”‚ Duration       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1        â”‚ 1     â”‚ 4      â”‚ 3 units        â”‚
â”‚ 2        â”‚ 3     â”‚ 5      â”‚ 2 units        â”‚
â”‚ 3        â”‚ 0     â”‚ 6      â”‚ 6 units        â”‚
â”‚ 4        â”‚ 5     â”‚ 7      â”‚ 2 units        â”‚
â”‚ 5        â”‚ 3     â”‚ 8      â”‚ 5 units        â”‚
â”‚ 6        â”‚ 5     â”‚ 9      â”‚ 4 units        â”‚
â”‚ 7        â”‚ 6     â”‚ 10     â”‚ 4 units        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1: Select earliest-finishing activity (1)
â”œâ”€ Pick: Activity 1 (finish: 4)
â”œâ”€ S = {1}
â””â”€ Next must start â‰¥ 4

Step 2: From remaining, pick earliest-finishing
â”œâ”€ Compatible: 2(finish 5), 4(finish 7), 6(finish 9), 7(finish 10)
â”œâ”€ Pick: Activity 4 (finish: 7) - earliest compatible
â”œâ”€ S = {1, 4}
â””â”€ Next must start â‰¥ 7

Step 3: From remaining, pick earliest-finishing
â”œâ”€ Compatible: 7(finish 10)
â”œâ”€ Pick: Activity 7 (finish: 10)
â”œâ”€ S = {1, 4, 7}
â””â”€ Next must start â‰¥ 10

Step 4: No more compatible activities
â””â”€ Final: S = {1, 4, 7} with size 3
```

### Why Greedy Finish-Time Works: Intuitive Argument

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    "GREEDY STAYS AHEAD" INTUITION                   â”‚
â”‚                                                      â”‚
â”‚  Claim: Greedy finishes NO LATER than any optimal   â”‚
â”‚                                                      â”‚
â”‚  Proof sketch:                                       â”‚
â”‚  â€¢ Gâ‚ = greedy's first activity (earliest finish)   â”‚
â”‚  â€¢ Oâ‚ = optimal's first activity                    â”‚
â”‚  â€¢ By definition: f(Gâ‚) â‰¤ f(Oâ‚)                     â”‚
â”‚                                                      â”‚
â”‚  So greedy finishes at time f(Gâ‚)                   â”‚
â”‚  Optimal finishes at time â‰¥ f(Oâ‚) â‰¥ f(Gâ‚)          â”‚
â”‚                                                      â”‚
â”‚  This means:                                         â”‚
â”‚  â€¢ Greedy has MORE TIME left than optimal!          â”‚
â”‚  â€¢ Whatever optimal can fit after its first activityâ”‚
â”‚  â€¢ Greedy can also fit (same or more!)              â”‚
â”‚                                                      â”‚
â”‚  By repeating this argument:                        â”‚
â”‚  â€¢ Greedy stays ahead at each step                  â”‚
â”‚  â€¢ So greedy can accommodate â‰¥ activities than opt  â”‚
â”‚  â€¢ Therefore greedy is optimal!                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual Proof: "Greedy Stays Ahead"

```
Timeline comparison:

Optimal solution:
â—‹ Oâ‚ [finishes at time tâ‚]
        â—‹ Oâ‚‚ [finishes at time tâ‚‚]
              â—‹ Oâ‚ƒ [finishes at time tâ‚ƒ]

Greedy solution:
â— Gâ‚ [finishes at time tâ‚'â‰¤tâ‚]
  
  â† More room for next activity!
  
        â— Gâ‚‚ [finishes at time tâ‚‚'â‰¤tâ‚‚]
        
        â† More room for next activity!
        
              â— Gâ‚ƒ [finishes at time tâ‚ƒ'â‰¤tâ‚ƒ]

At each stage, greedy finishes â‰¤ optimal
So greedy has at least as much room for future activities
Therefore greedy achieves â‰¥ activities as optimal
```

---

## ğŸ“ PART 3: INTERVAL SCHEDULING VARIATIONS (60 minutes)

### Variation 1: Weighted Activity Selection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VARIATION: WEIGHTED ACTIVITY SELECTION             â”‚
â”‚                                                      â”‚
â”‚  Problem: Each activity has WEIGHT (value)           â”‚
â”‚  Goal: Maximize TOTAL WEIGHT (not count)             â”‚
â”‚                                                      â”‚
â”‚  Example:                                            â”‚
â”‚  Activity 1: [1,4]  weight=10                       â”‚
â”‚  Activity 2: [3,5]  weight=8                        â”‚
â”‚  Activity 3: [0,6]  weight=6                        â”‚
â”‚                                                      â”‚
â”‚  Greedy by finish time gives: 1+2+... = 22          â”‚
â”‚  But optimal might be: Just 3 = 6 (WORSE!)          â”‚
â”‚  Or optimal might be: 1+3 = 16 (BETTER!)            â”‚
â”‚                                                      â”‚
â”‚  âœ— GREEDY FAILS for weighted version!               â”‚
â”‚  âœ“ Dynamic Programming needed instead                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Variation 2: Room Assignment (Interval Coloring)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VARIATION: ROOM ASSIGNMENT PROBLEM                 â”‚
â”‚                                                      â”‚
â”‚  Problem: Assign activities to rooms                â”‚
â”‚  Constraint: Overlapping activities â†’ different roomâ”‚
â”‚  Goal: Minimize number of rooms needed               â”‚
â”‚                                                      â”‚
â”‚  Greedy approach: Process activities by start time  â”‚
â”‚  â€¢ Assign to room with earliest free time          â”‚
â”‚  â€¢ If no room free, create new room                â”‚
â”‚                                                      â”‚
â”‚  Visual:                                             â”‚
â”‚  Activity 1: [0, 3]    â†’ Room A                     â”‚
â”‚  Activity 2: [1, 4]    â†’ Room B (overlaps with 1)  â”‚
â”‚  Activity 3: [2, 5]    â†’ Room C (overlaps 1,2)     â”‚
â”‚  Activity 4: [3, 6]    â†’ Room A (after 1 ends)     â”‚
â”‚  Activity 5: [3, 7]    â†’ Room B (after 2 ends)     â”‚
â”‚                                                      â”‚
â”‚  Result: 3 rooms needed                              â”‚
â”‚  This equals max overlapping activities             â”‚
â”‚  âœ“ GREEDY WORKS here!                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Variation 3: Interval Partitioning

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VARIATION: INTERVAL PARTITIONING                   â”‚
â”‚                                                      â”‚
â”‚  Problem: Partition intervals into minimum groups    â”‚
â”‚  Constraint: No overlapping intervals in same group  â”‚
â”‚  Goal: Minimize number of groups                     â”‚
â”‚                                                      â”‚
â”‚  Same as room assignment!                            â”‚
â”‚  Answer = maximum number of overlapping intervals   â”‚
â”‚                                                      â”‚
â”‚  Example:                                            â”‚
â”‚  Max overlap at any point = 3                        â”‚
â”‚  So minimum 3 groups needed                          â”‚
â”‚                                                      â”‚
â”‚  âœ“ Greedy processes by start time                    â”‚
â”‚  âœ“ Assigns to group with latest end time            â”‚
â”‚  âœ“ Always optimal!                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Decision Tree: Which Greedy for Intervals?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INTERVAL PROBLEMS: WHICH GREEDY APPROACH?         â”‚
â”‚                                                     â”‚
â”‚  Want: Max count of activities?                    â”‚
â”‚  â””â”€â†’ Greedy by FINISH TIME âœ“                       â”‚
â”‚                                                     â”‚
â”‚  Want: Min rooms/groups needed?                    â”‚
â”‚  â””â”€â†’ Greedy by START TIME âœ“                        â”‚
â”‚      (sweep line algorithm)                        â”‚
â”‚                                                     â”‚
â”‚  Want: Max weight (weighted)?                      â”‚
â”‚  â””â”€â†’ NOT GREEDY! Use DP instead âœ—                  â”‚
â”‚                                                     â”‚
â”‚  Want: Min weight? (weighted interval scheduling)  â”‚
â”‚  â””â”€â†’ NOT GREEDY! Use DP instead âœ—                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 4: GREEDY STAYS AHEAD PRINCIPLE (60 minutes)

### The Core Principle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   "GREEDY STAYS AHEAD" PROOF PRINCIPLE              â”‚
â”‚                                                      â”‚
â”‚  Used for many greedy proofs, not just activity sel â”‚
â”‚                                                      â”‚
â”‚  Pattern:                                            â”‚
â”‚  1. Compare greedy solution G with optimal O        â”‚
â”‚  2. Show: G achieves something faster/earlier/less  â”‚
â”‚  3. At each step, G â‰¤ O                             â”‚
â”‚  4. Therefore G can achieve â‰¥ O                     â”‚
â”‚  5. So G is also optimal                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Insight: Why Staying Ahead Means Optimal

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       WHY "STAYING AHEAD" IMPLIES OPTIMALITY        â”‚
â”‚                                                      â”‚
â”‚  Suppose greedy G always finishes before optimal O  â”‚
â”‚                                                      â”‚
â”‚  At each step i:                                    â”‚
â”‚  â€¢ G has completed action A_i by time t_g          â”‚
â”‚  â€¢ O has completed action A'_i by time t_o         â”‚
â”‚  â€¢ We show: t_g â‰¤ t_o                              â”‚
â”‚                                                      â”‚
â”‚  Why this matters:                                  â”‚
â”‚  â€¢ If G finishes earlier, G has more time left     â”‚
â”‚  â€¢ For next action, G can handle anything O can    â”‚
â”‚  â€¢ So G can fit â‰¥ actions than O                   â”‚
â”‚  â€¢ Since O is optimal with size k                  â”‚
â”‚  â€¢ G must also have size k (G is optimal too!)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Abstract Template: Stay Ahead Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    STAY-AHEAD PROOF TEMPLATE                          â”‚
â”‚                                                        â”‚
â”‚  Theorem: Greedy algorithm G is optimal               â”‚
â”‚                                                        â”‚
â”‚  Proof:                                                â”‚
â”‚    Let O = any optimal solution                       â”‚
â”‚    Let measure M = some metric we care about          â”‚
â”‚                                                        â”‚
â”‚    Claim 1: After first step, M(G) â‰¤ M(O)             â”‚
â”‚    Proof: [Show greedy choice minimizes/maximizes M]  â”‚
â”‚                                                        â”‚
â”‚    Claim 2: If M(G) â‰¤ M(O) at step i                  â”‚
â”‚             Then M(G) â‰¤ M(O) at step i+1              â”‚
â”‚    Proof: [Show greedy stays ahead one more step]     â”‚
â”‚                                                        â”‚
â”‚    Conclusion: By induction, M(G) â‰¤ M(O) always       â”‚
â”‚               So G is as good as O on key metric      â”‚
â”‚               Since O is optimal, G is optimal!       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 2 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DAY 2: KEY TAKEAWAYS                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ Activity Selection: classic greedy problem        â”‚
â”‚  âœ“ Greedy by FINISH TIME is optimal                  â”‚
â”‚                                                      â”‚
â”‚  âœ“ "Greedy Stays Ahead" proof pattern:               â”‚
â”‚    Shows greedy finishes â‰¤ optimal at each step      â”‚
â”‚    Therefore greedy can fit â‰¥ activities             â”‚
â”‚    So greedy is optimal                              â”‚
â”‚                                                      â”‚
â”‚  âœ“ Interval problems have multiple variants:         â”‚
â”‚    â€¢ Max activities â†’ finish time greedy             â”‚
â”‚    â€¢ Min rooms â†’ start time greedy                   â”‚
â”‚    â€¢ Weighted â†’ need DP, not greedy                  â”‚
â”‚                                                      â”‚
â”‚  âœ“ Key insight: Earlier finish = more room later     â”‚
â”‚  âœ“ Choosing "best for now" = best overall            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“… DAY 3: HUFFMAN CODING & OPTIMAL PREFIX TREES
## 5 Hours | Optimal Tree Construction

---

## ğŸ“ PART 1: PREFIX CODES AND THE HUFFMAN PROBLEM (90 minutes)

### What is a Prefix Code?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PREFIX CODES: DEFINITION                â”‚
â”‚                                                      â”‚
â”‚  Code: Assignment of binary strings to characters   â”‚
â”‚  Example: 'A'â†’0, 'B'â†’1, 'C'â†’00 (NO - violates prefix)â”‚
â”‚                                                      â”‚
â”‚  Prefix Code: No codeword is prefix of another      â”‚
â”‚  Example: 'A'â†’0, 'B'â†’10, 'C'â†’110 âœ“ Valid            â”‚
â”‚                                                      â”‚
â”‚  Property: Can decode uniquely without delimiters  â”‚
â”‚  String: 01011 can only be A,B,A,C (001-0-11)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Prefix Codes Matter

```
String: "ABAC"

Option 1: Fixed-length codes
'A'=00, 'B'=01, 'C'=10
Encoded: 00 01 00 10 (8 bits)

Option 2: Variable-length codes (prefix)
'A'=0, 'B'=10, 'C'=11
Encoded: 0 10 0 11 (6 bits) â† 25% savings!

BUT: Need code with no prefix property
Otherwise can't decode uniquely!
```

### The Huffman Coding Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HUFFMAN CODING PROBLEM                       â”‚
â”‚                                                      â”‚
â”‚  Input: Characters with frequencies (prob of use)   â”‚
â”‚  Example:                                            â”‚
â”‚    'A': frequency 45%  (most common)                 â”‚
â”‚    'B': frequency 13%  (less common)                 â”‚
â”‚    'C': frequency 12%  (less common)                 â”‚
â”‚    'D': frequency 16%  (less common)                 â”‚
â”‚    'E': frequency 9%   (least common)                â”‚
â”‚                                                      â”‚
â”‚  Goal: Find prefix code that minimizes expected     â”‚
â”‚        encoded message length                        â”‚
â”‚                                                      â”‚
â”‚  Expected length = Î£ (frequency Ã— codeword length)  â”‚
â”‚                                                      â”‚
â”‚  Minimize: 0.45Ã—1 + 0.13Ã—2 + 0.12Ã—2 + 0.16Ã—2 + 0.09Ã—2â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Representing Codes as Binary Trees

```
Key insight: Prefix codes â†” Binary trees with chars at leaves

Example encoding tree:
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ROOT        â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               / \
              0   1
            /       \
     â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”
     â”‚ 'A'  â”‚    â”‚ ROOT â”‚
     â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”¬â”€â”€â”€â”˜
                   / \
                  0   1
                /       \
         â”Œâ”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”
         â”‚'B' â”‚       â”‚'C' â”‚
         â””â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”˜

Decoding tree (left=0, right=1):
- 0 â†’ 'A'
- 10 â†’ 'B'
- 11 â†’ 'C'

Property: All chars at leaves (prefix-free!)
Cost: (frequencyÃ—depth) summed for all chars

Tree structure determines expected length!
```

### Cost of a Prefix Code Tree

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         COST OF PREFIX CODE TREE                     â”‚
â”‚                                                      â”‚
â”‚  Definition: Cost = Î£ (frequency Ã— depth)           â”‚
â”‚              for each character                      â”‚
â”‚                                                      â”‚
â”‚  Meaning: Expected number of bits per character     â”‚
â”‚                                                      â”‚
â”‚  Example:                                            â”‚
â”‚  'A': freq=45, depth=1  â†’ cost = 45Ã—1 = 45         â”‚
â”‚  'B': freq=13, depth=2  â†’ cost = 13Ã—2 = 26         â”‚
â”‚  'C': freq=12, depth=2  â†’ cost = 12Ã—2 = 24         â”‚
â”‚  'D': freq=16, depth=2  â†’ cost = 16Ã—2 = 32         â”‚
â”‚  'E': freq= 9, depth=3  â†’ cost =  9Ã—3 = 27         â”‚
â”‚                                                      â”‚
â”‚  Total: 45+26+24+32+27 = 154                        â”‚
â”‚  Average: 154/100 = 1.54 bits per character         â”‚
â”‚                                                      â”‚
â”‚  Goal: Minimize this cost!                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 2: THE HUFFMAN ALGORITHM (90 minutes)

### The Greedy Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      HUFFMAN ALGORITHM: GREEDY STRATEGY              â”‚
â”‚                                                      â”‚
â”‚  Goal: Build optimal prefix tree by greedily        â”‚
â”‚        combining lowest-frequency nodes             â”‚
â”‚                                                      â”‚
â”‚  Intuition: High-frequency chars â†’ shallow (short)  â”‚
â”‚            Low-frequency chars â†’ deep (long)        â”‚
â”‚            This minimizes expected length!          â”‚
â”‚                                                      â”‚
â”‚  Greedy choice: Always combine two nodes with       â”‚
â”‚                 smallest frequencies next            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm Steps

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       HUFFMAN ALGORITHM: STEP-BY-STEP                â”‚
â”‚                                                      â”‚
â”‚  Input: n characters with frequencies               â”‚
â”‚  Output: Optimal prefix tree                        â”‚
â”‚                                                      â”‚
â”‚  STEP 1: Create leaf node for each character        â”‚
â”‚          with its frequency                          â”‚
â”‚                                                      â”‚
â”‚  STEP 2: WHILE more than 1 node in forest:          â”‚
â”‚          a. Extract 2 nodes with min frequency      â”‚
â”‚          b. Create parent node with combined freq   â”‚
â”‚          c. Add parent back to forest               â”‚
â”‚                                                      â”‚
â”‚  STEP 3: Return remaining node as tree root         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Example: Building Huffman Tree

```
Start: Characters with frequencies
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”
â”‚ 'A' â”‚  â”‚ 'B' â”‚  â”‚ 'C' â”‚  â”‚ 'D' â”‚  â”‚ 'E' â”‚
â”‚ 45  â”‚  â”‚ 13  â”‚  â”‚ 12  â”‚  â”‚ 16  â”‚  â”‚  9  â”‚
â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜

Iteration 1: Combine two smallest (12, 9)
Merge C(12) + E(9) = 21

State:
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ 'A' â”‚  â”‚ 'B' â”‚  â”‚  X   â”‚  â”‚ 'D' â”‚
â”‚ 45  â”‚  â”‚ 13  â”‚  â”‚ 21   â”‚  â”‚ 16  â”‚
â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
           /  \
         'C'  'E'
         12    9

Iteration 2: Combine two smallest (13, 16)
Merge B(13) + D(16) = 29

State:
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ 'A' â”‚  â”‚  X   â”‚  â”‚  Y   â”‚
â”‚ 45  â”‚  â”‚ 21   â”‚  â”‚ 29   â”‚
â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
          /  \      /  \
        'C'  'E'   'B'  'D'
        12    9    13   16

Iteration 3: Combine two smallest (21, 29)
Merge 21 + 29 = 50

State:
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ 'A' â”‚  â”‚  Z   â”‚
â”‚ 45  â”‚  â”‚ 50   â”‚
â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
          /      \
         X        Y
        / \      / \
       C   E    B   D
      12   9   13  16

Iteration 4: Combine two smallest (45, 50)
Merge 45 + 50 = 95 (FINAL ROOT)

Final tree:
        â”Œâ”€â”€â”€â”€â”€â”€â”
        â”‚ ROOT â”‚
        â”‚ 95   â”‚
        â””â”€â”€â”¬â”€â”€â”€â”˜
          / \
         /   \
        /     \
    â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚A  â”‚   â”‚  X   â”‚
    â”‚45 â”‚   â”‚ 50   â”‚
    â””â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”€â”˜
              / \
             /   \
        â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”
        â”‚X  â”‚   â”‚  Y   â”‚
        â”‚21 â”‚   â”‚ 29   â”‚
        â””â”€â”¬â”€â”˜   â””â”€â”€â”¬â”€â”€â”€â”˜
         / \      / \
        /   \    /   \
       C     E  B     D
       12    9  13   16

Resulting codes:
'A': 0 (depth 1)
'C': 100 (depth 3)
'E': 101 (depth 3)
'B': 110 (depth 3)
'D': 111 (depth 3)

Total cost: 45Ã—1 + 12Ã—3 + 9Ã—3 + 13Ã—3 + 16Ã—3
         = 45 + 36 + 27 + 39 + 48 = 195
```

### Why This Greedy Works: Intuitive Argument

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    WHY HUFFMAN GREEDY IS OPTIMAL                     â”‚
â”‚                                                      â”‚
â”‚  Key insight:                                        â”‚
â”‚  If we're combining two nodes into parent,           â”‚
â”‚  we should combine the ones we'll visit least often  â”‚
â”‚  (least frequently used) to minimize depth impact    â”‚
â”‚                                                      â”‚
â”‚  Why combine smallest frequencies?                   â”‚
â”‚  â€¢ If we combine, they go deeper in final tree       â”‚
â”‚  â€¢ Depth Ã— frequency = cost increase                 â”‚
â”‚  â€¢ So we WANT least-frequent chars deep              â”‚
â”‚  â€¢ Therefore: combine smallest frequencies          â”‚
â”‚                                                      â”‚
â”‚  If we combined large frequencies instead:          â”‚
â”‚  Those chars would end up deep                       â”‚
â”‚  But they appear often!                              â”‚
â”‚  So cost would be huge (freq Ã— depth)                â”‚
â”‚  âœ— MUCH worse than huffman!                         â”‚
â”‚                                                      â”‚
â”‚  âœ“ HUFFMAN greedy choice minimizes cost              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mathematical Proof Sketch

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HUFFMAN OPTIMALITY PROOF SKETCH                   â”‚
â”‚                                                      â”‚
â”‚  Theorem: Huffman tree minimizes cost                â”‚
â”‚                                                      â”‚
â”‚  Proof idea (exchange argument):                     â”‚
â”‚                                                      â”‚
â”‚  Let O = any optimal tree                            â”‚
â”‚  Let H = Huffman tree                                â”‚
â”‚                                                      â”‚
â”‚  Step 1: In O, there must be two leaf siblings       â”‚
â”‚          with smallest frequencies fâ‚, fâ‚‚ (or else  â”‚
â”‚          we could rearrange to put small depths      â”‚
â”‚          on largest frequencies, improving O)        â”‚
â”‚                                                      â”‚
â”‚  Step 2: Huffman combines two smallest frequencies  â”‚
â”‚          creating parent node                        â”‚
â”‚                                                      â”‚
â”‚  Step 3: If O's smallest-freq pair differs from H's  â”‚
â”‚          Replace them with Huffman's pair           â”‚
â”‚          Result: new tree O' with cost â‰¤ O's cost   â”‚
â”‚          (swapping smaller frequencies improves!)    â”‚
â”‚                                                      â”‚
â”‚  Step 4: Recursively apply to remaining tree        â”‚
â”‚          Eventually transform O into H              â”‚
â”‚          showing H is optimal                        â”‚
â”‚                                                      â”‚
â”‚  Conclusion: Huffman is optimal!                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 3: HUFFMAN TREE PROPERTIES (60 minutes)

### Optimality Guarantee

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      HUFFMAN TREE: OPTIMALITY PROPERTIES             â”‚
â”‚                                                      â”‚
â”‚  Property 1: Optimal Substructure                    â”‚
â”‚  â”œâ”€ Remove any internal node from Huffman tree      â”‚
â”‚  â”œâ”€ Remaining subtree is Huffman for its chars      â”‚
â”‚  â””â”€ No better tree possible for that subset         â”‚
â”‚                                                      â”‚
â”‚  Property 2: Greedy Choice Property                  â”‚
â”‚  â”œâ”€ Two smallest-frequency nodes MUST be siblings   â”‚
â”‚  â”‚  in any optimal tree                             â”‚
â”‚  â”œâ”€ Huffman puts them as siblings                   â”‚
â”‚  â””â”€ So Huffman's first choice is in some optimal    â”‚
â”‚                                                      â”‚
â”‚  Property 3: Local Optimality â†’ Global              â”‚
â”‚  â”œâ”€ Once we make greedy choice (combine two)        â”‚
â”‚  â”œâ”€ Remaining problem is same type                  â”‚
â”‚  â”œâ”€ Solve recursively                               â”‚
â”‚  â””â”€ Gives globally optimal solution                 â”‚
â”‚                                                      â”‚
â”‚  Result: âœ“ Huffman guaranteed optimal for any       â”‚
â”‚           frequency distribution                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cost Analysis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HUFFMAN TREE: COST ANALYSIS                  â”‚
â”‚                                                      â”‚
â”‚  Input: n characters with frequencies               â”‚
â”‚                                                      â”‚
â”‚  Time Complexity: O(n log n)                        â”‚
â”‚  â”œâ”€ Create n nodes: O(n)                            â”‚
â”‚  â”œâ”€ Extract min + insert: O(log n) each             â”‚
â”‚  â”œâ”€ Do this n-1 times (combine until 1 node)       â”‚
â”‚  â”œâ”€ Total: O(n log n) with heap                     â”‚
â”‚  â””â”€ Optimal: can't do better in general             â”‚
â”‚                                                      â”‚
â”‚  Space Complexity: O(n)                             â”‚
â”‚  â”œâ”€ Store tree with n leaves                        â”‚
â”‚  â”œâ”€ Need n-1 internal nodes                         â”‚
â”‚  â”œâ”€ Total: 2n-1 nodes                               â”‚
â”‚  â””â”€ O(n) space                                       â”‚
â”‚                                                      â”‚
â”‚  Compression Ratio Achieved:                        â”‚
â”‚  â”œâ”€ Depends on character frequency distribution     â”‚
â”‚  â”œâ”€ Uniform distribution: ~logâ‚‚(n) average length  â”‚
â”‚  â”œâ”€ Skewed distribution: can approach 1 bit         â”‚
â”‚  â”œâ”€ Best case: highly skewed (few high freq)        â”‚
â”‚  â””â”€ Typically: 10-40% compression vs fixed-length   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Huffman in Practice

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        HUFFMAN CODING: REAL-WORLD USE                â”‚
â”‚                                                      â”‚
â”‚  Applications:                                       â”‚
â”‚  â€¢ JPEG compression (combines with other methods)    â”‚
â”‚  â€¢ ZIP/DEFLATE file compression                      â”‚
â”‚  â€¢ Data transmission (minimize bits)                 â”‚
â”‚  â€¢ Text compression                                  â”‚
â”‚                                                      â”‚
â”‚  Limitations:                                        â”‚
â”‚  â€¢ Requires knowing character frequencies upfront    â”‚
â”‚  â€¢ Must transmit/store code tree with data           â”‚
â”‚  â€¢ Static Huffman not adaptive                       â”‚
â”‚  â€¢ Better compression with context modeling         â”‚
â”‚                                                      â”‚
â”‚  Extensions:                                         â”‚
â”‚  â€¢ Adaptive Huffman: update tree as data processes  â”‚
â”‚  â€¢ Canonical Huffman: compact representation         â”‚
â”‚  â€¢ Arithmetic coding: better than Huffman            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 3 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DAY 3: KEY TAKEAWAYS                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ Prefix codes enable unique decoding               â”‚
â”‚  âœ“ Can represent codes as binary trees               â”‚
â”‚  âœ“ Cost = Î£ (frequency Ã— depth)                      â”‚
â”‚                                                      â”‚
â”‚  âœ“ Huffman algorithm: greedy, builds tree bottom-up  â”‚
â”‚  âœ“ Always combines two smallest frequencies          â”‚
â”‚                                                      â”‚
â”‚  âœ“ Intuition: low-freq chars go deep (minimize cost)â”‚
â”‚  âœ“ Result: optimal prefix code                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ Optimality proven via exchange argument           â”‚
â”‚  âœ“ Time: O(n log n), Space: O(n)                    â”‚
â”‚                                                      â”‚
â”‚  âœ“ Used in JPEG, ZIP, data compression               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“… DAY 4: FRACTIONAL KNAPSACK & JOB SCHEDULING
## 5 Hours | Practical Greedy Applications

---

## ğŸ“ PART 1: FRACTIONAL KNAPSACK PROBLEM (90 minutes)

### Problem Definition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       FRACTIONAL KNAPSACK PROBLEM                    â”‚
â”‚                                                      â”‚
â”‚  Given:                                              â”‚
â”‚  â€¢ n items, each with weight w_i and value v_i      â”‚
â”‚  â€¢ Knapsack capacity W (weight limit)                â”‚
â”‚  â€¢ Can take FRACTIONS of items (0 â‰¤ x_i â‰¤ 1)       â”‚
â”‚                                                      â”‚
â”‚  Goal: Maximize total value subject to:              â”‚
â”‚  Î£ (x_i Ã— w_i) â‰¤ W                                   â”‚
â”‚                                                      â”‚
â”‚  Maximize: Î£ (x_i Ã— v_i)                             â”‚
â”‚                                                      â”‚
â”‚  Key difference from 0/1 knapsack:                   â”‚
â”‚  â”œâ”€ 0/1: Take whole item or nothing                  â”‚
â”‚  â”œâ”€ Fractional: Can take partial item                â”‚
â”‚  â””â”€ This makes greedy work!                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Problem

```
Knapsack capacity: 15 kg

Items:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Item â”‚ Weight â”‚ Value  â”‚ Value/Weight â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ A    â”‚ 5 kg   â”‚ $50    â”‚ $10/kg       â”‚
â”‚ B    â”‚ 10 kg  â”‚ $60    â”‚ $6/kg        â”‚
â”‚ C    â”‚ 3 kg   â”‚ $12    â”‚ $4/kg        â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Greedy strategy: Take by VALUE/WEIGHT ratio (best bang for buck)

Selection order: A ($10/kg) â†’ B ($6/kg) â†’ C ($4/kg)

Step 1: Take all of A (5 kg, value $50)
â”œâ”€ Weight used: 5 kg
â”œâ”€ Value gained: $50
â””â”€ Capacity left: 10 kg

Step 2: Take all of B (10 kg, value $60)
â”œâ”€ Weight used: 10 kg
â”œâ”€ Value gained: $60
â”œâ”€ Total weight: 15 kg
â””â”€ Capacity left: 0 kg

Final result:
â””â”€ Total value: $50 + $60 = $110 âœ“ OPTIMAL
```

### Why Greedy by Value/Weight Ratio Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FRACTIONAL KNAPSACK: WHY GREEDY WORKS              â”‚
â”‚                                                      â”‚
â”‚  Greedy property: Take items by value/weight ratio  â”‚
â”‚  (highest first)                                     â”‚
â”‚                                                      â”‚
â”‚  Why this is optimal:                                â”‚
â”‚                                                      â”‚
â”‚  1. We want maximum value using W weight            â”‚
â”‚  2. Each kg of item i gives value v_i/w_i          â”‚
â”‚  3. To maximize total value:                        â”‚
â”‚     "Spend weight on items giving best value/kg"   â”‚
â”‚  4. Since we can take fractions:                    â”‚
â”‚     Top off knapsack with highest-ratio items       â”‚
â”‚  5. Any other strategy would use weight on           â”‚
â”‚     lower-ratio items (losing value!)                â”‚
â”‚  6. Therefore greedy is optimal!                    â”‚
â”‚                                                      â”‚
â”‚  Key insight: Because fractions allowed,             â”‚
â”‚  we can ALWAYS fill knapsack to capacity            â”‚
â”‚  with highest-ratio items (at least partially)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual: Why Fractions Make Greedy Work

```
Fractional knapsack (GREEDY WORKS):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Item A: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (full)     â”‚
â”‚ Item B: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (full)     â”‚
â”‚ Item C: â–ˆâ–ˆâ–ˆâ–ˆ (partial)      â”‚  â† Can take fraction!
â”‚         â•â•â•â• Knapsack full  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Result: Optimal!

0/1 Knapsack (GREEDY FAILS):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ If highest-ratio is small:  â”‚
â”‚ Item A: â–ˆâ–ˆâ–ˆ (must take full)â”‚
â”‚ But now can't fit others!   â”‚
â”‚ Remaining capacity wasted   â”‚
â”‚         â•â•â•â• Knapsack       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Result: NOT always optimal! (DP needed)

Key difference:
Fractional: Fill gaps with partial items
0/1: Can't fill gaps â†’ can be suboptimal
```

### Proof: Why Fractional Greedy is Optimal

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FRACTIONAL KNAPSACK OPTIMALITY PROOF              â”‚
â”‚                                                      â”‚
â”‚  Theorem: Greedy (by value/weight) is optimal       â”‚
â”‚                                                      â”‚
â”‚  Proof sketch (exchange argument):                  â”‚
â”‚                                                      â”‚
â”‚  1. Let O = any optimal solution                    â”‚
â”‚  2. Let G = greedy solution                         â”‚
â”‚  3. Sort items by value/weight: A, B, C, ...        â”‚
â”‚     (descending order)                              â”‚
â”‚                                                      â”‚
â”‚  4. CASE: O takes different item first than G      â”‚
â”‚     â”œâ”€ G takes A (highest ratio) with amount a     â”‚
â”‚     â”œâ”€ O takes something else                       â”‚
â”‚     â”œâ”€ Since A has best ratio, swapping in A       â”‚
â”‚     â”‚  improves value without increasing weight    â”‚
â”‚     â””â”€ So O wasn't optimal! Contradiction.         â”‚
â”‚                                                      â”‚
â”‚  5. CASE: O takes same items as G but different    â”‚
â”‚     amounts for some items                          â”‚
â”‚     â”œâ”€ Similar argument: O could increase          â”‚
â”‚     â”‚  lower-ratio items by higher-ratio items     â”‚
â”‚     â”‚  getting better value                        â”‚
â”‚     â””â”€ Contradiction.                               â”‚
â”‚                                                      â”‚
â”‚  6. Therefore: G must be optimal!                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 2: 0/1 vs FRACTIONAL KNAPSACK (60 minutes)

### The Critical Difference

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    0/1 KNAPSACK VS FRACTIONAL KNAPSACK               â”‚
â”‚                                                      â”‚
â”‚  0/1 Knapsack:                                       â”‚
â”‚  â€¢ Must take entire item OR nothing                  â”‚
â”‚  â€¢ Cannot divide items                               â”‚
â”‚  â€¢ NP-hard problem (no known polynomial algorithm)   â”‚
â”‚  â€¢ Requires Dynamic Programming                      â”‚
â”‚  â€¢ Example: Can't split a painting                   â”‚
â”‚                                                      â”‚
â”‚  Fractional Knapsack:                                â”‚
â”‚  â€¢ Can take fractions of items                       â”‚
â”‚  â€¢ Can divide items arbitrarily                      â”‚
â”‚  â€¢ Polynomial-time (greedy works!)                   â”‚
â”‚  â€¢ O(n log n) with sorting                           â”‚
â”‚  â€¢ Example: Can split grain/liquid                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Greedy Fails for 0/1 Knapsack

```
Counterexample: Greedy by value/weight FAILS for 0/1

Capacity: 10 kg

Items:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Item â”‚ Weight â”‚ Value  â”‚ Value/Weight â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ A    â”‚ 6 kg   â”‚ $30    â”‚ $5/kg        â”‚
â”‚ B    â”‚ 3 kg   â”‚ $14    â”‚ $4.67/kg     â”‚
â”‚ C    â”‚ 4 kg   â”‚ $16    â”‚ $4/kg        â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Greedy approach (by ratio):
1. A ($5/kg): Take (6 kg, value $30)  â†’ Remaining: 4 kg
2. B ($4.67/kg): Can't fit (needs 3 kg, have 4, OK!)
   Take (3 kg, value $14) â†’ Remaining: 1 kg
3. C ($4/kg): Can't fit (needs 4 kg, have 1)
   Skip
Total: $30 + $14 = $44

Optimal solution:
Take B (3 kg, $14) + C (4 kg, $16) = 7 kg, $30
Wait, that's $44. Let me recalculate...

Actually, let me use different example:

Items:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Item â”‚ Weight â”‚ Value  â”‚ Value/Weight â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ A    â”‚ 5 kg   â”‚ $100   â”‚ $20/kg       â”‚
â”‚ B    â”‚ 4 kg   â”‚ $80    â”‚ $20/kg       â”‚
â”‚ C    â”‚ 3 kg   â”‚ $40    â”‚ $13.33/kg    â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Capacity: 7 kg

Greedy approach:
1. A ($20/kg): Take (5 kg, value $100) â†’ Remaining: 2 kg
2. B ($20/kg): Can't fit (needs 4 kg)
3. C ($13.33/kg): Can't fit (needs 3 kg)
Total: $100

Optimal: A (5 kg, $100) OR B+C (7 kg, $120) 
âœ“ Optimal is $120 (B+C), not $100!
âœ— GREEDY FAILS! It picks A first and can't fit others.
```

### Key Insight: Why Structure Breaks

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WHY GREEDY FAILS FOR 0/1 KNAPSACK                  â”‚
â”‚                                                      â”‚
â”‚  For Fractional Knapsack:                            â”‚
â”‚  âœ“ Can take partial items                            â”‚
â”‚  âœ“ Always fill knapsack to capacity                  â”‚
â”‚  âœ“ No wasted space if all high-ratio items taken    â”‚
â”‚  âœ“ Greedy choice property holds                      â”‚
â”‚                                                      â”‚
â”‚  For 0/1 Knapsack:                                   â”‚
â”‚  âœ— Cannot take partial items                         â”‚
â”‚  âœ— May have wasted space after high-ratio items     â”‚
â”‚  âœ— Lower-ratio combinations might fit better        â”‚
â”‚  âœ— Greedy choice property FAILS!                     â”‚
â”‚                                                      â”‚
â”‚  Example: High-ratio item too large                  â”‚
â”‚  Takes up space, leaves gap no other item fits      â”‚
â”‚  But multiple lower-ratio items would fill gap      â”‚
â”‚  giving better total value!                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 3: JOB SEQUENCING WITH DEADLINES (90 minutes)

### Problem Definition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JOB SEQUENCING WITH DEADLINES PROBLEM               â”‚
â”‚                                                      â”‚
â”‚  Given:                                              â”‚
â”‚  â€¢ n jobs, each with:                                â”‚
â”‚    - Deadline d_i (must complete by this time)       â”‚
â”‚    - Profit p_i (gain if completed by deadline)      â”‚
â”‚  â€¢ Each job takes 1 unit of time                     â”‚
â”‚  â€¢ Can do at most 1 job at a time                    â”‚
â”‚                                                      â”‚
â”‚  Goal: Select subset of jobs to maximize profit      â”‚
â”‚        while meeting all deadlines                   â”‚
â”‚                                                      â”‚
â”‚  Constraints:                                        â”‚
â”‚  â€¢ If select job i with deadline d_i,                â”‚
â”‚    must schedule it in slot â‰¤ d_i                    â”‚
â”‚  â€¢ No two jobs in same time slot                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual Example

```
Jobs with deadlines and profits:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Job  â”‚ Deadline â”‚ Profit  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ J1   â”‚ 2        â”‚ $100    â”‚
â”‚ J2   â”‚ 2        â”‚ $80     â”‚
â”‚ J3   â”‚ 1        â”‚ $30     â”‚
â”‚ J4   â”‚ 3        â”‚ $60     â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Timeline visualization (3 time slots):
Time:  [Slot 1] [Slot 2] [Slot 3]
        â”â”â”â”â”â”  â”â”â”â”â”â”  â”â”â”â”â”â”

Greedy: Select by highest profit first
â”œâ”€ Select J1 (profit $100, deadline 2)
â”œâ”€ Select J2 (profit $80, deadline 2)
â”œâ”€ Select J4 (profit $60, deadline 3)
â””â”€ Skip J3 (no room by deadline 1)

Scheduling:
Time 1: [J3] â† Only job with deadline 1
Time 2: [J1] â† One of jobs with deadline 2
Time 3: [J4] â† One of jobs with deadline 3

Note: J2 ($80) cannot be scheduled (deadline 2 only)
Total profit: $30 + $100 + $60 = $190

Wait, let's try greedy by profit:
Sorted by profit: J1($100), J2($80), J4($60), J3($30)

Step 1: Select J1 (deadline 2, profit $100)
â”œâ”€ Schedule J1 at latest feasible slot before deadline 2
â”œâ”€ Latest slot: 2
â””â”€ Schedule: Time 2 â† J1

Step 2: Select J2 (deadline 2, profit $80)
â”œâ”€ Schedule at latest feasible slot before deadline 2
â”œâ”€ Latest slot: 1 (slot 2 occupied)
â””â”€ Schedule: Time 1 â† J2

Step 3: Select J4 (deadline 3, profit $60)
â”œâ”€ Schedule at latest feasible slot before deadline 3
â”œâ”€ Latest slot: 3 (slots 1,2 occupied)
â””â”€ Schedule: Time 3 â† J4

Step 4: Select J3 (deadline 1, profit $30)
â”œâ”€ Schedule at latest feasible slot before deadline 1
â”œâ”€ No slots available before/at time 1
â””â”€ Cannot include J3

Result:
Time 1: [J2] ($80)
Time 2: [J1] ($100)
Time 3: [J4] ($60)
Total profit: $240 âœ“ OPTIMAL
```

### The Greedy Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    JOB SEQUENCING GREEDY STRATEGY                    â”‚
â”‚                                                      â”‚
â”‚  Step 1: Sort jobs by PROFIT (descending)            â”‚
â”‚                                                      â”‚
â”‚  Step 2: FOR each job in profit order:               â”‚
â”‚          Find latest time slot â‰¤ deadline            â”‚
â”‚          where no job scheduled yet                  â”‚
â”‚          If found: schedule job there                â”‚
â”‚          Else: skip job (don't include)              â”‚
â”‚                                                      â”‚
â”‚  Step 3: Return all scheduled jobs                   â”‚
â”‚                                                      â”‚
â”‚  Intuition:                                           â”‚
â”‚  â€¢ Want to maximize profit â†’ pick high-profit first  â”‚
â”‚  â€¢ For each job, give it latest possible slot       â”‚
â”‚  â€¢ This leaves earlier slots for others              â”‚
â”‚  â€¢ Others might have tighter deadlines               â”‚
â”‚  â†’ best to fill latest slots with high-profit       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why "Latest Slot" Strategy Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   WHY SCHEDULE AT LATEST FEASIBLE SLOT               â”‚
â”‚                                                      â”‚
â”‚  Greedy insight: When scheduling job i with         â”‚
â”‚  deadline d_i, place it at LATEST feasible slot     â”‚
â”‚  â‰¤ d_i                                               â”‚
â”‚                                                      â”‚
â”‚  Why? (Intuitive argument)                           â”‚
â”‚                                                      â”‚
â”‚  If we schedule job i at earlier slot:              â”‚
â”‚  â€¢ Later slots still available                       â”‚
â”‚  â€¢ Future jobs might have later deadlines            â”‚
â”‚  â€¢ OR might need this job's slot!                    â”‚
â”‚  â€¢ We waste scheduling flexibility                   â”‚
â”‚                                                      â”‚
â”‚  If we schedule job i at latest slot:                â”‚
â”‚  â€¢ Earlier slots remain free                         â”‚
â”‚  â€¢ Future jobs have full range of options            â”‚
â”‚  â€¢ Maximizes flexibility for others                  â”‚
â”‚  â€¢ More jobs can fit overall                         â”‚
â”‚                                                      â”‚
â”‚  Analogy: Parking lot                                â”‚
â”‚  â€¢ New car arrives                                   â”‚
â”‚  â€¢ Park at back (latest) spot                        â”‚
â”‚  â€¢ Leaves front spots free for others                â”‚
â”‚  â€¢ Fits more cars!                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Correctness Argument

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   JOB SEQUENCING CORRECTNESS PROOF SKETCH            â”‚
â”‚                                                      â”‚
â”‚  Theorem: Greedy (sort by profit, place at          â”‚
â”‚           latest slot) gives optimal profit         â”‚
â”‚                                                      â”‚
â”‚  Proof idea:                                         â”‚
â”‚                                                      â”‚
â”‚  1. Suppose greedy solution G differs from           â”‚
â”‚     optimal solution O                               â”‚
â”‚                                                      â”‚
â”‚  2. Both have same number of jobs (both feasible     â”‚
â”‚     with deadlines), but different jobs              â”‚
â”‚                                                      â”‚
â”‚  3. Let job J_i be first where G and O differ       â”‚
â”‚     â”œâ”€ G includes job with profit p_g              â”‚
â”‚     â”œâ”€ O includes job with profit p_o < p_g        â”‚
â”‚     â””â”€ (Since G sorted by profit, p_g â‰¥ p_o)       â”‚
â”‚                                                      â”‚
â”‚  4. SWAP: Replace O's job with G's job              â”‚
â”‚     â”œâ”€ G's job has deadline that fits in O's sched â”‚
â”‚     â”œâ”€ Because G can fit it, O can too              â”‚
â”‚     â”œâ”€ But G's job worth more!                       â”‚
â”‚     â””â”€ O' now has â‰¥ profit than O                   â”‚
â”‚                                                      â”‚
â”‚  5. Continue replacing: O becomes G                  â”‚
â”‚     While maintaining â‰¥ profit                       â”‚
â”‚                                                      â”‚
â”‚  6. Therefore: G is optimal!                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 4 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DAY 4: KEY TAKEAWAYS                       â”‚
â”‚                                                      â”‚
â”‚  âœ“ Fractional Knapsack: greedy by value/weight      â”‚
â”‚  âœ“ Works because CAN take partial items             â”‚
â”‚  âœ“ Always fills knapsack to capacity                â”‚
â”‚                                                      â”‚
â”‚  âœ“ 0/1 Knapsack: greedy FAILS                        â”‚
â”‚  âœ“ Can't divide items â†’ wasted space                â”‚
â”‚  âœ“ Needs DP, not greedy                              â”‚
â”‚                                                      â”‚
â”‚  âœ“ Job Sequencing: greedy by profit                  â”‚
â”‚  âœ“ Schedule at LATEST feasible slot (maximize flex) â”‚
â”‚  âœ“ Proven optimal via exchange argument              â”‚
â”‚                                                      â”‚
â”‚  âœ“ KEY INSIGHT: Problem structure determines        â”‚
â”‚    whether greedy works!                             â”‚
â”‚  âœ“ Fractional vs 0/1 shows this clearly             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“… DAY 5: GREEDY IN SYSTEMS & INTEGRATION
## 5 Hours | Real-World Applications and Synthesis

---

## ğŸ“ PART 1: GREEDY IN NETWORK ALGORITHMS (90 minutes)

### Minimum Spanning Tree (MST): Kruskal's Algorithm

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       MINIMUM SPANNING TREE (MST) PROBLEM            â”‚
â”‚                                                      â”‚
â”‚  Given: Connected weighted undirected graph          â”‚
â”‚                                                      â”‚
â”‚  Goal: Find spanning tree (connects all vertices)    â”‚
â”‚        with MINIMUM total edge weight                â”‚
â”‚                                                      â”‚
â”‚  Application: Road networks, airlines, fiber optics  â”‚
â”‚  â”œâ”€ Vertices = cities                                â”‚
â”‚  â”œâ”€ Edges = roads/routes with distances              â”‚
â”‚  â””â”€ Find: Minimum total distance connecting all      â”‚
â”‚                                                      â”‚
â”‚  Greedy approach: Kruskal's Algorithm                â”‚
â”‚  â”œâ”€ Sort edges by weight (ascending)                â”‚
â”‚  â”œâ”€ Add edges one-by-one if no cycle formed         â”‚
â”‚  â”œâ”€ Stop when n-1 edges added (tree complete)       â”‚
â”‚  â””â”€ Result: MST!                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Kruskal's Algorithm Visualization

```
Graph with weighted edges:
     â”Œâ”€â”€â”€ A â”€â”€â”€ B â”€â”€â”€â”
     â”‚    3    2     4
     â”‚   /      \   /
     â”‚  C â”€â”€â”€â”€â”€â”€ D
     â”‚        1
     
    Edges (sorted by weight):
    1. C-D (1)
    2. A-B (2)
    3. A-C (3)
    4. B-D (4)

Kruskal's steps:
Step 1: Add C-D (weight 1)
        â””â”€ No cycle, so add it
        
        C â”€â”€â”€ D (1)
        
Step 2: Add A-B (weight 2)
        â””â”€ No cycle, so add it
        
        A â”€â”€â”€ B (2)
        C â”€â”€â”€ D (1)
        
Step 3: Add A-C (weight 3)
        â””â”€ No cycle, connects components
        
          A â”€â”€â”€ B
          â”‚ (3)
          C â”€â”€â”€ D (1)
        
Step 4: Try B-D (weight 4)
        â””â”€ WOULD CREATE CYCLE! Skip it
           All vertices connected anyway
           
Final MST:
  Total weight: 1 + 2 + 3 = 6
  Edges: {C-D, A-B, A-C}
```

### Why Kruskal's Greedy Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    WHY KRUSKAL'S GREEDY IS OPTIMAL                   â”‚
â”‚                                                      â”‚
â”‚  Greedy choice property:                             â”‚
â”‚  â€¢ Always pick smallest edge that doesn't form cycle â”‚
â”‚  â€¢ This edge MUST be in some MST                     â”‚
â”‚  â€¢ Why? If we remove it from any MST,                â”‚
â”‚    we disconnect the graph                           â”‚
â”‚  â€¢ To reconnect, need another edge                   â”‚
â”‚  â€¢ That edge weighs â‰¥ original (else would be picked)â”‚
â”‚  â€¢ So original edge is in some MST                   â”‚
â”‚                                                      â”‚
â”‚  Optimal substructure:                               â”‚
â”‚  â€¢ After adding edge, remaining graph is same type   â”‚
â”‚  â€¢ Find MST for remaining (forest)                   â”‚
â”‚  â€¢ Together = MST for original                       â”‚
â”‚                                                      â”‚
â”‚  Result: âœ“ Kruskal's is optimal!                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Prim's Algorithm (Alternative Greedy MST)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PRIM'S ALGORITHM: ALTERNATIVE MST             â”‚
â”‚                                                      â”‚
â”‚  Different greedy approach (but also optimal!)        â”‚
â”‚                                                      â”‚
â”‚  Strategy: Build MST incrementally starting from     â”‚
â”‚           any vertex, always adding cheapest edge    â”‚
â”‚           connecting tree to outside                 â”‚
â”‚                                                      â”‚
â”‚  Steps:                                               â”‚
â”‚  1. Start with arbitrary vertex (e.g., A)            â”‚
â”‚  2. WHILE tree incomplete:                           â”‚
â”‚     Find minimum-weight edge connecting             â”‚
â”‚     current tree to a vertex not yet in tree         â”‚
â”‚     Add that edge (and new vertex)                   â”‚
â”‚  3. Continue until all vertices in tree              â”‚
â”‚                                                      â”‚
â”‚  Visual:                                              â”‚
â”‚  Start: Tree = {A}                                    â”‚
â”‚         Candidates = edges from A to {B,C,D,...}    â”‚
â”‚         Pick min: say A-B (weight 2)                â”‚
â”‚                                                      â”‚
â”‚  Next: Tree = {A, B}                                 â”‚
â”‚        Candidates = edges from {A,B} to {C,D,...}   â”‚
â”‚        Pick min: say B-C (weight 3)                 â”‚
â”‚                                                      â”‚
â”‚  Continue until tree complete                        â”‚
â”‚                                                      â”‚
â”‚  Comparison with Kruskal's:                          â”‚
â”‚  â€¢ Kruskal's: Sort all edges, build forest           â”‚
â”‚  â€¢ Prim's: Grow tree from seed vertex                â”‚
â”‚  â€¢ Both greedy, both optimal!                        â”‚
â”‚  â€¢ Different strategies, same result                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 2: GREEDY IN CACHING & SYSTEMS (60 minutes)

### LRU Cache: Eviction Policy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LRU CACHE: EVICTION GREEDY                   â”‚
â”‚                                                      â”‚
â”‚  Problem: Cache has limited size                     â”‚
â”‚  When new item arrives, must evict something         â”‚
â”‚  Which item to evict?                                â”‚
â”‚                                                      â”‚
â”‚  LRU Strategy (GREEDY):                              â”‚
â”‚  "Evict Least Recently Used item"                    â”‚
â”‚                                                      â”‚
â”‚  Intuition:                                           â”‚
â”‚  â€¢ If item hasn't been used recently,                â”‚
â”‚    likely won't be used soon                         â”‚
â”‚  â€¢ So evicting it wastes nothing                     â”‚
â”‚  â€¢ Keep recently-used items (more likely to reuse)   â”‚
â”‚  â€¢ Local choice (evict LRU) seems good               â”‚
â”‚                                                      â”‚
â”‚  Note: NOT optimal for all access patterns!          â”‚
â”‚  But works well in practice (locality of reference)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LRU Cache Example

```
Cache size: 3 items
Access sequence: A, B, C, D, A, E, C, D

Step 1: Access A
        Cache: [A]
        
Step 2: Access B
        Cache: [B, A]
        
Step 3: Access C
        Cache: [C, B, A]
        
Step 4: Access D (cache full!)
        LRU item: A (accessed at time 1)
        Evict A, insert D
        Cache: [D, C, B]
        
Step 5: Access A (NOT in cache - cache miss)
        LRU item: B (accessed at time 2)
        Evict B, insert A
        Cache: [A, D, C]
        
Step 6: Access E (cache full!)
        LRU item: C (accessed at time 3)
        Evict C, insert E
        Cache: [E, A, D]
        
Step 7: Access C (NOT in cache - cache miss)
        LRU item: D (accessed at time 4)
        Evict D, insert C
        Cache: [C, E, A]
        
Step 8: Access D (NOT in cache - cache miss)
        LRU item: E (accessed at time 6)
        Evict E, insert D
        Cache: [D, C, A]

Result: 3 cache misses out of 8 accesses
Performance depends on access pattern!
```

### Why LRU is "Greedy"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LRU AS GREEDY HEURISTIC (Not optimal)            â”‚
â”‚                                                      â”‚
â”‚  Local greedy choice: "Evict item least likely      â”‚
â”‚                      to be used soon"                â”‚
â”‚                                                      â”‚
â”‚  Why it's not guaranteed optimal:                    â”‚
â”‚  â€¢ Doesn't predict future accesses                   â”‚
â”‚  â€¢ Only reacts to past behavior                      â”‚
â”‚  â€¢ Could have long gap between current & next use   â”‚
â”‚                                                      â”‚
â”‚  Why it works well in practice:                      â”‚
â”‚  â€¢ Real access patterns have locality                â”‚
â”‚  â€¢ If used recently, likely to use again soon        â”‚
â”‚  â€¢ Temporal locality common in programs              â”‚
â”‚  â€¢ Programs access same data repeatedly              â”‚
â”‚                                                      â”‚
â”‚  Optimal (offline) algorithm:                        â”‚
â”‚  "Evict item used furthest in future"                â”‚
â”‚  But requires knowing future! (impossible online)    â”‚
â”‚                                                      â”‚
â”‚  LRU is good online approximation!                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 3: WHEN GREEDY FAILS (60 minutes)

### Examples Where Greedy Fails

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     WHEN GREEDY FAILS: IMPORTANT PATTERNS            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example 1: Coin Change with Non-Standard Denominations
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Coins: 1, 3, 4
Target: 6 cents

Greedy (largest first):
Pick 4 â†’ Remaining 2
Pick 1 â†’ Remaining 1
Pick 1 â†’ Remaining 0
Total: 3 coins

Optimal:
Pick 3 â†’ Remaining 3
Pick 3 â†’ Remaining 0
Total: 2 coins â† BETTER!

Why fails: Picking largest coin creates bad remainder


Example 2: Maximum Path in DAG
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Graph:     A â”€10â†’ B â”€1â†’ C
           â””â”€â”€2â”€â”€â†’ C

Greedy (always pick heaviest edge from current):
Start A: Pick 10 â†’ reach B
From B: Pick 1 â†’ reach C
Total: 11

Optimal: 
A â†’ C directly: 2
Wait, that's worse. Let me recalculate...

Actually: A â†’ B (10) â†’ C (1) = 11, which is optimal here.

Let me use better example:
           A â”€1â†’ B â”€10â†’ C
           â””â”€â”€2â”€â”€â†’ C

Greedy (always pick locally best):
From A: Pick edge to B (1)? Or to C (2)?
If greedy picks "longest looking" (max remaining potential):
- B path: 1 + potential(10) = promising
- C path: 2 direct
Greedy might pick Bâ†’C (1+10=11)

But alternative: Aâ†’C (2) direct
For this problem, (11 > 2), so greedy wins.

Real example that fails:
           A â”€100â†’ B â”€1â†’ C
           â””â”€â”€100â†’ D â”€101â†’ C

Greedy maximizes locally:
Pick Aâ†’B (100) â†’ Pick Bâ†’C (1) = 101 total

Optimal:
Pick Aâ†’D (100) â†’ Pick Dâ†’C (101) = 201 total â† BETTER!

Why fails: Greedy doesn't look ahead enough


Example 3: Coloring Graph with Min Colors
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Graph: Triangle (3 vertices, all connected)
Minimum colors needed: 3

Greedy (color vertices in order):
Vertex 1: Color 1
Vertex 2: Color 2 (can't use 1)
Vertex 3: Color 3 (can't use 1 or 2)
Total: 3 colors â† Optimal by luck

Different graph:
Vertex 1 connects to: 2, 3, 4, 5, 6 (star)
Others don't connect to each other

Minimum colors: 2 (center 1 color, all others another color)

Greedy (color in order 1,2,3,4,5,6):
Vertex 1: Color 1
Vertices 2,3,4,5,6: All connect to 1
Greedy colors them Color 2 (since they don't connect to each other)
Total: 2 colors â† Optimal

But change ordering:
Greedy (in order 6,5,4,3,2,1):
Vertex 6: Color 1
Vertex 5: Color 1 (doesn't connect to 6)
Vertex 4: Color 1 (doesn't connect to 5,6)
... all get color 1 except need to separate from center
Actually this also works...

Real failing example (Welsh-Powell):
Greedy graph coloring with bad vertex ordering
Can use 4 colors when 3 suffice
```

### Pattern: When Greedy Fails

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    RECOGNIZING WHEN GREEDY FAILS                     â”‚
â”‚                                                      â”‚
â”‚  Red flag 1: Problem is NP-hard                      â”‚
â”‚  â”œâ”€ 0/1 Knapsack: NP-hard                            â”‚
â”‚  â”œâ”€ TSP: NP-hard                                     â”‚
â”‚  â”œâ”€ Vertex coloring: NP-hard                         â”‚
â”‚  â”œâ”€ Greedy usually fails for these                   â”‚
â”‚  â””â”€ Need DP or heuristics instead                    â”‚
â”‚                                                      â”‚
â”‚  Red flag 2: Local choice conflicts with global      â”‚
â”‚  â”œâ”€ Example: Coin change                             â”‚
â”‚  â”œâ”€ Greedy coin too large                            â”‚
â”‚  â”œâ”€ Creates bad remainder                            â”‚
â”‚  â”œâ”€ Other coins are better globally                  â”‚
â”‚  â””â”€ Greedy choice property fails                     â”‚
â”‚                                                      â”‚
â”‚  Red flag 3: Problem lacks optimal substructure      â”‚
â”‚  â”œâ”€ After greedy choice, remaining problem          â”‚
â”‚  â”œâ”€ is NOT same type or                              â”‚
â”‚  â”œâ”€ is NOT independent of greedy choice              â”‚
â”‚  â””â”€ Can't recurse to build optimal                   â”‚
â”‚                                                      â”‚
â”‚  Red flag 4: Problem requires lookahead              â”‚
â”‚  â”œâ”€ Optimal choice depends on future                 â”‚
â”‚  â”œâ”€ Greedy can't predict future                      â”‚
â”‚  â”œâ”€ Example: Maximum path in graph                   â”‚
â”‚  â””â”€ Need DP for lookahead                            â”‚
â”‚                                                      â”‚
â”‚  When to try greedy:                                 â”‚
â”‚  âœ“ Problem is polynomial-time (P)                    â”‚
â”‚  âœ“ Has greedy choice property (provable!)            â”‚
â”‚  âœ“ Has optimal substructure                          â”‚
â”‚  âœ“ Can prove or show with examples                   â”‚
â”‚                                                      â”‚
â”‚  When to use DP instead:                             â”‚
â”‚  âœ— Problem is NP-hard                                â”‚
â”‚  âœ— Greedy fails on examples                          â”‚
â”‚  âœ— Overlapping subproblems present                   â”‚
â”‚  âœ— Need to try multiple choices (not just one)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PART 4: APPROXIMATION ALGORITHMS & GREEDY HEURISTICS (60 minutes)

### When Optimal is Hard: Use Greedy Approximation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GREEDY AS APPROXIMATION FOR NP-HARD                â”‚
â”‚                                                      â”‚
â”‚  Problem: Many real problems are NP-hard             â”‚
â”‚  â”œâ”€ 0/1 Knapsack                                     â”‚
â”‚  â”œâ”€ Traveling Salesman Problem (TSP)                â”‚
â”‚  â”œâ”€ Set Cover                                        â”‚
â”‚  â”œâ”€ Vertex Coloring                                  â”‚
â”‚  â””â”€ No known polynomial-time optimal algorithms      â”‚
â”‚                                                      â”‚
â”‚  Solution: Use APPROXIMATION ALGORITHMS              â”‚
â”‚  â”œâ”€ Greedy algorithm runs fast                       â”‚
â”‚  â”œâ”€ Gives "good enough" solution (not optimal)       â”‚
â”‚  â”œâ”€ Can prove it's within factor of optimal         â”‚
â”‚  â””â”€ Example: "Guarantee â‰¤ 2Ã— optimal"                â”‚
â”‚                                                      â”‚
â”‚  Practical approach:                                  â”‚
â”‚  â”œâ”€ For small inputs: try exact (DP, brute force)    â”‚
â”‚  â”œâ”€ For large inputs: use greedy approximation       â”‚
â”‚  â””â”€ Often good enough in practice                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Set Cover Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SET COVER PROBLEM                            â”‚
â”‚                                                      â”‚
â”‚  Given: Universe U of n elements                     â”‚
â”‚         Collection of m sets Sâ‚, Sâ‚‚, ..., S_m        â”‚
â”‚         Each set covers some elements                â”‚
â”‚                                                      â”‚
â”‚  Goal: Select minimum number of sets such that      â”‚
â”‚        their union equals U (covers all elements)    â”‚
â”‚                                                      â”‚
â”‚  Application: TV channels (sets) that cover           â”‚
â”‚             viewers' interests (elements)            â”‚
â”‚  â”œâ”€ Channel A covers interests: {sports, news}       â”‚
â”‚  â”œâ”€ Channel B covers interests: {news, drama}        â”‚
â”‚  â”œâ”€ Channel C covers interests: {sports, drama}      â”‚
â”‚  â””â”€ Select min channels covering all interests       â”‚
â”‚                                                      â”‚
â”‚  NP-hard: No known polynomial algorithm              â”‚
â”‚                                                      â”‚
â”‚  Greedy Approximation:                               â”‚
â”‚  1. Start with uncovered elements U                  â”‚
â”‚  2. WHILE uncovered elements remain:                 â”‚
â”‚     a. Pick set covering most uncovered elements    â”‚
â”‚     b. Mark its elements as covered                  â”‚
â”‚     c. Add set to solution                           â”‚
â”‚  3. Return solution                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Set Cover Example

```
Universe: {A, B, C, D, E, F}

Sets:
Sâ‚ = {A, B, C}
Sâ‚‚ = {B, D, E}
Sâ‚ƒ = {E, F}
Sâ‚„ = {A, D, F}
Sâ‚… = {C, E, F}

Greedy approach (pick max coverage each step):

Step 1: Which set covers most elements?
â”œâ”€ Sâ‚: 3 elements {A,B,C}
â”œâ”€ Sâ‚‚: 3 elements {B,D,E}
â”œâ”€ Sâ‚ƒ: 2 elements
â”œâ”€ Sâ‚„: 3 elements
â”œâ”€ Sâ‚…: 3 elements
Pick Sâ‚ (or any with 3): covers {A,B,C}
Covered: {A,B,C}
Uncovered: {D,E,F}

Step 2: Which set covers most UNCOVERED?
â”œâ”€ Sâ‚: 0 new elements (already picked)
â”œâ”€ Sâ‚‚: 2 new {D,E}
â”œâ”€ Sâ‚ƒ: 1 new {F}
â”œâ”€ Sâ‚„: 2 new {D,F}
â”œâ”€ Sâ‚…: 2 new {E,F}
Pick Sâ‚‚ (or Sâ‚„, Sâ‚…): covers 2 new
Covered: {A,B,C,D,E}
Uncovered: {F}

Step 3: Which set covers most UNCOVERED?
â”œâ”€ Sâ‚ƒ: 1 new {F}
â”œâ”€ Sâ‚„: 1 new {F}
â”œâ”€ Sâ‚…: 1 new {F}
Pick any: Sâ‚ƒ
Covered: All
Uncovered: {}

Greedy solution: Sâ‚, Sâ‚‚, Sâ‚ƒ
Total sets: 3

Optimal solution:
Sâ‚ {A,B,C} + Sâ‚‚ {B,D,E} + Sâ‚ƒ {E,F}? No, just need 2:
Sâ‚‚ {B,D,E} + Sâ‚„ {A,D,F} + ??? need C
Actually: Sâ‚ {A,B,C} + Sâ‚‚ {B,D,E} covers all but F
No single set covers F without covering others already covered,
so need 3 sets minimum

Greedy matches optimal here!

Theorem: Greedy gives â‰¤ ln(n) Ã— optimal for set cover
For n=6: â‰¤ 2.59 Ã— optimal
Usually much closer in practice!
```

---

## ğŸ“ PART 5: INTEGRATION & PARADIGM SYNTHESIS (60 minutes)

### Greedy Algorithm Design Checklist

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      WHEN TO USE GREEDY: DECISION CHECKLIST          â”‚
â”‚                                                      â”‚
â”‚  âœ“ Can I identify a clear local choice?              â”‚
â”‚  âœ“ Do I have intuition it leads to global optimum?   â”‚
â”‚  âœ“ Can I prove greedy choice property?               â”‚
â”‚    (Does some optimal solution contain this choice?) â”‚
â”‚  âœ“ Does optimal substructure hold?                   â”‚
â”‚    (After choice, remaining is same-type problem?)   â”‚
â”‚  âœ“ Can I prove it rigorously? Exchange argument?     â”‚
â”‚                                                      â”‚
â”‚  If YES to most â†’ Try greedy                         â”‚
â”‚  If NO to most â†’ Try DP or other paradigm            â”‚
â”‚                                                      â”‚
â”‚  If NP-hard proven â†’ Greedy approximation acceptable â”‚
â”‚  If not proven NP â†’ Could still try greedy           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comparing Greedy with Other Paradigms

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ALGORITHM PARADIGMS: WHEN TO USE EACH              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GREEDY                                              â”‚
â”‚ â”œâ”€ Use when: Optimal substructure + greedy choice  â”‚
â”‚ â”œâ”€ Examples: Activity selection, Huffman, MST      â”‚
â”‚ â”œâ”€ Time: Usually O(n log n) or better              â”‚
â”‚ â”œâ”€ Space: Usually O(n)                              â”‚
â”‚ â””â”€ Proof: Exchange argument, stay-ahead            â”‚
â”‚                                                     â”‚
â”‚ DYNAMIC PROGRAMMING                                â”‚
â”‚ â”œâ”€ Use when: Overlapping subproblems               â”‚
â”‚ â”œâ”€ Examples: 0/1 knapsack, LCS, coin change        â”‚
â”‚ â”œâ”€ Time: Often O(nÂ²) to O(nÂ³)                      â”‚
â”‚ â”œâ”€ Space: Often O(nÂ²)                              â”‚
â”‚ â””â”€ Proof: Induction on DP recurrence               â”‚
â”‚                                                     â”‚
â”‚ BACKTRACKING                                        â”‚
â”‚ â”œâ”€ Use when: Search all possibilities               â”‚
â”‚ â”œâ”€ Examples: N-queens, permutations, sudoku        â”‚
â”‚ â”œâ”€ Time: O(2â¿) worst case (exponential)            â”‚
â”‚ â”œâ”€ Space: O(n) recursion depth                      â”‚
â”‚ â””â”€ Proof: Completeness of DFS                      â”‚
â”‚                                                     â”‚
â”‚ DIVIDE & CONQUER                                    â”‚
â”‚ â”œâ”€ Use when: Problem breaks into independent parts â”‚
â”‚ â”œâ”€ Examples: Merge sort, quick sort, FFT           â”‚
â”‚ â”œâ”€ Time: Usually O(n log n)                        â”‚
â”‚ â”œâ”€ Space: Often O(n)                               â”‚
â”‚ â””â”€ Proof: Induction on recursion depth             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Common Mistakes and How to Avoid

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    COMMON GREEDY MISTAKES & FIXES                    â”‚
â”‚                                                      â”‚
â”‚ Mistake 1: Assume greedy works without proving      â”‚
â”‚ â”œâ”€ Many problems LOOK greedy but aren't optimal    â”‚
â”‚ â”œâ”€ Example: Coin change, 0/1 knapsack               â”‚
â”‚ â”œâ”€ Fix: Always prove or test on examples            â”‚
â”‚ â””â”€ Test: Try counterexample before coding           â”‚
â”‚                                                      â”‚
â”‚ Mistake 2: Choosing wrong greedy criterion          â”‚
â”‚ â”œâ”€ Example: Sort by weight instead of value/weight â”‚
â”‚ â”œâ”€ Different criterion â†’ different result            â”‚
â”‚ â”œâ”€ Fix: Understand problem intimately               â”‚
â”‚ â””â”€ Think: What metric should we optimize?           â”‚
â”‚                                                      â”‚
â”‚ Mistake 3: Not handling ties/edge cases             â”‚
â”‚ â”œâ”€ When multiple elements have same metric          â”‚
â”‚ â”œâ”€ Different choices â†’ potentially different resultsâ”‚
â”‚ â”œâ”€ Fix: Ensure algorithm works for all orderings   â”‚
â”‚ â””â”€ Think: Does choice of tie-breaker matter?        â”‚
â”‚                                                      â”‚
â”‚ Mistake 4: Assuming polynomial time means greedy   â”‚
â”‚ â”œâ”€ Just because problem is polynomial               â”‚
â”‚ â”œâ”€ Doesn't mean greedy works!                       â”‚
â”‚ â”œâ”€ Example: Some scheduling problems are polynomial â”‚
â”‚                but need DP                          â”‚
â”‚ â”œâ”€ Fix: Prove specific problem has greedy propertiesâ”‚
â”‚ â””â”€ Think: Does this particular problem allow it?    â”‚
â”‚                                                      â”‚
â”‚ Mistake 5: Not considering complexity               â”‚
â”‚ â”œâ”€ Greedy trade-off: simple but not always optimal â”‚
â”‚ â”œâ”€ DP more powerful but slower                      â”‚
â”‚ â”œâ”€ Fix: Consider input size and time limits         â”‚
â”‚ â””â”€ Think: Is correctness or speed more important?   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DAY 5 & WEEK 12 SUMMARY

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     WEEK 12: COMPLETE SUMMARY                        â”‚
â”‚     GREEDY ALGORITHMS & PROOFS MASTERY               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DAY 1: GREEDY FUNDAMENTALS
âœ“ Greedy makes locally optimal choices at each step
âœ“ NOT always globally optimal (must prove!)
âœ“ TWO properties needed for correctness:
  1. Optimal substructure
  2. Greedy choice property
âœ“ Exchange argument: proves greedy works
âœ“ 5-step proof strategy for correctness

DAY 2: ACTIVITY SELECTION & INTERVALS
âœ“ Activity Selection: classic greedy problem
âœ“ Sort by finish time, greedily select non-overlapping
âœ“ "Greedy stays ahead" proof pattern
âœ“ Variations: weighted (fails), room assignment (works)
âœ“ Different problems need different greedy criteria

DAY 3: HUFFMAN CODING
âœ“ Prefix codes enable unique decoding
âœ“ Codes represented as binary trees
âœ“ Cost = Î£(frequency Ã— depth)
âœ“ Huffman: greedily combine two smallest frequencies
âœ“ Bottom-up tree construction gives optimal prefix code
âœ“ O(n log n) time, O(n) space

DAY 4: FRACTIONAL KNAPSACK & JOB SCHEDULING
âœ“ Fractional Knapsack: greedy by value/weight ratio
âœ“ Works because CAN take fractions (fills to capacity)
âœ“ 0/1 Knapsack: greedy FAILS (can't divide)
âœ“ Job Scheduling: greedy by profit, place at latest slot
âœ“ Latest slot maximizes flexibility for remaining jobs

DAY 5: REAL-WORLD APPLICATIONS & INTEGRATION
âœ“ Kruskal's & Prim's: MST via greedy
âœ“ LRU cache: greedy eviction heuristic (not optimal but good)
âœ“ When greedy fails: NP-hard problems, no greedy property
âœ“ Greedy approximation: O(log n) guarantee for set cover
âœ“ Choose paradigm: greedy fast, DP powerful, backtrack complete

KEY INSIGHTS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. GREEDY IS POWERFUL BUT DANGEROUS
   â€¢ Can solve problems optimally in polynomial time
   â€¢ But ONLY if problem has right structure
   â€¢ Must verify with proof or counterexamples

2. PROBLEM STRUCTURE DETERMINES APPROACH
   â€¢ Same-looking problems need different algorithms
   â€¢ Example: Fractional (greedy) vs 0/1 (DP) knapsack
   â€¢ Understand problem deeply!

3. PROOF IS ESSENTIAL
   â€¢ Never assume greedy works without proving
   â€¢ Exchange argument is standard technique
   â€¢ "Stay ahead" pattern common in proofs

4. WHEN TO USE:
   â€¢ Problem polynomial-time solvable âœ“
   â€¢ Can identify clear local choice âœ“
   â€¢ Can prove greedy choice property âœ“
   â€¢ Can prove optimal substructure âœ“
   â€¢ Then: Try greedy!

5. REAL-WORLD USE:
   â€¢ Some problems: want optimal (greedy/DP)
   â€¢ Some problems: want fast approximation (greedy)
   â€¢ Some problems: need exact exponential search
   â€¢ Choose based on problem needs!

MASTERY CHECKLIST:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â–¡ Understand greedy algorithm template
â–¡ Can write exchange argument proofs
â–¡ Know: optimal substructure + greedy choice property
â–¡ Solve activity selection variations
â–¡ Understand Huffman coding completely
â–¡ Know when fractional knapsack greedy works
â–¡ Can prove job scheduling greedy is optimal
â–¡ Recognize MST problems (Kruskal/Prim)
â–¡ Understand LRU cache as greedy heuristic
â–¡ Know patterns where greedy fails
â–¡ Can choose between greedy/DP/backtrack

NEXT STEPS (Week 13):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â†’ Backtracking: Systematic search with pruning
â†’ Branch & Bound: Optimization via search
â†’ Amortized Analysis: Cost analysis across operations
â†’ Integration: When to combine paradigms
```

---

# ğŸ“Š WEEK 12 LEARNING PROGRESSION

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         DIFFICULTY PROGRESSION BY DAY                â”‚
â”‚                                                      â”‚
â”‚ Day 1: ğŸŸ¢ GREEN (Fundamentals)                       â”‚
â”‚ â”œâ”€ Greedy concept: intuitive, easy to understand     â”‚
â”‚ â”œâ”€ Template and properties: pattern recognition      â”‚
â”‚ â””â”€ Exchange argument: proof technique (challenging)  â”‚
â”‚                                                      â”‚
â”‚ Day 2: ğŸŸ¡ YELLOW (Application)                       â”‚
â”‚ â”œâ”€ Activity selection: clean, canonical problem      â”‚
â”‚ â”œâ”€ "Stay ahead" pattern: elegant proof               â”‚
â”‚ â””â”€ Interval variations: deeper understanding         â”‚
â”‚                                                      â”‚
â”‚ Day 3: ğŸŸ¡ YELLOW (Specialized)                       â”‚
â”‚ â”œâ”€ Huffman coding: concrete, visual                  â”‚
â”‚ â”œâ”€ Tree construction: bottom-up greedy               â”‚
â”‚ â””â”€ Optimality: exchange argument again               â”‚
â”‚                                                      â”‚
â”‚ Day 4: ğŸŸ  ORANGE (Advanced Applications)             â”‚
â”‚ â”œâ”€ Fractional vs 0/1: contrast understanding         â”‚
â”‚ â”œâ”€ Job scheduling: optimal slot selection            â”‚
â”‚ â””â”€ Problem structure importance: key insight         â”‚
â”‚                                                      â”‚
â”‚ Day 5: ğŸ”´ RED (Integration & Analysis)               â”‚
â”‚ â”œâ”€ MST algorithms: multiple greedy approaches        â”‚
â”‚ â”œâ”€ Greedy failures: recognize patterns               â”‚
â”‚ â”œâ”€ Approximation: use greedy when optimal hard       â”‚
â”‚ â””â”€ Synthesis: choose right paradigm                  â”‚
â”‚                                                      â”‚
â”‚ MASTERY OUTCOME:                                     â”‚
â”‚ âœ“ Understand greedy deeply                           â”‚
â”‚ âœ“ Can design greedy algorithms                       â”‚
â”‚ âœ“ Can write rigorous proofs                          â”‚
â”‚ âœ“ Know limitations and failures                      â”‚
â”‚ âœ“ Ready for backtracking & advanced topics!          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š RECOMMENDED STUDY MATERIALS

### Conceptual Resources
- Exchange argument deep-dive: practice transforming optimal solutions
- Visual debugging: draw trees, timelines, priority queues
- Pattern recognition: study multiple greedy problems to see connections

### Practice Approach
1. Study concept first (why and what)
2. Draw diagrams and visualizations
3. Trace through examples step-by-step
4. Identify greedy choice criterion
5. Attempt informal correctness argument
6. Read formal proof
7. Try to write proof independently

### Common Pitfalls to Avoid
- âŒ Don't assume greedy without proof
- âŒ Don't confuse greedy with DP
- âŒ Don't pick wrong optimality criterion
- âŒ Don't skip tie-breaking rules
- âŒ Don't ignore edge cases

---

**Week 12 Complete! Ready for Week 13: Backtracking & Branch & Bound**
