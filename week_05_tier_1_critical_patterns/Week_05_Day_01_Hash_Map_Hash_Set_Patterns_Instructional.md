# üìö Week 05 Day 01: Hash Map / Hash Set Patterns (Instructional)

**Week:** 5 | **Day:** 1 | **Tier:** Tier 1 Critical Patterns  
**Topics:** Hash Map Patterns, Hash Set Deduplication, Frequency Counting  
**Duration:** 4-5 hours | **Difficulty:** üü° Medium  
**MIT Connection:** Hashing fundamentals from 6.006

---

## üéØ CHAPTER 1: CONTEXT & MOTIVATION

### Why Hash Patterns Matter

Hash maps and hash sets are ubiquitous in algorithmic problems. Nearly **25-30% of interview questions** leverage hash-based patterns because:

1. **Constant-time lookup** (O(1) average): Makes many "find" or "check existence" problems trivial
2. **Frequency counting**: Natural way to aggregate data
3. **Complement patterns**: Solve pairs/triplets efficiently
4. **Deduplication**: Remove duplicates in a single pass

**Real-world context:** Every search engine, cache system, and data structure library relies on hashing.

### Problems Hash Solves

Before Week 05, if you had a problem like "find two numbers that sum to target," you might:
- ‚ùå Brute force: O(n¬≤) ‚Äî check every pair
- ‚úÖ (After sorting + two-pointer from Week 04): O(n log n) ‚Äî sort then search

But with **hash-based thinking**, you can:
- ‚úÖ Hash-based complement: O(n) ‚Äî one pass, store complements in a set

This pattern works for:
- **Two-sum, three-sum variants**
- **Finding complements** (anagrams, pairs)
- **Frequency-based problems** (top-K, majority element)
- **Membership tests** (is element in set? is word valid?)

### Week 05 Position in Curriculum

**Week 04** gave you foundational patterns (two-pointer, sliding window, divide & conquer, binary search).
**Week 05** adds **high-frequency tactical patterns** (hash, monotonic stack, intervals, partition, Kadane, fast/slow).

These five patterns account for ~60% of real interview problems. Master Week 05, and you've covered most of what interviewers ask.

---

## üß† CHAPTER 2: BUILDING THE MENTAL MODEL

### Hash Map Fundamentals (Quick Review)

A **hash map** (or dictionary in C#) maps keys to values:

```
Hash Map: { "alice": 25, "bob": 30, "charlie": 28 }
         Key     Value

Operations:
- INSERT:  map["alice"] = 25         ‚Üí O(1) average
- LOOKUP:  int age = map["alice"]    ‚Üí O(1) average
- DELETE:  map.Remove("alice")       ‚Üí O(1) average
- CHECK:   if (map.ContainsKey(...)) ‚Üí O(1) average
```

A **hash set** is a special case: keys with no values (or dummy values):

```
Hash Set: { "alice", "bob", "charlie" }

Operations:
- ADD:     set.Add("alice")           ‚Üí O(1) average
- CONTAINS: set.Contains("alice")     ‚Üí O(1) average (binary vs. linear!)
- REMOVE:  set.Remove("alice")        ‚Üí O(1) average
```

### Three Core Hash Patterns

#### Pattern A: Complement Lookup

**Core Idea:** For each element, check if its "complement" exists.

```
Example: Two-Sum(nums, target)
  For each num in nums:
    complement = target - num
    If complement exists in set, FOUND!
    Else add num to set

Time: O(n), Space: O(n)
Why beats sorting+two-pointer: No sort needed, pure iteration
```

**Invariant:** At each step, we've either found a pair or we've stored this element for future checking.

#### Pattern B: Frequency Counting

**Core Idea:** Count occurrences; answer queries based on counts.

```
Example: Top-K Frequent Elements
  1. Count frequencies: { elem: count }
  2. Group by count: { count: [elems] }
  3. Extract top-K

Time: O(n + k) for counting and extraction
Why matters: Frequency is the key to many problems
```

**Use cases:**
- "Find most common element" ‚Üí frequency count
- "Remove elements with frequency < k" ‚Üí count and filter
- "Are these two strings anagrams?" ‚Üí count chars in both, compare

#### Pattern C: Membership & Deduplication

**Core Idea:** Use a set to track "seen" items; skip duplicates.

```
Example: Remove Duplicates (array form)
  seen = { }
  For each element:
    If element in seen, skip
    Else add to result and seen

Time: O(n), Space: O(n) for set
Why matters: One-pass, clean logic
```

### Mental Model: When to Use Hash

```
Question Type                    Use Hash?   Why
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
"Does X exist?"                  YES         O(1) membership
"Count occurrences of X"         YES         Frequency map
"Find pairs/triplets"            YES         Complement lookup
"Remove duplicates"              YES         Set for seen items
"Group by property"              YES         Dict with key=property
"Is this possible in one pass?"  YES         Likely needs hash
"Two arrays, find common"        YES         Hash first, check second
"Cache/memoize results"          YES         Dict stores results
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
```

---

## üîß CHAPTER 3: MECHANICS & IMPLEMENTATION

### Implementation Pattern 1: Two-Sum via Complement

**Problem:** Given array and target, find two indices that sum to target.

```csharp
public class TwoSumComplement
{
    public static int[] TwoSum(int[] nums, int target)
    {
        var seen = new HashSet<int>();
        
        for (int i = 0; i < nums.Length; i++)
        {
            int complement = target - nums[i];
            
            // If complement exists, we found a pair
            if (seen.Contains(complement))
            {
                return new int[] { 
                    Array.IndexOf(nums, complement), 
                    i 
                };
            }
            
            seen.Add(nums[i]);
        }
        
        return new int[] { };  // No pair found
    }
}
```

**Trace Example:** `nums = [2, 7, 11, 15], target = 9`

```
i=0: num=2, complement=7, seen={}, no match, add 2 ‚Üí seen={2}
i=1: num=7, complement=2, seen={2}, MATCH! Return [0, 1]
```

**Invariant:** Before checking nums[i], all nums[0..i-1] are in `seen`.

---

### Implementation Pattern 2: Frequency Counting & Top-K

**Problem:** Find k most frequent elements.

```csharp
public class TopKFrequent
{
    public static int[] TopK(int[] nums, int k)
    {
        // Step 1: Count frequencies
        var freqMap = new Dictionary<int, int>();
        foreach (int num in nums)
        {
            if (freqMap.ContainsKey(num))
                freqMap[num]++;
            else
                freqMap[num] = 1;
        }
        
        // Step 2: Group by frequency
        var freqBuckets = new Dictionary<int, List<int>>();
        foreach (var kvp in freqMap)
        {
            int num = kvp.Key;
            int freq = kvp.Value;
            
            if (!freqBuckets.ContainsKey(freq))
                freqBuckets[freq] = new List<int>();
            freqBuckets[freq].Add(num);
        }
        
        // Step 3: Extract top-K (iterate from highest frequency)
        var result = new List<int>();
        for (int freq = nums.Length; freq > 0 && result.Count < k; freq--)
        {
            if (freqBuckets.ContainsKey(freq))
            {
                result.AddRange(freqBuckets[freq]);
            }
        }
        
        return result.ToArray();
    }
}
```

**Trace Example:** `nums = [1, 1, 1, 2, 2, 3], k = 2`

```
Step 1: Frequencies ‚Üí {1: 3, 2: 2, 3: 1}
Step 2: Buckets ‚Üí {3: [1], 2: [2], 1: [3]}
Step 3: Top-K ‚Üí [1, 2]
```

**Why bucket sort:** Instead of sorting O(n log n), we bucket into frequency counts (max frequency = n), then iterate buckets. Linear time!

---

### Implementation Pattern 3: Anagram Grouping

**Problem:** Group strings that are anagrams of each other.

```csharp
public class GroupAnagrams
{
    public static List<List<string>> Anagrams(string[] words)
    {
        var groups = new Dictionary<string, List<string>>();
        
        foreach (string word in words)
        {
            // Key: sorted characters (canonical form)
            char[] chars = word.ToCharArray();
            Array.Sort(chars);
            string canonical = new string(chars);
            
            if (!groups.ContainsKey(canonical))
                groups[canonical] = new List<string>();
            
            groups[canonical].Add(word);
        }
        
        return new List<List<string>>(groups.Values);
    }
}
```

**Trace Example:** `words = ["eat", "tea", "ate", "bat", "tab"]`

```
"eat" ‚Üí canonical "aet" ‚Üí groups["aet"] = ["eat"]
"tea" ‚Üí canonical "aet" ‚Üí groups["aet"] = ["eat", "tea"]
"ate" ‚Üí canonical "aet" ‚Üí groups["aet"] = ["eat", "tea", "ate"]
"bat" ‚Üí canonical "abt" ‚Üí groups["abt"] = ["bat"]
"tab" ‚Üí canonical "abt" ‚Üí groups["abt"] = ["bat", "tab"]

Result: [["eat", "tea", "ate"], ["bat", "tab"]]
```

**Key insight:** Two strings are anagrams iff their sorted forms are identical. Use sorted form as key.

---

### Implementation Pattern 4: Valid Anagram Check

**Problem:** Check if two strings are anagrams.

```csharp
public class ValidAnagram
{
    public static bool IsAnagram(string s, string t)
    {
        if (s.Length != t.Length) return false;
        
        var charCount = new Dictionary<char, int>();
        
        // Count characters in s
        foreach (char c in s)
        {
            if (charCount.ContainsKey(c))
                charCount[c]++;
            else
                charCount[c] = 1;
        }
        
        // Decrement for characters in t
        foreach (char c in t)
        {
            if (!charCount.ContainsKey(c))
                return false;
            
            charCount[c]--;
            if (charCount[c] < 0)
                return false;
        }
        
        // All counts should be 0
        return true;
    }
}
```

**Trace Example:** `s = "listen", t = "silent"`

```
Count from s: {l: 1, i: 1, s: 1, t: 1, e: 1, n: 1}
Check t:
  - s: {l: 1, i: 1, s: 0, t: 1, e: 1, n: 1}
  - i: {l: 1, i: 0, s: 0, t: 1, e: 1, n: 1}
  - l: {l: 0, i: 0, s: 0, t: 1, e: 1, n: 1}
  - e: {l: 0, i: 0, s: 0, t: 1, e: 0, n: 1}
  - n: {l: 0, i: 0, s: 0, t: 1, e: 0, n: 0}
  - t: {l: 0, i: 0, s: 0, t: 0, e: 0, n: 0}
All zeros ‚Üí True (anagrams!)
```

---

### Implementation Pattern 5: Majority Element

**Problem:** Find element appearing more than n/2 times (guaranteed to exist).

```csharp
public class MajorityElement
{
    public static int FindMajority(int[] nums)
    {
        var countMap = new Dictionary<int, int>();
        int target = nums.Length / 2;
        
        foreach (int num in nums)
        {
            if (countMap.ContainsKey(num))
                countMap[num]++;
            else
                countMap[num] = 1;
            
            // Early exit
            if (countMap[num] > target)
                return num;
        }
        
        return -1;  // Should never reach (guaranteed to exist)
    }
}
```

**Why hash works:** One pass through array, track counts, return when count exceeds n/2.

**Bonus:** Boyer-Moore Voting (uses no extra space) ‚Äî mentioned in advanced section.

---

## üìà CHAPTER 4: PERFORMANCE & REAL-WORLD SYSTEMS

### Time Complexity Comparison

| Problem | Naive | Hash-Based |
|---------|-------|-----------|
| Two-Sum | O(n¬≤) | O(n) |
| Top-K Frequent | O(n log n) | O(n) |
| Anagrams | O(n log n) | O(n) |
| Majority Element | O(n log n) | O(n) |

### Space-Time Trade-off

**Hash-based solutions trade space for time:**

```
Two-Sum:
- Array-only (sorted): O(1) space, O(n log n) time
- Hash-based: O(n) space, O(n) time ‚Üê Usually preferred
```

**Interview principle:** Time is more valuable than space (modern machines have lots of RAM).

### Hash Collisions & Load Factor

In practice, hash functions occasionally collide:

```
Hash collision: Two different keys hash to same bucket
  Example: hash("alice") = hash("bob") = bucket 5

Handling (C# Dictionary does this internally):
  - Chaining: Store multiple items in same bucket
  - Open addressing: Probe for next empty bucket
  - Load factor: When capacity/(size) exceeds threshold, resize
```

**For this week:** Trust your language's implementation. Understand that worst-case O(n) exists (adversarial inputs), but average-case O(1) is guaranteed in practice.

### Real-world Application: Cache Systems

```csharp
// LRU Cache (simplified)
public class LRUCache
{
    private Dictionary<int, int> cache;
    private int capacity;
    
    // When accessing:
    // - Check if key in cache (O(1))
    // - Return value if found
    // - Evict least-recently-used if capacity exceeded
    
    // Hash map: Find item in O(1)
    // Linked list: Track LRU order
}
```

---

## üåç CHAPTER 5: INTEGRATION & MASTERY

### Five Cognitive Lenses for Hash Patterns

**1. Lookup Lens:** Every "does X exist?" problem
- "Is word valid?" ‚Üí Hash set of valid words
- "Seen before?" ‚Üí Hash set tracks visited

**2. Pairing Lens:** Every "find two that satisfy property" problem
- "Sum to target?" ‚Üí Complement in hash set
- "Form valid pair?" ‚Üí Store first item, check for second

**3. Frequency Lens:** Every "count" or "top-k" problem
- "Most common?" ‚Üí Count frequencies
- "Remove infrequent?" ‚Üí Filter by threshold

**4. Grouping Lens:** Every "partition by property" problem
- "Group anagrams?" ‚Üí Hash map key=sorted
- "Group by type?" ‚Üí Hash map key=type

**5. De-duplication Lens:** Every "remove duplicates" problem
- "Unique elements?" ‚Üí Hash set
- "First unique?" ‚Üí Frequency + find first with count=1

### Misconceptions & Traps

‚ùå **Misconception 1:** "Hash is always O(1)"
‚úÖ **Reality:** Average O(1), worst-case O(n). Trust your language's library.

‚ùå **Misconception 2:** "Hash uses more space than needed"
‚úÖ **Reality:** Justified by time savings. One 1M-element pass beats sorting.

‚ùå **Misconception 3:** "Hash only works on integer keys"
‚úÖ **Reality:** Works on any hashable object (strings, tuples, custom objects).

‚ùå **Misconception 4:** "Two-pointer is always better than hash"
‚úÖ **Reality:** Two-pointer requires sorted input. Hash works on unsorted.

---

## üéØ CHAPTER 6: INTERVIEW PATTERNS & EXTENSIONS

### Common Interview Questions Using Hash

**Question 1: Two-Sum**
- "Given array and target, find two numbers that sum to target"
- **Hash solution:** One pass, store complements
- **LeetCode:** 1 (Easy)

**Question 2: Contains Duplicate**
- "Check if array has duplicates"
- **Hash solution:** Add to set; if already there, return true
- **LeetCode:** 217 (Easy)

**Question 3: Valid Anagram**
- "Check if s and t are anagrams"
- **Hash solution:** Count characters, compare
- **LeetCode:** 242 (Easy)

**Question 4: Top K Frequent Elements**
- "Return k most frequent elements"
- **Hash solution:** Frequency + bucket sort
- **LeetCode:** 347 (Medium)

**Question 5: Group Anagrams**
- "Group strings that are anagrams"
- **Hash solution:** Key = sorted characters
- **LeetCode:** 49 (Medium)

### Extension: Hash Sets vs. Hash Maps

| Need | Use | Example |
|------|-----|---------|
| Membership only | Hash Set | "Is word valid?" |
| Need value | Hash Map | "What's the count?" |
| Track order | Linked Dict | "What was first?" |

---

## ‚úÖ CHAPTER 7: MASTERY CHECKLIST

By end of Day 01, you should be able to:

- ‚òê Recognize "complement" problems (two-sum variants)
- ‚òê Implement two-sum in O(n) using hash set
- ‚òê Recognize "frequency" problems (top-K, majority)
- ‚òê Count character frequencies and compare (anagrams)
- ‚òê Use hash maps to group by key (group anagrams)
- ‚òê Explain time-space trade-off of hash vs. sorting
- ‚òê Identify when hash is better than two-pointer
- ‚òê Solve 4+ problems without solution hints
- ‚òê Explain hash collisions and load factors (conceptual)

---

## üìù CHAPTER 8: PRACTICE PROBLEMS & LeetCode MAPPING

### Day 01 Practice (Easy ‚Üí Medium)

| # | Problem | Difficulty | Pattern | LeetCode |
|---|---------|-----------|---------|----------|
| 1 | Two-Sum | Easy | Complement | 1 |
| 2 | Contains Duplicate | Easy | Set membership | 217 |
| 3 | Valid Anagram | Easy | Frequency count | 242 |
| 4 | Two-Sum II (sorted) | Easy | Complement | 167 |
| 5 | Majority Element | Easy | Frequency | 169 |
| 6 | Top K Frequent | Medium | Frequency + buckets | 347 |
| 7 | Group Anagrams | Medium | Hash grouping | 49 |
| 8 | First Unique Character | Medium | Frequency + iteration | 387 |

---

## üöÄ NEXT STEPS

**After Day 01:**
- ‚úÖ Solve all 8 problems
- ‚úÖ Understand trade-offs (hash vs. sorting)
- ‚úÖ Be ready for Day 02 (monotonic stack)

**Estimated time:** 4-5 hours (1.5 hrs reading + 2.5 hrs practice)

---

**Week 05 Day 01 Complete. Hash patterns are your tactical weapon for fast problem-solving.**

Generated: January 08, 2026  
Quality: Production-Grade  
Length: ~4,000 words

