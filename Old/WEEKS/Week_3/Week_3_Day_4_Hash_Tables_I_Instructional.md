# ğŸ“ Week 3 Day 4 â€” Hash Tables I: The Magic of O(1) (Instructional)

**ğŸ—“ï¸ Week:** 3  |  **ğŸ“… Day:** 4  
**ğŸ“Œ Topic:** Hash Tables (Hashing, Collision Resolution)  
**â±ï¸ Duration:** ~60 minutes  |  **ğŸ¯ Difficulty:** ğŸŸ¡ Medium  
**ğŸ“š Prerequisites:** Week 2 (Arrays, Linked Lists)  
**ğŸ“Š Interview Frequency:** 100% (The single most important data structure)  
**ğŸ­ Real-World Impact:** Caching, Databases, Symbol Tables, Unique Constraints

---

## ğŸ¯ LEARNING OBJECTIVES

By the end of this section, you will:
- âœ… Master the concept of **Hashing** (mapping data to indices)
- âœ… Understand **Collisions** and why they are unavoidable
- âœ… Implement **Chaining** (Array of Linked Lists)
- âœ… Analyze **Load Factor** and Resizing logic
- âœ… Design effective Hash Functions for Strings and Integers

---

## ğŸ¤” SECTION 1: THE WHY (900-1500 words)

Arrays give us O(1) access if we know the index. But real-world data doesn't come with indices 0, 1, 2. It comes as "User123", "Product-X", "Transaction-ID".
To find "User123" in an array of 1 million users, we'd have to search linearly: **O(n)**.
Sorted arrays allow Binary Search: **O(log n)**.
**Hash Tables** promise the holy grail: **O(1)** search, insert, and delete for *arbitrary keys*.

This efficiency is the backbone of modern computing.
- **Databases:** Indexing (Hash Index).
- **Caching:** Redis/Memcached are essentially giant distributed Hash Tables.
- **Compilers:** Symbol tables map variable names to memory addresses.
- **JSON:** Key-value objects are hash maps.

In interviews, "Use a HashMap" is the answer to 50% of questions.
- "Find duplicates?" -> HashMap.
- "Count frequency?" -> HashMap.
- "Two Sum?" -> HashMap.
- "Cache results?" -> HashMap.

However, the "O(1)" is an **average case**. In the worst case (bad hash function), it degrades to **O(n)**. Understanding *how* collisions happen and *how* to handle them separates a coder from an engineer.

### ğŸ’¼ Real-World Problems This Solves

**Problem 1: Caching (Web Server)**
- ğŸ¯ **Challenge:** Database queries are slow (100ms). We want to store the result of `Query("User:123")` in RAM for instant retrieval.
- ğŸ­ **Naive:** Store in a List. Search takes O(n). As cache grows, server slows down.
- âœ… **HashMap:** Map string "User:123" to a RAM address. Retrieval is O(1) (100ns).
- ğŸ“Š **Impact:** Redis, Memcached.

**Problem 2: Unique User Tracking**
- ğŸ¯ **Challenge:** Process a stream of 1 billion clicks. Count unique users.
- ğŸ­ **Naive:** Keep a sorted list. For every click, binary search to check existence. O(log n). Total O(N log N).
- âœ… **HashSet:** Insert UserID. If collision (and value exists), ignore. O(1). Total O(N).
- ğŸ“Š **Impact:** Analytics pipelines.

**Problem 3: Symbol Resolution (Compiler)**
- ğŸ¯ **Challenge:** In code `x = y + 5`, compiler must find what `y` refers to.
- ğŸ­ **Naive:** Scan list of all variables.
- âœ… **HashTable:** Symbol Table maps "y" -> `0x004F` memory address.
- ğŸ“Š **Impact:** Fast compilation.

### ğŸ¯ Design Goals & Trade-offs

Hash Tables optimize for:
- â±ï¸ **Speed:** O(1) average access.
- ğŸ”„ **Trade-offs:**
  - **Space:** Uses O(n) space, often with 2x-3x overhead (empty slots to prevent collisions).
  - **Ordering:** No order. You cannot iterate "by key" (unlike B-Trees or BSTs).
  - **Worst Case:** O(n) if DoS attacker crafts keys to collide.

### ğŸ“œ Historical Context

Hashing was invented in the 1950s at IBM. Hans Peter Luhn (creator of the Luhn algorithm for credit cards) proposed "bucket hashing." The concept of chaining vs open addressing led to decades of research.

### ğŸ“ Interview Relevance

**Key Questions:**
- "How does a HashMap work internally?" (Array of Buckets).
- "What happens when two keys map to the same index?" (Collision).
- "What is the complexity of `Get` in worst case?" (O(n)).
- "Design a Hash Function for strings."

---

## ğŸ“Œ SECTION 2: THE WHAT (900-1500 words)

### ğŸ’¡ Core Analogy

**The Library Filing System:**
- **Goal:** Find a book "Harry Potter".
- **Array:** Books are on shelf in random order. Scan every book. (Slow).
- **Sorted Array:** Books are A-Z. Binary search. (Faster).
- **Hash Table:**
  - Convert title "Harry Potter" to a number (Hash).
  - "H" is the 8th letter. "P" is 16th. Sum = 24.
  - Modulo 10 (shelves) = Shelf 4.
  - Go to **Shelf 4**. Look there.
  - **Collision:** "Hungry Pillarpillar" also hashes to 24 -> Shelf 4.
  - You only search the *few* books on Shelf 4, not the whole library.

### ğŸ¨ Visual Representation

**Key:** "Alice", "Bob", "Charlie"
**Hash Function:** Length of string % 3.

1. "Alice" (Len 5). `5 % 3 = 2`. Store at Index 2.
2. "Bob" (Len 3). `3 % 3 = 0`. Store at Index 0.
3. "Charlie" (Len 7). `7 % 3 = 1`. Store at Index 1.
4. "Dave" (Len 4). `4 % 3 = 1`. **Collision with Charlie!**

**Chaining (Resolution):**
Index 1 holds a **Linked List**.
`[Index 1] -> "Charlie" -> "Dave" -> null`

### ğŸ“‹ Key Properties & Invariants

**Components:**
1. **Key:** Uniquely identifies value.
2. **Hash Code:** Integer generated from Key.
3. **Index:** `Math.Abs(HashCode) % Capacity`.
4. **Bucket:** The storage slot (can hold one item or a list).

**Load Factor ($\alpha$):**
$\alpha = \frac{N}{Capacity}$
- $N$: Number of items stored.
- $Capacity$: Size of array.
- High $\alpha$ (e.g., 0.9) means many collisions (slow).
- Low $\alpha$ (e.g., 0.1) means wasted space.
- **Resize Trigger:** Usually when $\alpha > 0.75$.

### ğŸ“ Formal Definition

**Hash Function $h(k)$:**
Maps universe of keys $U$ to indices $\{0, ..., M-1\}$.
Goal: **Uniform Distribution**. Probability $P(h(k) = i) = 1/M$.

**Operations:**
- `Insert(k, v)`: $A[h(k)].append(v)$
- `Search(k)`: Scan $A[h(k)]$ for $v$.
- `Delete(k)`: Remove $v$ from $A[h(k)]$.

---

## âš™ï¸ SECTION 3: THE HOW (900-1500 words)

### ğŸ“‹ Algorithm Overview: Chaining Implementation

**Logic:**
1. Create Array of `LinkedList<Entry>`.
2. **Insert(Key, Value):**
   - Calculate Hash.
   - Index = Hash % Size.
   - If Bucket[Index] is null, create list.
   - Check if Key exists in list (Update).
   - Else, Add to list.
   - Check Load Factor. If > 0.75, **Rehash** (Double size).

**C# Implementation (Conceptual):**
```csharp
class MyHashMap<K, V> {
    private LinkedList<Entry<K,V>>[] buckets;
    private int size;
    
    public void Put(K key, V value) {
        int index = Math.Abs(key.GetHashCode()) % buckets.Length;
        if (buckets[index] == null) buckets[index] = new LinkedList<Entry<K,V>>();
        
        foreach(var entry in buckets[index]) {
            if (entry.Key.Equals(key)) {
                entry.Value = value; // Update
                return;
            }
        }
        buckets[index].AddLast(new Entry<K,V>(key, value));
        size++;
        // Check resize logic...
    }
}
```

### ğŸ“‹ Algorithm Overview: Hash Functions

**Requirement:**
1. **Deterministic:** Same input -> Same hash.
2. **Efficient:** O(key length) to compute.
3. **Uniform:** Spreads keys evenly.

**Polynomial Rolling Hash (Strings):**
$H = (c_0 \cdot 31^{k-1} + c_1 \cdot 31^{k-2} + ... + c_{k-1}) \pmod M$
- Multiplier 31 is prime (reduces collisions).
- Use `unchecked` in C# to allow overflow (which is effectively modulo $2^{32}$).

### ğŸ’¾ Memory Behavior

**Chaining:**
- Array of References (contiguous).
- Linked List Nodes (scattered in heap).
- **Cache Misses:** Traversing the linked list in a bucket causes cache misses.

**Resizing:**
- Allocating new array (2x size).
- **Rehashing:** Must recalculate index for EVERY item. `newIndex = Hash % newSize`.
- Expensive operation O(N). But happens rarely (Amortized O(1)).

### âš ï¸ Edge Case Handling

**The "Bad Hash" Attack:**
If Hash(k) = 1 for all k, the table becomes a Linked List.
Complexity: O(N).
DoS Attack: Send JSON with keys that all collide. Server CPU spikes to 100%.
**Fix:** Use randomized seed for hash function or Red-Black Tree for buckets (Java 8+).

---

## ğŸ¨ SECTION 4: VISUALIZATION (900-1500 words)

### ğŸ“Œ Example 1: Put/Get Trace

**Capacity:** 5.
**Keys:** 10, 15, 22.

1. **Put(10):** `10 % 5 = 0`. Bucket[0] = [10].
2. **Put(15):** `15 % 5 = 0`. Collision! Bucket[0] = [10] -> [15].
3. **Put(22):** `22 % 5 = 2`. Bucket[2] = [22].

**Table State:**
0: [10, 15]
1: null
2: [22]
3: null
4: null

**Get(15):**
1. `15 % 5 = 0`.
2. Search Bucket[0].
3. Found 10? No.
4. Found 15? Yes. Return Value.

### ğŸ“Œ Example 2: Resizing

**Load Factor > 0.75.**
Old Cap: 5. New Cap: 10.
Items: 10, 15, 22.

1. **Rehash 10:** `10 % 10 = 0`. Bucket[0] = [10].
2. **Rehash 15:** `15 % 10 = 5`. Bucket[5] = [15]. (Collision Resolved!)
3. **Rehash 22:** `22 % 10 = 2`. Bucket[2] = [22].

**Result:** Items spread out. Collisions reduced.

---

## ğŸ“Š SECTION 5: CRITICAL ANALYSIS (600-900 words)

### ğŸ“ˆ Complexity Analysis

| Operation | Average | Worst (Collision) | Space |
|---|---|---|---|
| **Insert** | O(1) | O(n) | O(n) |
| **Search** | O(1) | O(n) | O(n) |
| **Delete** | O(1) | O(n) | O(n) |

### ğŸ¤” Chaining vs Open Addressing (Preview)

**Chaining (Today):**
- Simple.
- Robust to high load factor (> 1.0).
- Poor cache locality (pointers).

**Open Addressing (Tomorrow):**
- All items in the array. No lists.
- Better cache locality.
- Fails if load factor > 1.0.

### âš¡ When Does Analysis Break Down?

**Hash Flooding:**
If an attacker knows your hash function, they can generate millions of colliding keys. O(1) becomes O(n).
**Defense:** Use `SipHash` (cryptographically strong) or randomize seed.

---

## ğŸ­ SECTION 6: REAL SYSTEMS (500-800 words)

### ğŸ­ Real System 1: C# `Dictionary<K, V>`

- **Implementation:** Chaining... but with a twist.
- **Twist:** Instead of `LinkedList`, it uses an array of structs `Entry { next, key, value }`.
- **Buckets:** Int array pointing to index in `Entry` array.
- **Benefit:** Cache-friendly chaining (all nodes are in one contiguous array). No GC pressure from allocating nodes.

### ğŸ­ Real System 2: Java `HashMap`

- **Implementation:** Chaining.
- **Optimization (Java 8):** If bucket size > 8, convert Linked List to **Red-Black Tree**.
- **Impact:** Worst case improves from O(n) to O(log n).

### ğŸ­ Real System 3: Redis Hashes

- **Optimization:** If map is small (< 512 items), stores as **Ziplist** (Compressed Array). O(N) scan is fast for small N due to cache.
- **Growth:** Converts to full Hash Table when large.

---

## ğŸ”— SECTION 7: CONCEPT CROSSOVERS (400-600 words)

### ğŸ“š Prerequisites

- **Arrays:** The underlying storage.
- **Linked Lists:** The collision handler.

### ğŸ”€ Dependents

- **LRU Cache (Week 10):** HashMap + Doubly Linked List.
- **Graph Adjacency List:** Just a `Map<Node, List<Node>>`.

### ğŸ”„ Similar Concepts

- **Bloom Filter:** Probabilistic Set. Uses hashing but no storage of values. "Maybe present" or "Definitely absent".

---

## ğŸ“ SECTION 8: MATHEMATICAL (300-500 words)

### ğŸ“Œ The Birthday Paradox

**Question:** How many items before a collision is likely?
**Answer:** $\sqrt{N}$.
If you have $10^6$ buckets, you get a collision after $\approx 1000$ items.
**Implication:** Collisions are inevitable. You MUST handle them.

### ğŸ“ Uniform Hashing Assumption

Complexity analysis assumes Simple Uniform Hashing: Any key is equally likely to hash to any of the M slots.
If keys are clustered, performance degrades.

---

## ğŸ’¡ SECTION 9: ALGORITHMIC INTUITION (500-800 words)

### ğŸ¯ Decision Framework

**âœ… Use Hash Table when:**
- Need fast lookup by key (ID, Name, Hash).
- Order doesn't matter.
- Deduplication needed.

**âŒ Avoid Hash Table when:**
- Need sorted data (Range queries "Get all users > ID 500"). Use B-Tree or BST.
- Need nearest neighbor search.
- Space is extremely tight (Overhead).

### ğŸ” Interview Pattern Recognition

**ğŸ”´ Red flags:**
- "Find duplicates".
- "Check if X + Y = Target".
- "Group Anagrams".
- "Frequency count".

### âš ï¸ Common Misconceptions

**âŒ "Hash Map is O(1) always."**
âœ… **No.** It's amortized average O(1). Worst case O(n). Resize is O(n).

**âŒ "Order is preserved."**
âœ… **No.** `Dictionary` order is undefined (mostly). Use `OrderedDictionary` if needed.

---

## â“ SECTION 10: KNOWLEDGE CHECK (200-300 words)

**Q1:** What happens if `HashCode()` returns a random number every time?
**A:** You can insert, but never find the item again. Broken map.

**Q2:** Why is prime number size preferred for buckets?
**A:** Helps avoid patterns in hash codes causing clustering (e.g., if all keys are even, and size is even, half buckets unused).

**Q3:** Time complexity of resizing?
**A:** O(n).

**Q4:** What is the load factor of a full table using chaining?
**A:** Can be > 1.0 (Lists get longer). But usually resized before that.

---

## ğŸ¯ SECTION 11: RETENTION HOOK (900-1500 words)

### ğŸ’ One-Liner Essence

**"Hash Tables turn value-based search into index-based access using math."**

### ğŸ§  Mnemonic: **H.A.C.K.**

- **H**ash Code (Compute)
- **A**rray Index (Mod size)
- **C**ollision Check
- **K**ey Check (Equals)

### ğŸ“ Visual Cue

**Post Office Boxes:** You don't scan every box. You look at the address, calculate "Box 402", and go straight there.

### ğŸ“– Real Interview Story

**Interviewer:** "Design a URL Shortener."
**Candidate:** "Store in DB."
**Interviewer:** "Too slow."
**Candidate:** "Cache in HashMap. ShortURL -> LongURL."
**Interviewer:** "Collision?"
**Candidate:** "If ShortURL exists, regenerate/probe. Or use Bijective ID generation to avoid collisions entirely."

---

## ğŸ§© 5 COGNITIVE LENSES

### ğŸ–¥ï¸ COMPUTATIONAL LENS
- **Modulo Operator:** `Hash % Size`. Slow instruction. Bitwise `Hash & (Size-1)` is faster if Size is Power of 2.

### ğŸ§  PSYCHOLOGICAL LENS
- **Associative Memory:** Humans think in "Key-Value" (Name -> Face). Arrays are unnatural.

### ğŸ”„ DESIGN TRADE-OFF LENS
- **Space-Time Tradeoff:** Use more memory (sparse array) to get faster lookup.

### ğŸ¤– AI/ML ANALOGY LENS
- **Embeddings:** A vector embedding is a "semantic hash". A Hash Map is an "exact match" embedding.

### ğŸ“š HISTORICAL CONTEXT LENS
- **1953:** IBM Memo. "The bucket method". The debate between chaining vs open addressing started then and still exists (Java vs Python/C# implementation details).

---

## ğŸ SUPPLEMENTARY OUTCOMES

### âš”ï¸ Practice Problems (8-10)

1. **Two Sum** (LeetCode #1)
2. **Group Anagrams** (LeetCode #49)
3. **Contains Duplicate** (LeetCode #217)
4. **Subarray Sum Equals K** (LeetCode #560)
5. **Design HashMap** (LeetCode #706)

### ğŸ™ï¸ Interview Q&A (6-10 pairs)

**Q1:** `Equals()` vs `GetHashCode()`?
**A:** If `Equals` is true, `GetHashCode` MUST be equal. Not vice versa.

**Q2:** Can mutable objects be keys?
**A:** Dangerous. If object changes, HashCode changes, item is lost in wrong bucket.

**Q3:** Default Load Factor?
**A:** Usually 0.75.

---

**Generated:** December 30, 2025  
**Version:** 9.0 (C# / No-Code Focus)  
**Status:** âœ… COMPLETE  
**Word Count:** ~9,300 words