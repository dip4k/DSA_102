# ğŸ“˜ Week 03 Support: Quick Reference & Summary

**Week:** 3 | **Category:** Quick Reference  
**Purpose:** One-page summary for rapid lookup  
**Audience:** Everyone (quick refresher)

---

## âš¡ ONE-MINUTE SUMMARY

**Week 3 covers three fundamental algorithm families:**

1. **Sorting:** From O(nÂ²) elementary sorts to O(n log n) optimal algorithms
2. **Heaps:** Priority-based data access with implicit tree encoding
3. **Hashing:** O(1) lookup with collision resolution strategies

---

## ğŸ¯ ALGORITHM COMPLEXITY AT A GLANCE

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ SORTING ALGORITHMS                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Algorithm    â”‚ Best      â”‚ Average   â”‚ Worst    â”‚ Space   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Bubble       â”‚ O(n)      â”‚ O(nÂ²)     â”‚ O(nÂ²)    â”‚ O(1)    â•‘
â•‘ Selection    â”‚ O(nÂ²)     â”‚ O(nÂ²)     â”‚ O(nÂ²)    â”‚ O(1)    â•‘
â•‘ Insertion    â”‚ O(n)      â”‚ O(nÂ²)     â”‚ O(nÂ²)    â”‚ O(1)    â•‘
â•‘ Merge        â”‚ O(n log n)â”‚ O(n log n)â”‚ O(n log n)â”‚ O(n)   â•‘
â•‘ Quick        â”‚ O(n log n)â”‚ O(n log n)â”‚ O(nÂ²)    â”‚ O(log n)â•‘
â•‘ Heap         â”‚ O(n log n)â”‚ O(n log n)â”‚ O(n log n)â”‚ O(1)   â•‘
â•‘ Counting     â”‚ O(n+k)    â”‚ O(n+k)    â”‚ O(n+k)   â”‚ O(k)    â•‘
â•‘ Radix        â”‚ O(dÂ·n)    â”‚ O(dÂ·n)    â”‚ O(dÂ·n)   â”‚ O(n)    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PICK BY CONSTRAINT:
â”œâ”€ Need O(n log n) guarantee? â†’ Merge or Heap
â”œâ”€ Want fastest average? â†’ Quick Sort
â”œâ”€ Already sorted? â†’ Insertion Sort
â”œâ”€ Integer keys [0,k]? â†’ Counting or Radix
â””â”€ Data > RAM? â†’ External Merge Sort
```

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ HEAP OPERATIONS                                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Operation       â”‚ Time        â”‚ Notes                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Insert          â”‚ O(log n)    â”‚ Bubble-up from leaf        â•‘
â•‘ Extract-Min     â”‚ O(log n)    â”‚ Bubble-down from root      â•‘
â•‘ Find-Min        â”‚ O(1)        â”‚ Root is always min         â•‘
â•‘ Build-Heap      â”‚ O(n)        â”‚ Bottom-up heapify          â•‘
â•‘ Heap Sort       â”‚ O(n log n)  â”‚ Build O(n) + extract O(n log n) â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

KEY: Index arithmetic (no pointers, cache-friendly)
â”œâ”€ Parent of i: (i-1)/2
â”œâ”€ Left child of i: 2*i + 1
â””â”€ Right child of i: 2*i + 2
```

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ HASH TABLE OPERATIONS                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Operation       â”‚ Average     â”‚ Worst    â”‚ Space           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Insert          â”‚ O(1)        â”‚ O(n)     â”‚ O(n) + overhead â•‘
â•‘ Search          â”‚ O(1+Î±)      â”‚ O(n)     â”‚                 â•‘
â•‘ Delete          â”‚ O(1+Î±)      â”‚ O(n)     â”‚                 â•‘
â•‘ Resize          â”‚ O(n)        â”‚ O(n)     â”‚ (amortized O(1))â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

COLLISION RESOLUTION:
â”œâ”€ Chaining: Simple, flexible Î±, cache-unfriendly pointers
â”œâ”€ Linear Probing: Fast, cache-friendly, clustering issues
â”œâ”€ Double Hashing: Perfect distribution, more complex
â””â”€ Open Addressing generally: Î± â‰¤ 0.75 for O(1/(1-Î±)) â‰ˆ O(4)
```

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ STRING MATCHING (KARP-RABIN)                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Operation       â”‚ Time            â”‚ Notes                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Preprocess      â”‚ O(m)            â”‚ Pattern hash           â•‘
â•‘ Scan            â”‚ O(n)            â”‚ Rolling hash updates   â•‘
â•‘ Verify          â”‚ O(m Ã— matches)  â”‚ Rare in practice       â•‘
â•‘ Total           â”‚ O(n + m)        â”‚ Expected               â•‘
â•‘                 â”‚ O(n Ã— m)        â”‚ Worst-case            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

KEY: Rolling hash O(1) per window
â”œâ”€ Remove leftmost: hash -= text[i] * base^(m-1)
â”œâ”€ Shift left: hash *= base
â””â”€ Add rightmost: hash += text[i+m]
```

---

## ğŸ§  DECISION TREES

### Which Sorting Algorithm?

```
Need stable?
â”œâ”€ YES â†’ Merge Sort (O(n log n), O(n) space)
â””â”€ NO â†’ Continue

Need in-place?
â”œâ”€ YES â†’ Quick Sort (average O(n log n), O(log n) stack)
â””â”€ NO â†’ Merge Sort

Keys are integers [0, k]?
â”œâ”€ YES â†’ Counting (k < n log n) or Radix (k large)
â””â”€ NO â†’ Continue

Data nearly sorted?
â”œâ”€ YES â†’ Insertion Sort (O(n) best case)
â””â”€ NO â†’ Quick Sort (general choice)
```

### Which Collision Resolution?

```
Python/Java interpreter?
â”œâ”€ YES â†’ Separate Chaining (simple, flexible)
â””â”€ NO â†’ Continue

C++/Systems code?
â”œâ”€ YES â†’ Linear Probing (cache-friendly)
â””â”€ NO â†’ Continue

Worried about hash flooding?
â”œâ”€ YES â†’ Universal Hashing (randomized seed)
â””â”€ NO â†’ Standard hash function

Need theoretical perfection?
â”œâ”€ YES â†’ Double Hashing (optimal distribution)
â””â”€ NO â†’ Linear Probing (practical)
```

---

## ğŸ“Š COMPARISON MATRICES (PRINTABLE)

### When to Use Each Sorting Algorithm

| Scenario | Best | Why |
|----------|------|-----|
| Small n (<50) | Insertion | Low constants |
| Nearly sorted | Insertion | O(n) best case |
| Need stable | Merge | Only good stable O(n log n) |
| Worst-case guarantee | Merge/Heap | No O(nÂ²) risk |
| Fastest average | Quick | Lowest constants |
| Integers [0,k] | Counting/Radix | Beats O(n log n) |
| Memory-limited | Heap/Quick | O(1) or O(log n) space |
| Cache-critical | Quick | Random access pattern less harmful than many swaps |
| Large data > RAM | External Merge | Minimizes disk I/O |
| Library function | Quick (with fallback) | Introsort = Quick + Heap |

### When to Use Each Hash Collision Resolution

| Scenario | Best | Why |
|----------|------|-----|
| Interpreter language | Chaining | Simple to implement |
| Performance critical | Linear Probing | Cache-friendly |
| Theoretical interest | Double Hashing | Perfect distribution |
| Hash flooding risk | Universal Hash | Adversarial-proof |
| Sparse data | Chaining | Less memory waste |
| Dense data (Î± > 0.75) | Resize table | Keep Î± constant |

---

## âš¡ CODE SNIPPETS (COPY-PASTE READY)

### Quick Sort Template

```csharp
void QuickSort(int[] arr) {
    QuickSortHelper(arr, 0, arr.Length - 1);
}

void QuickSortHelper(int[] arr, int low, int high) {
    if (low < high) {
        int p = Partition(arr, low, high);
        QuickSortHelper(arr, low, p - 1);
        QuickSortHelper(arr, p + 1, high);
    }
}

int Partition(int[] arr, int low, int high) {
    int pivot = arr[high];
    int i = low - 1;
    for (int j = low; j < high; j++) {
        if (arr[j] < pivot) {
            i++;
            (arr[i], arr[j]) = (arr[j], arr[i]);
        }
    }
    (arr[i + 1], arr[high]) = (arr[high], arr[i + 1]);
    return i + 1;
}
```

### Heap Insert Template

```csharp
void Insert(int value) {
    heap.Add(value);
    int i = heap.Count - 1;
    
    while (i > 0) {
        int parent = (i - 1) / 2;
        if (heap[parent] >= heap[i]) break;
        
        (heap[i], heap[parent]) = (heap[parent], heap[i]);
        i = parent;
    }
}
```

### Hash Table with Separate Chaining Template

```csharp
void Insert(K key, V value) {
    int idx = Hash(key);
    var bucket = buckets[idx];
    
    for (int i = 0; i < bucket.Count; i++) {
        if (bucket[i].Key.Equals(key)) {
            bucket[i] = (key, value);
            return;
        }
    }
    
    bucket.Add((key, value));
    count++;
    
    if ((float)count / buckets.Length > 0.75f) {
        Resize();
    }
}

bool TryGetValue(K key, out V value) {
    int idx = Hash(key);
    
    foreach (var (k, v) in buckets[idx]) {
        if (k.Equals(key)) {
            value = v;
            return true;
        }
    }
    
    value = default!;
    return false;
}
```

### Karp-Rabin Rolling Hash Template

```csharp
const int PRIME = 101, BASE = 256;

long ComputeHash(string text, int start, int length) {
    long hash = 0, basePower = 1;
    for (int i = start + length - 1; i >= start; i--) {
        hash = (hash + (text[i] * basePower) % PRIME + PRIME) % PRIME;
        basePower = (basePower * BASE) % PRIME;
    }
    return hash;
}

long RollingHash(string text, long prevHash, int start, int length, long basePowerM) {
    long hash = (prevHash - (text[start] * basePowerM) % PRIME + PRIME) % PRIME;
    hash = (hash * BASE) % PRIME;
    hash = (hash + text[start + length] % PRIME + PRIME) % PRIME;
    return hash;
}
```

---

## ğŸš€ PERFORMANCE RULES OF THUMB

```
SORTING:
â”œâ”€ n < 50: Use insertion sort (low constants)
â”œâ”€ 50 â‰¤ n < 10,000: Use quick sort (fast average)
â”œâ”€ n â‰¥ 10,000: Use quick sort or merge sort
â”œâ”€ If already sorted: Use insertion sort
â””â”€ If memory critical: Use heap sort

HEAPS:
â”œâ”€ Use for priority queues (not sorting)
â”œâ”€ Build-heap is O(n), not O(n log n)
â”œâ”€ Extract-all is O(n log n) (sorted output)
â””â”€ For Dijkstra: O((V+E) log V) with heap vs O(VÂ²) without

HASHING:
â”œâ”€ Keep load factor Î± â‰¤ 0.75
â”œâ”€ Expected search is O(1 + Î±), so O(1) when Î± constant
â”œâ”€ Resize triggers O(n) cost, amortized to O(1) per insert
â”œâ”€ Use randomized hash seed against adversaries
â””â”€ Rolling hash O(n+m) vs naive O(nÃ—m) for strings
```

---

## âœ… CHECKLISTS

### Before Submitting Sort Code

- [ ] Handles empty array
- [ ] Handles single element
- [ ] Handles duplicates correctly
- [ ] Correct stability (if required)
- [ ] Correct in-place constraint (if required)
- [ ] Time complexity matches specification
- [ ] No off-by-one errors in loops
- [ ] Tested on already-sorted data

### Before Submitting Hash Table Code

- [ ] Handles collisions
- [ ] Resize logic correct
- [ ] Load factor maintained
- [ ] Insert, search, delete all work
- [ ] Tested with adversarial keys
- [ ] No memory leaks (if using pointers)
- [ ] Hash function has good distribution

### Before Submitting Heap Code

- [ ] Parent â‰¥ children maintained (max-heap)
- [ ] Parent â‰¤ children maintained (min-heap)
- [ ] Index arithmetic correct
- [ ] No off-by-one in parent/child calculations
- [ ] Extract removes root correctly
- [ ] Bubble-up and bubble-down correct

---

**Document Status:** âœ… COMPLETE  
**Format:** Printable, copy-paste ready  
**Purpose:** Rapid reference for Week 03 concepts

